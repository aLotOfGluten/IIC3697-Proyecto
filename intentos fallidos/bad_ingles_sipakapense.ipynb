{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96PapqzwAUkB"
   },
   "source": [
    "# Experimentos de Traducci√≥n Ingl√©s -> Sipakapense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_FHD9kw266t",
    "outputId": "84489b12-96ff-4730-9941-9d936178dd54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5rb6MT0A5mD"
   },
   "source": [
    "## Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yFaCwcFLx9HV"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Hg_qHsB95EzQ"
   },
   "outputs": [],
   "source": [
    "!pip install -U bitsandbytes\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NF14LcemARSd"
   },
   "outputs": [],
   "source": [
    "!pip install -U accelerate peft transformers sentencepiece datasets\n",
    "!pip install evaluate\n",
    "!pip install rouge_score\n",
    "!pip install nltk\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7-HRnAKmA8LR"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6x8Nds_8Y1Mm"
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smVHNrAeY5ck"
   },
   "source": [
    "Dataset se puede encontrar en el [siguiente enlace](https://github.com/transducens/mayanv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1ViYHauY4v3",
    "outputId": "50d1bb5a-2e3a-4a49-c717-26b76145c1d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mayanv'...\n",
      "remote: Enumerating objects: 177, done.\u001b[K\n",
      "remote: Counting objects: 100% (177/177), done.\u001b[K\n",
      "remote: Compressing objects: 100% (163/163), done.\u001b[K\n",
      "remote: Total 177 (delta 22), reused 157 (delta 14), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (177/177), 1.35 MiB | 5.48 MiB/s, done.\n",
      "Resolving deltas: 100% (22/22), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/transducens/mayanv.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ghoF4-noMjaC"
   },
   "outputs": [],
   "source": [
    "def generate_dataset(language, train_folder=\"train\", test_folder=\"test\", base_path=\"mayanv/MayanV\"):\n",
    "    # Rutas\n",
    "    train_lang_path = f\"{base_path}/{language}/{train_folder}/data.{language}\"\n",
    "    test_lang_path = f\"{base_path}/{language}/{test_folder}/data.{language}\"\n",
    "\n",
    "    train_es_path = f\"{base_path}/{language}/{train_folder}/data.es\"\n",
    "    test_es_path = f\"{base_path}/{language}/{test_folder}/data.es\"\n",
    "\n",
    "    # Carga manual de archivos\n",
    "    def load_lines(path):\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    train_src = load_lines(train_lang_path)\n",
    "    train_tgt = load_lines(train_es_path)\n",
    "\n",
    "    test_src = load_lines(test_lang_path)\n",
    "    test_tgt = load_lines(test_es_path)\n",
    "\n",
    "    # Crea datasets\n",
    "    train_dataset = Dataset.from_dict({\"input\": train_src, \"target\": train_tgt})\n",
    "    test_dataset = Dataset.from_dict({\"input\": test_src, \"target\": test_tgt})\n",
    "\n",
    "    return DatasetDict({\n",
    "        \"train\": train_dataset,\n",
    "        \"test\": test_dataset,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PmYZbWQ1kPpQ"
   },
   "outputs": [],
   "source": [
    "def invertir_input_target(example):\n",
    "    return {\n",
    "        \"input\": example[\"target\"],\n",
    "        \"target\": example[\"input\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "9522d74a4df84d099f25fd8168dea51c",
      "dd2ec1476a3c48e1b4b409d13d5bd9b3",
      "5c2e761058f945dc81a2aa3ddf8d7ca6",
      "9c62eed0117046259730318c17f94658",
      "731116717b4449ed84ddea8d48fda671",
      "c8999cbd29e94e3dad794b585e13b9f8",
      "12ce148841724ccd9ca287f20ead7d2b",
      "2bd78eeaee984c2fa4b6b32e2bd81c8b",
      "b1353cd350674a15b7281baf2b56083f",
      "45ffd500ec0c4f218f14c6bdd50a2f04",
      "00c7614b72f04406a0e0c50f94e0b5df",
      "28839145848f489c92ab4ddda734c88f",
      "33e401c6527341ed8e9b23444ad54adb",
      "f792ef15343e4d36915be0af6d5cfb79",
      "eeb84961c6ba4d8eac7b3d932a589e16",
      "3ce7f4d6fa4b4b30adb0448e407a3c68",
      "55663a5f61db47a5b2c667afb43496ee",
      "586271b3cbc348a2b3c360b59f001e8c",
      "f6568c63239a411397391bea5c0e61fa",
      "238d664975ca4c6fb08abe7ea87fe53e",
      "f760cf2a6cf94ef98db465cdd3ab8bbc",
      "9a3c93446a5d4700bdafb05c8c68df42"
     ]
    },
    "id": "4l0xcZcOgsmx",
    "outputId": "0321cde0-52de-46c1-b20c-b45db6f01ebc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9522d74a4df84d099f25fd8168dea51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28839145848f489c92ab4ddda734c88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "es_qum_dataset = generate_dataset(\"qum\", train_folder=\"test\", test_folder=\"dev\")\n",
    "es_qum_dataset = DatasetDict({\n",
    "    \"train\": es_qum_dataset[\"train\"].map(invertir_input_target),\n",
    "    \"test\": es_qum_dataset[\"test\"].map(invertir_input_target),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pb8bBRAeD9BG"
   },
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DtFcTKxaD-Mw"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    max_length = 128\n",
    "\n",
    "    inputs = finetune_tokenizer(\n",
    "        examples[\"input\"],\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    targets = finetune_tokenizer(\n",
    "        examples[\"target\"],\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def translate_text(model, tokenizer, text, src_lang, tgt_lang):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    forced_bos_id = tokenizer.convert_tokens_to_ids(tgt_lang)\n",
    "\n",
    "    # Detecta el dispositivo (GPU o CPU)\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Tokeniza y mueve a la misma device\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    # Generaci√≥n\n",
    "    outputs = model.generate(**inputs, forced_bos_token_id=forced_bos_id)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "\n",
    "def build_and_save_split_en_only(split, model, tokenizer, output_dir):\n",
    "    input_path = os.path.join(output_dir, f\"{split}.en\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with open(input_path, \"w\", encoding=\"utf-8\") as f_en:\n",
    "        print(f\"üîÑ Traduciendo y guardando split '{split}' al ingl√©s...\\n\")\n",
    "\n",
    "        for example in tqdm(es_qum_dataset[split]):\n",
    "            es_text = example[\"input\"].replace(\"#qum#\", \"\").strip()\n",
    "\n",
    "            try:\n",
    "                en_text = translate_text(model, tokenizer, es_text, \"spa_Latn\", \"eng_Latn\")\n",
    "                en_text = \"#qum# \" + en_text.strip()\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error traduciendo: {es_text}\\n{e}\")\n",
    "                en_text = \"#qum#\"\n",
    "\n",
    "            f_en.write(en_text + \"\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Archivo '{split}.en' guardado en {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6y8Xh2RBAmS"
   },
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6ngW-l5c1aq"
   },
   "source": [
    "### 1. Modelo Zero-shot (ELIMINAR LUEGO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397,
     "referenced_widgets": [
      "afd1b2ee815647fb8f6a0f223afce9bb",
      "904c99dabdb04069aea5e260bee7b2ed",
      "cb891dd6095e450e83e389864dc9b209",
      "5c9d6998a89442b7b5e43b955c1b0cc5",
      "ff9995c7be4a4fd89a35423c1b183197",
      "11c0e984f95b49b384574018ae73a3c5",
      "90a7daa1f6bb4ae19733920f881a60a5",
      "80e4ce296ea143039fc2775fe21f7dea",
      "07dc90720c00485ea80c4f1bf611e4da",
      "664759ce7da7411ca1c614593d7fdf46",
      "a9281c41be7b4d82bad24354bd8cec58",
      "2786730bc2c54c349a88168c43be917c",
      "94e9b7fae59949a4afd625aec8c34113",
      "130f01c93c834c039b098da9c881fe15",
      "f1e27e02b3984a839c143d17ae5a61ec",
      "3c7f69442ae8455dac22c6f254a733a9",
      "066b0a5024254bb490eba5e2ddcda532",
      "d1c8252e75e44761b1edbaaa3ae6b791",
      "ebebe98a51444d27ae231064c179e24e",
      "e68b9392916b44e0af992d3724ef94d6",
      "d918b18191a54008b65982afd7a667c1",
      "841a49af7e2341409c4d3cc0edc5c2a9",
      "83f012c486164c33bfe4bb633fa42221",
      "25cd6808058f4e9ebe97c454541d35eb",
      "cc763f0f8a094e80bd4069f1d202d555",
      "fd3a7d3ec12a42ddb02e2a8342a169d2",
      "c7f5c18f83c142dfbbf057ca836aa0bc",
      "769729478f244791b21ca1ba44b7eafd",
      "9ec5d9f813e44dbf87441760c4c372db",
      "ccf5fed14e5445f580bde7ff9f4a2ab7",
      "a9ecb48b9b2b4037bd48ed30cf084cff",
      "9c24cfe629ff4c5089823f141819d92e",
      "1e9685a333bf49a5ae7b86bbdc14aec9",
      "98bcf5fd7e2741f8beb7ec69e10c5147",
      "c55d241cc57f4e8186a60db86e3752bf",
      "492558c15de04370a6d573f866732b2f",
      "79fcd1a2401743e69752c09510c80086",
      "8e7ee2e8ec2241658606e7d38aa100d1",
      "d4de236fba484d7bb178dab358447b3f",
      "d8ff026dfdee471dbb51d8ac6c8cebf7",
      "196284ba752f433a9aed183e16f9de71",
      "b144bc4304c24bcea17f83c4ebd91aab",
      "d99e32bcf649435d9a7c455d4f73fa19",
      "28f7abd737514b3992572a7261f44a5d",
      "99e91256be3b46a6b6ba95976b38f2e3",
      "8f6e8660444c4676beb0204522b3de63",
      "a879b6c3782d4a80967c4a87a9f9eb9d",
      "2d9c2e09f069468aa20a100c96b3ffb9",
      "3b8da0ca8f7b4604b274c8cb9b0854d7",
      "eb55864238f34b46888c455480f50ac8",
      "4e58dba3ca2e4104b6aa0a68ef26131c",
      "fd7dd6cea2564773afd5a3e73c62ee57",
      "4dda373e1318461a9a91092a0d27a842",
      "3a9b6256c4d4496c99961521e8be6407",
      "5a8b4432d43440c8b9551213cb3d7466",
      "cd4536f686ec4783a15f91670d88b189",
      "0d96704e29ed43b2804f27676729b98e",
      "1594fbe69ffe4f31b6ea7e19faf32594",
      "bd2e429a79a44a509193426bb3b170ef",
      "1de9eb90694e4d429bce8f1c7d08cb95",
      "f6798caa6afa4a72ab0168fded0933d9",
      "1b33669e1f084aa4bcec76785ab2126d",
      "ecd186d515c84f83be3164e29a07f678",
      "efb2623c87764c15a542d6cd0bddef47",
      "bd3b68dc847548188b9b72327d642eef",
      "3acf021716c540e3a9a76faa72fafc94",
      "686a6902cc7944e092f15a75a8fd3f3a",
      "f865e80e68e942edbdd0aa039063c603",
      "14b37af4900e44ffbdf4e34d6d60bfff",
      "49045c11f4fa494a8082e013885e3132",
      "2e79f195f7fd47b994982f5a27631511",
      "8c0c4e8d87b340b6bdc58cc095777da2",
      "bd9abe7632d449fd89c9cd4c1612b9d8",
      "79f73fb3133f4a74b5b0c7d7ba06d4d2",
      "781a1670981c473796ed2ef58dd7ca08",
      "d37d374932284c529b61053256f6c675",
      "866ff764a5d441278a2ebe807dd1af28",
      "00782f5b0aa549d7a22435f146ca36aa",
      "13af87960f1c41b883106eea07ffbeae",
      "d96950adfc844f90aeb67bf826c61c0b",
      "032708db70c648ea90b7a325d393d0dc",
      "2c199354d1cc41afbe8c3cf5b664bc90",
      "62677446875e4e0394ea016f5ffeaec7",
      "7f0c81fee6704830967f368619182f5d",
      "710c21d07a5c40259f452ed514709c31",
      "b5c164cedce84facb9445269e6cef79c",
      "9183404984e94442bebee604d778316b",
      "5afa887358cd4848a5d5927a13a7620c"
     ]
    },
    "id": "vu8_JYKFBErT",
    "outputId": "c4549215-815b-4fcf-e18d-a735684c6990"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd1b2ee815647fb8f6a0f223afce9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2786730bc2c54c349a88168c43be917c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f012c486164c33bfe4bb633fa42221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98bcf5fd7e2741f8beb7ec69e10c5147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e91256be3b46a6b6ba95976b38f2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4536f686ec4783a15f91670d88b189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686a6902cc7944e092f15a75a8fd3f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00782f5b0aa549d7a22435f146ca36aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "zeroshot_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "zeroshot_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHu6X_ULjgGH"
   },
   "outputs": [],
   "source": [
    "zeroshot_tokenizer.src_lang = \"eng_Latn\"\n",
    "forced_bos_id = zeroshot_tokenizer.convert_tokens_to_ids(\"quc_Latn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjWCp3bkc27u"
   },
   "source": [
    "### 2. Modelo con Finetuning Espa√±ol-Sipakapense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397,
     "referenced_widgets": [
      "2389f20b977542ec8ff828a11b1de0ed",
      "a4ae93932e114a51abcc38580d3579bd",
      "483510e4c7a741b4b98e6e3af52662fa",
      "48a799a41037497fa3f143519ddbac4e",
      "67f3bb5e5ae046f798a85f94a9bbb048",
      "6a8619c2020447f280764852f8f0182f",
      "6dbade7bd63e4308aea09ec3a2a29924",
      "a864f7cc5a3a4f4294bc0cb53eff2652",
      "4b7bad336a5a44bda0d84f2b253b4195",
      "cc97d294ef8c491cbdb815647b5ff018",
      "5bf5047009a749fca84605cbf9153a70",
      "9688fdf29394461788230e6ba25e468d",
      "70ba0ad812a2449e8a6e81048a3b5c47",
      "24ab13dc1b5f43b8a1a0b7c384401a6b",
      "53f33a0f7d8644c998417b77669c3a0e",
      "d15f17a9f61e494f865f38482e13603d",
      "66b98d72987543f5b5897b4edeeae2cf",
      "502b542165ef479aac79589b54b68320",
      "1f468f0799004f21a7b1bf5b4c2b6f1b",
      "932639d197ab4a9fbe56d3295e1bfa87",
      "e464ec94700a4937a0d8c14bbe8b6d0e",
      "ab06ebd4f2b34642bac730aca4fed6d2",
      "a3601fb1cf184b6792efe18d73b365d9",
      "1c8941013d4d4cf78b0a9d6eb3c79546",
      "da454e110b1741638af057a62e31e5c9",
      "6610eb4188d44476af05042b56760722",
      "80da71d54a324b98968d3164eff66d20",
      "534f3ba5341f4c6588d11dad80370358",
      "d2096b3022ab4297a6f7a0373a5324e3",
      "902891be3cb74283b08b7026e8e216c2",
      "b12e8dbe3daf4f0c9cdd575373b66b2b",
      "62e1a54e17204ea8a94c115de6e36956",
      "d122c60bad9d46179281559411d416a4",
      "3af8bb392f5b460687ba3abaa5229392",
      "c92384e5688249cf9bade53c3df8ad1e",
      "c2bff7060b114896bb4e5170d6f4969a",
      "b4b4d5ec2e734e62866c585a03a448e1",
      "8262ab7c7b14487ebcd4d3f18b1638bd",
      "8fbefec5d5994915bdcc9aed12fe1a5d",
      "670cd2e291594076bffa7b093d301caa",
      "c637cb1fffb1476e96ef654d0be44a0a",
      "f9bb5da185894388af9b342b131beae4",
      "3bb5a00af9fb42f2a03cb332760a74af",
      "6a7e2e49c12444a2ab95f94b4f00a745",
      "c36a7d274d674b73b59993b9b91a07b9",
      "1cbb34c7cb184a1bbc85f3f17f7c33ae",
      "a00725a1980b43568847aa39b2d0fdb0",
      "a6ad5bb2dbf341f9a63a0726938b3c1a",
      "1ab2665bd7fe41d5a1b94fca786c3dde",
      "2a3862937b184f12ba797c04f39504e2",
      "37b0bf5346b6425eab75ad491379a8db",
      "1f08cec4eeb340cf866c093ef53805d3",
      "a41b21e885784ecda0fa1b7bb5e63463",
      "525efb8994d943bbbc965c66f2b0a71a",
      "af34b5ec23bc4862897c24cfdedecde9",
      "dda06acd8c6d418a99f355dd541d6a83",
      "5acfd145710f45709b1b34d8e01e057e",
      "4fa56e62628142d7b8f85167e8ef6790",
      "f467652557a34228a17bc9a4d73eb8ef",
      "955ed2653de445fbb840f2f9a7a507fd",
      "00eb3554c62147cabe0fec618e2a3c3c",
      "e272bd642ebc4f3492a349c874657d16",
      "aa8dab76cc6b48f6a934f0ec4adeb7ff",
      "fc924752b137420fb8008773518518e6",
      "35b8db4cf8f74a5b9196f3c715e66876",
      "b5fc82f7636e4670a3f628f3a86613ea",
      "b4e40be4d06b45438b1f4da291699dc2",
      "d448e0dfe56640eea287ac27f96b9d3d",
      "b7878bb0f1464d8bb1b8352cc7dd1171",
      "0fd92936553a49b68bb0c8284c829de4",
      "1709ea84177146a2b1fa626b24422d3a",
      "c6469a4a445e45bfa572f6e8a8ffb009",
      "061e3cd4d98f45dda5e96902d98b4278",
      "23cb61fde88c470dbd7cec7e1973883f",
      "9fe0c4569f964944b92a2110d99e2196",
      "5722aa5817a34d9db130e6c48f52511a",
      "684d7e28d992478cbe43df0e77d51b93",
      "ae08c60d5f4a4f298b773af967fa2f56",
      "3cfdfadf03464a9d845b0b899511a02b",
      "e84cc4030198450ba68ae40095fd7617",
      "8fb93cd5a7be43f0b4b08f84d7fef2cf",
      "d2b4e2c184c84478bc65e7471e30969f",
      "1e8a8aba5c1a46948275ba8da450884f",
      "44f08e6fa07d4aefbde534247fa9d8e1",
      "a39077941cb0411daf8d52f6f876fd26",
      "e36483b2c125404b8212156ed646ebe5",
      "5db632dfb07d42e596722bf26f132cc0",
      "6e2004a185244962a230784c1270f492"
     ]
    },
    "id": "j0zKtLz_K7Uc",
    "outputId": "336d7658-10a9-4989-9b52-ff023bebf169"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2389f20b977542ec8ff828a11b1de0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9688fdf29394461788230e6ba25e468d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3601fb1cf184b6792efe18d73b365d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af8bb392f5b460687ba3abaa5229392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36a7d274d674b73b59993b9b91a07b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda06acd8c6d418a99f355dd541d6a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e40be4d06b45438b1f4da291699dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae08c60d5f4a4f298b773af967fa2f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "finetune_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "\n",
    "finetune_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Configurar LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "# Aplicar QLoRA\n",
    "finetune_model = get_peft_model(finetune_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-TAeIyJ4pOZM",
    "outputId": "ca69d70b-c4c1-4cb5-ab9a-e4b92e065d18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M2M100ScaledWordEmbedding(256205, 1024, padding_idx=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A√±adir el token especial \"#qum#\" como marcador de idioma\n",
    "special_tokens_dict = {\"additional_special_tokens\": [\"#qum#\"]}\n",
    "finetune_tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# Redimensionar embeddings del modelo para incluir el nuevo token\n",
    "finetune_model.resize_token_embeddings(len(finetune_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "5154fd2d204a4ca09cd806ab95409d59",
      "9883e5b455b14f9bafb216c905b0fc57",
      "64c546d03d154080951fa0c7e2a63dd0",
      "ed1629de3a0f46edb2364edd43635eec",
      "3799e67fc9cd48cd9efa80c8837c41b6",
      "b0b3f3e9b6ea49fea3d56c1b4828790c",
      "b8957fa45dd64e6ca1ac4d53c1470857",
      "a1f9ce634dcd46f59380acf2c10965b3",
      "6d23bb9595044916bc4485c1ee51f531",
      "be26744ef3544190b1774fc568c78833",
      "b99cda15fd034256816fdcf1a3f75942",
      "e4c18d1a9be148d8b3dc38bd2caad8d7",
      "f02218097d3f4f8987b09862bf30032c",
      "08217e93325c4c13936d1933b426fc93",
      "4710b77ddcad4a008a5293f1bbe38522",
      "bf36fa79dddd4d97bac36d13940fe9d2",
      "43c19261b648480da9dad868a022ea1a",
      "e55be4ca594d4e2e8db19a09df8ea57f",
      "216dcc34d4e6402685837ad31eb292ec",
      "69b0874a5755401cbcd1f85189f9e7c2",
      "324eaab3243a4489ae2624c25a7aad8a",
      "215ba66872a9467aac0367d48ae4a366"
     ]
    },
    "id": "R2iPhpoQnSc2",
    "outputId": "ac4a5dbf-68ab-4cef-827c-1962f8fd35b5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5154fd2d204a4ca09cd806ab95409d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c18d1a9be148d8b3dc38bd2caad8d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = es_qum_dataset[\"train\"].map(preprocess_function, batched=True)\n",
    "tokenized_test = es_qum_dataset[\"test\"].map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "aXgDM4lAnagN",
    "outputId": "2e8ce169-9c3b-47c8-afd5-1a42c0b7e01c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipython-input-13-2171961071.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 04:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>8.125700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./qlora_finetuned_qum_nllb/tokenizer_config.json',\n",
       " './qlora_finetuned_qum_nllb/special_tokens_map.json',\n",
       " './qlora_finetuned_qum_nllb/sentencepiece.bpe.model',\n",
       " './qlora_finetuned_qum_nllb/added_tokens.json',\n",
       " './qlora_finetuned_qum_nllb/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qlora_finetuned_qum_nllb\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs_qlora\",\n",
    "    save_total_limit=2,\n",
    "    bf16=False,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=finetune_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=finetune_tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "finetune_model.save_pretrained(\"./qlora_finetuned_qum_nllb\")\n",
    "finetune_tokenizer.save_pretrained(\"./qlora_finetuned_qum_nllb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dazLUZlhKKHk"
   },
   "source": [
    "### 3. Modelo con Finetuning Ingl√©s-Sipakapense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VY4VIVD98VVY"
   },
   "source": [
    "#### Crear dataset directo (artificial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cq7pfc8XeVl"
   },
   "source": [
    "Para ejecutar esta parte se requiere haber definido la funci√≥n `translate_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "WWP5k7eHBeGc"
   },
   "outputs": [],
   "source": [
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "mid_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "mid_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "mid_tokenizer.src_lang = \"spa_Latn\"\n",
    "mid_forced_bos_id = mid_tokenizer.convert_tokens_to_ids(\"eng_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-mHBhUPZ3JcF",
    "outputId": "86bf8178-332d-442e-8d94-c414274ea504"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Traduciendo y guardando split 'test' al ingl√©s...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 321/321 [10:44<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo 'test.en' guardado en /content/drive/MyDrive/en_qum_dataset\n",
      "üîÑ Traduciendo y guardando split 'train' al ingl√©s...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [34:31<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo 'train.en' guardado en /content/drive/MyDrive/en_qum_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/content/drive/MyDrive/en_qum_dataset\"\n",
    "\n",
    "build_and_save_split_en_only(\"test\", mid_model, mid_tokenizer, output_dir)\n",
    "build_and_save_split_en_only(\"train\", mid_model, mid_tokenizer, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yg2pG-V8b5l"
   },
   "source": [
    "#### Realizar finetuning con datos artificiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397,
     "referenced_widgets": [
      "e2986057849c498f8f6654bee7c34214",
      "a169f9257b794cd9b494b95dd0f38d8e",
      "1f2baa738b4749dda309c71b6a813047",
      "753255a115f34c23991dcdd87cd4dd08",
      "4f4d0fb0bf2843d5b8729735da3ef9f0",
      "c5d2e0d9ffa44ec4af5478efcef22b12",
      "3eadaf0838264fca8e7b3545c2bd6e79",
      "46fc73721ace4f63a374b6e5a4d95648",
      "3127a852f1ef4d32bd8e27be19c11355",
      "83c9575a85e24621903afaf15012f205",
      "7bc50ca84517439f9c9c2f24d457d1e0",
      "3b5f552e890946f3b915e710ce0198e9",
      "946ef2d0c16e4cb8aaed25e3ea1db333",
      "4db67050037443c1afd03f9f1f03a5f1",
      "2c19ed51a38142f8a01d25619e7a6e4f",
      "c3382b5afdd74e2581150b9119f15b7f",
      "c9cd1f288ce04b3c94d7dc6d5cff24e4",
      "b3f48bd8141049679e938e5085a372b9",
      "89cf06d84f3b485db5d6d63f6832a149",
      "03b22ffba0a6455e862e371a9ec29978",
      "bcca652a491e4d1daae628a2641a3043",
      "1a4742fc417845dd96e9f0b948d5558b",
      "f3021cf9cd1246778ffce09ef73a0125",
      "3007df507d5845c38c413dea28fa036e",
      "1d2459bca3fb4e7990c857d03dfef871",
      "c578807c03de477b93cab5e2eaf23c0d",
      "5a5846f6f12448b5bef2a8c89e2e4bd9",
      "6fcaeddc80404dfd9f24b99fd4db5f86",
      "d702167de5b14f7795f2dd6cb8a71e0f",
      "a51cc680be354986a339d8483947686a",
      "fe8348ec0a1b4004a3c308e0a5e7bba2",
      "875609318c034f0db9c67f446fba01e3",
      "84154daf7cce478594bf4b29346c1913",
      "ffd7cbb0081d4db884851ae334e27848",
      "47d317d63111405497f3f253b3534b8b",
      "2dff662d6aa64bca92c533c3f5091609",
      "7c1e0f06cb444d46ba6069cbaa8f038c",
      "6c29b31862aa48b59c7d05a4c915dc62",
      "891adaf684ff41bbba513540d2a0733b",
      "ad3f9554e5d14a21bd5ab70fef795ae3",
      "8f73eb4d265b4e72b17db4b563d5f10c",
      "00faece2e95649b5b2d5f39b03abb5c0",
      "a5dd627485c14fd4aad2f937d54ca5f0",
      "430821b067c14e65b66569aea2f538b3",
      "5952329521244d718bff6fd1cc4d0a0d",
      "f1f0d4285dec429ca36963c47628965f",
      "bbb81fe8483f4eadba41900b2d046ac5",
      "6ec6555fc27c44bfb4db2c0c20b5b432",
      "b68b381b5301427ca86cf05070972cd4",
      "89e34892131541069c550537f0f21138",
      "087ed12f9de04e1191ef3c796e7c0e4a",
      "f2a150f69c30465f8f0464b696f729a4",
      "f6e2f896536648d8b23e97ffbd05fdef",
      "913b957c01654f8eb18e194d9587f4ae",
      "d13662f64f1445389b02a2d40c01e7dc",
      "68c4791de02e4442a6d3c2aeadb64634",
      "9611ddebfb4248b79d9843ec82fe9115",
      "96302ac40c5e408eacb6ee72ef4757d4",
      "72b8df47e4014f64b071fb115e22d80c",
      "988ffe33ea59421783c0356cb5edcb68",
      "fa3ccd5ffb704d0c97728e07f868fb6c",
      "f72b3d55a45c4c7d8a3d04a75dd4b11a",
      "c6fdd8658baf4d59b241631d2fc4f875",
      "60dbcb184d604968a1830aa3a7c7c8e2",
      "a0ce619326ac4915acabd88b8bc85cb8",
      "45214671e9ac4a76af8a18dd2e38015a",
      "a41b4ec251e24d55bd89b0531ebeffe5",
      "c1ca37e604a14abf97c5ce8df21424b1",
      "895226062800456eb30a8dcc20215ba2",
      "8b18a1629dc34d679e09050945fe46b5",
      "784ca8bedfab49379cc394318d2f0b53",
      "94743ea58b0d4baa97fbbba4c55d1d7f",
      "254d300a8d084202883da64a3a400e38",
      "c4abb342fdc84c01bd273e403ee9e8b5",
      "caa654cb425c4a9fb5dc19a30f76d58b",
      "971f7a4aeaf548159d2810173fb60af3",
      "49cbdc9fedfd4d1d9c97c1d6e9eebf7a",
      "28a1733700654a53a30c3791d213783b",
      "2c018b8f5bfc46ad9768a0ba67474f6e",
      "e041e5815d724d949b09b617034b831f",
      "14184416bab84361818c2c40c67d8c55",
      "cb9fd0d9fa2c4e959a063c4f6a2b1d56",
      "c4dbef832863421a95c2a4ac84639422",
      "5fc3650942ba4c5da75e55e4701febcf",
      "e6255d126d5a409db260a10a9d79d8e4",
      "e22bbb8c7cd9420a9474039a935cbb65",
      "b6c9387655b04d6a9913944cb1b6e872",
      "b86c5912707e44728291ea4bfa44f5e3"
     ]
    },
    "id": "LEUkIjpj33ln",
    "outputId": "b0e5a1c2-242e-422c-daa7-ce7943a4bfe2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2986057849c498f8f6654bee7c34214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5f552e890946f3b915e710ce0198e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3021cf9cd1246778ffce09ef73a0125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd7cbb0081d4db884851ae334e27848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5952329521244d718bff6fd1cc4d0a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c4791de02e4442a6d3c2aeadb64634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41b4ec251e24d55bd89b0531ebeffe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a1733700654a53a30c3791d213783b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "en_qum_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "en_qum_model = get_peft_model(base_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "ddf0a44eefe547479584c5deccecec7d",
      "6e01a2e2e2c543e1824f60e87adc13e2",
      "973e9b6bb52b4867aa722cb4db086c1f",
      "366f5d69d1ec48cfb4349c0107390cf0",
      "486ecc27023043eda51473d2b3492d12",
      "f6f9ea4b3ef540dcad94b0330219e142",
      "c03ce63581c249f7ac283c844c97a5e6",
      "98e7fef459b64108930a2b6a92650642",
      "8bd0547d288e4abeb1925c275fbcf671",
      "c4651321a5d4478c912466f5110ea974",
      "b2a6741a95c64810884157e8f7501a7a",
      "8b9b86f8d5144f66a51d4bab98f8aa5b",
      "dca49835efef4892bcc17fcdb74d4b8e",
      "dd4e879dc25a4183a66bcc3435269d86",
      "1e304ad12a734498addc6664f7b89be2",
      "33a8a989e0fb435ba546fbeaf20775bc",
      "eb9ea5e352d74748b58d8910eefc5675",
      "d7d24170d15642749241d1e8bdadbf02",
      "4202241df9b445f69a86c648ef79596d",
      "28d54a5244094cd89a911e52f81c7efe",
      "9993ca83ce6f4cf58dff004023f1eab4",
      "61fae0d2712c44abaf65227f5e8d8d17",
      "cae88b59f1c74b9780abed290b3ed04c",
      "c9f0f81278054cdf9e5d7c8dadcb2769",
      "6b514aff481e4c70a0574eca84c8f7b6",
      "275522673ba24747aca9970ccb6e3163",
      "afd4c9a1c567481fbcba8a4648e6033d",
      "29ddf51382f34d22ab380ba35ffa65f6",
      "501cf061b9804458bd3c6e5b916a5e45",
      "961b5cfa3526487998a6bd790096e1b1",
      "23e4157bd8c9487e89a727dea5ce5ae7",
      "a11b07827ca245fb875eca7efe58ff5c",
      "b2cc879e0ef94ae69142cb53bd5e6c1d",
      "c94f1a013a554a9dbf99f5011d0eb2a1",
      "a4c2ae4644d145fa9e0f3b60514f5274",
      "50c796bad6084ba581fe5a101a065470",
      "5edcd03065f445929b1fca23974fa03e",
      "17d15c46d3a84facb3029d29e3e13783",
      "ffe0ec4aed864cda90ce1470da4e6b6e",
      "005f2cb3acf447129e0bdfd10e3a2161",
      "c119b9cf901b414badbb34a449c88d15",
      "51b9174f94f94ae68892902f9978a9d5",
      "2593d6c44fdd4ba68ee925ee2f14b8f4",
      "489cbc32f841433893f4cdb8510b2907"
     ]
    },
    "id": "64iABUrW19Vf",
    "outputId": "63eba1d0-bef1-4739-fd4c-385c14fbcab8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf0a44eefe547479584c5deccecec7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9b86f8d5144f66a51d4bab98f8aa5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae88b59f1c74b9780abed290b3ed04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94f1a013a554a9dbf99f5011d0eb2a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = \".\"\n",
    "\n",
    "en_train = load_dataset(\"text\", data_files=f\"{data_dir}/train.en\")[\"train\"]\n",
    "quc_train = load_dataset(\"text\", data_files=f\"{data_dir}/train.quc\")[\"train\"]\n",
    "\n",
    "en_test = load_dataset(\"text\", data_files=f\"{data_dir}/test.en\")[\"train\"]\n",
    "quc_test = load_dataset(\"text\", data_files=f\"{data_dir}/test.quc\")[\"train\"]\n",
    "\n",
    "# Combinar train\n",
    "train_dict = {\n",
    "    \"input\": [x[\"text\"] for x in en_train],\n",
    "    \"target\": [x[\"text\"] for x in quc_train],\n",
    "}\n",
    "train_dataset = Dataset.from_dict(train_dict)\n",
    "\n",
    "# Combinar test\n",
    "test_dict = {\n",
    "    \"input\": [x[\"text\"] for x in en_test],\n",
    "    \"target\": [x[\"text\"] for x in quc_test],\n",
    "}\n",
    "test_dataset = Dataset.from_dict(test_dict)\n",
    "\n",
    "en_qum_dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "cc1dee25a6ea42f293b3c1452e614b45",
      "5ae282dcaebc4532b07911cfde8c476a",
      "bda7a75b2578438b9804f06ec48f9ce1",
      "71d3d1a788f248e9b305c457768eb964",
      "36c9a6a812bc43969da1fa528673813e",
      "6e3432c7f9994e83a4d756f79e8d1f41",
      "b80944bd8ef646e691336ceb94efa0b1",
      "39b685495cad461996c0406b43d5dfe7",
      "fe42c04a5857405d9a425a8a58262ca0",
      "8dee820a5ff946f7a09e95ab54082506",
      "52560adc15234804b1fa33a4cddb7013",
      "5d6a989635ee4ee6ae64f9a7c9457f3d",
      "533ab382d36546ceb9dd9d1c5668dffe",
      "0939b8080c9d4a058063d689fd03622e",
      "047b83d3b15445c49658d75ebade4aa0",
      "5dc440ae793145a2848af65d7bb0b600",
      "e75e444d3e3c4b0eb7427a1c992c0e85",
      "db7eb15a5d924f75924e10bc70ed0276",
      "58d70ef0f2c34635b9495a1fcc42eb8e",
      "b5ab57e926f9486f8fdcde87b2152bb8",
      "d762ea66d4804d7aba2e5640f219ccbb",
      "07f8894fa83c4d4999a9530194cad4a3"
     ]
    },
    "id": "w1sEWghP4B7C",
    "outputId": "c80ab1e6-da08-4ca7-971b-38c92103ed1b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1dee25a6ea42f293b3c1452e614b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6a989635ee4ee6ae64f9a7c9457f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function_en_qum(examples):\n",
    "    max_length = 128\n",
    "    inputs = en_qum_tokenizer(examples[\"input\"], max_length=max_length, truncation=True, padding=True)\n",
    "    targets = en_qum_tokenizer(examples[\"target\"], max_length=max_length, truncation=True, padding=True)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "tokenized_en_qum_train = en_qum_dataset[\"train\"].map(preprocess_function_en_qum, batched=True)\n",
    "tokenized_en_qum_test = en_qum_dataset[\"test\"].map(preprocess_function_en_qum, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxivqDvt4GEf",
    "outputId": "a9c3425e-49e3-4be1-df1e-0531be05ba4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "training_args_en_qum = TrainingArguments(\n",
    "    output_dir=\"./finetuned_en_qum_nllb\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs_en_qum\",\n",
    "    logging_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "WWYUxQWm4IU_",
    "outputId": "37c74abf-e1ee-419b-df05-bda9e7639303"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-15-1310942191.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_en_qum = Trainer(\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 01:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>10.082700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>8.990700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>8.157500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=8.834854166666666, metrics={'train_runtime': 93.4692, 'train_samples_per_second': 32.096, 'train_steps_per_second': 4.012, 'total_flos': 815382134784000.0, 'train_loss': 8.834854166666666, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_en_qum = Trainer(\n",
    "    model=en_qum_model,\n",
    "    args=training_args_en_qum,\n",
    "    train_dataset=tokenized_en_qum_train,\n",
    "    eval_dataset=tokenized_en_qum_test,\n",
    "    tokenizer=en_qum_tokenizer,\n",
    ")\n",
    "\n",
    "trainer_en_qum.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tc2QH1HJcuKn"
   },
   "source": [
    "## Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9jCIC05CCG_"
   },
   "source": [
    "### M√©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0,
     "referenced_widgets": [
      "6ee7760ef10d413d8e272622678fc9ae",
      "92a6799b1849476b9039b9e7890d4b26",
      "cd86c233132848c280b97106134ec4a8",
      "8f9de0f2ba254133a623612387a654a4",
      "b309f972e3f84c4b89efe3431e13ac23",
      "db92624e06604ccb91e4c0c559543e9d",
      "fc2a323e0540410ca02a3545dc09e777",
      "e6b86e2373664b1bb97d73beb69c2e91",
      "83186234985a4441aebb181e24ccd44d",
      "3cb0d193681c4581927e4a9bd0f1a2f7",
      "45be047402934c57b0238e93f4e24248",
      "ef828607ae95487ab6dba092e866e9e4",
      "504fe369303347d2b6d1e72b08dc858e",
      "586c916f3f514c0a9fb538d60d3802c2",
      "ddf151a7e6f64a6d8e406a4e35dc1b8c",
      "0314f8acb8ce419eac133790309a5dc1",
      "2d8215823b2549dfa6e74be859339c54",
      "ef47dff4f08f487a800d00331bad0c2a",
      "d101fb68001d45ab9ae66dadec78b2b8",
      "81d3bd0997c04d2a989be662993b7265",
      "770bd6a6a5b648eb98e9893ce2cb362c",
      "b6f02088c0a74a25a18d68590ad6e711",
      "25d3959f49394adebef46c6097266f6e",
      "d3f337245ac6446a9b968094ca20ceac",
      "65a4714a0a0e43e49a00c911e7dd32cc",
      "eee6d0f785104fa1873b7022b7a68e06",
      "e6425c733266467e8fd4d61e5da7a40c",
      "0e01bd0f45f44e56bdb5419d99cd53cb",
      "948088caefcb48d984ce8842bdd334f6",
      "625214b644e748a0b189f5066f072129",
      "588e9e73f1354240a05198ebdfc3c16c",
      "d3a1dbf7c98145748d3ddb8bc595f68e",
      "e76fce4da1ca46d4a61c4d086a070a17",
      "8a0477f518114675aaedf427fe4abb7a",
      "56929f25d67b4c06973bc9a00c29b093",
      "549e9c0e035442a18173e50a845e4720",
      "89c8acec017641d1bfeb858c724cfedb",
      "ba9d5ee1524a42fcbfec6c43518cbfd3",
      "75cfaebaef1141d496185a88e261c55d",
      "9f23852bf45040b1aa8a7664e3ca5d46",
      "7d0728cb5cd84fcda6670f8c909e6b9d",
      "e941c05c7f2544dea6e1afe7966e44e5",
      "c62d9ab2381e4d09b8a6609eee177405",
      "b2e650e77a2c4cc8b9c082d95fbe4247",
      "332f6e85fd1f4a2a94efe28f043faed7",
      "03c41bb9cd4c4b33918cc8c1cfee8292",
      "76cc8949393343f1b5d1a71f890d941e",
      "6581ceba2b994d1d81bf61d9877ed60e",
      "67338fd422dd418eb0e904ebfe986519",
      "8b1b6a38e1554ede90f6ee7ae248159f",
      "d79f8881430d4698aec41043b840a011",
      "e24428f97f19475ba4aaaf080ed46117",
      "90c8eb6b6a6a41d580d31817a4d7c508",
      "9825a4bd3fbc449193a7dd5024372b82",
      "a8cfd8d2f4244888a67dd8b2c550ea88"
     ]
    },
    "id": "YEoaaYAZCDnX",
    "outputId": "770d6cd1-1f79-4318-c367-e0f67844c35a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee7760ef10d413d8e272622678fc9ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef828607ae95487ab6dba092e866e9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d3959f49394adebef46c6097266f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0477f518114675aaedf427fe4abb7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332f6e85fd1f4a2a94efe28f043faed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "meteor = evaluate.load(\"meteor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coKh9lECcw45"
   },
   "source": [
    "### Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljNvMeB3ezyA"
   },
   "source": [
    "#### 1. Zero-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h97Ae05Ce4E0"
   },
   "source": [
    "Como NLLB tiene el idioma K‚Äôiche‚Äô, se coloca este como idioma objetivo para las traducciones directas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqLQveUOffXM",
    "outputId": "581fbd91-a318-45db-f7ff-b1bcded0f5a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 321/321 [1:17:38<00:00, 14.51s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for item in tqdm(es_qum_dataset[\"test\"]):\n",
    "    input_text = item[\"input\"]\n",
    "    reference = item[\"target\"]\n",
    "\n",
    "    inputs = zeroshot_tokenizer(input_text, return_tensors=\"pt\", truncation=True)\n",
    "    outputs = zeroshot_model.generate(**inputs, forced_bos_token_id=forced_bos_id)\n",
    "    pred = zeroshot_tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNH6mQC-j-jf",
    "outputId": "e5ae9f02-98c3-4435-b85d-cc926ea873e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplos ===\n",
      "\n",
      "> Entrada:     wu rxqiil ta º xuux xaq utz laj si º kchuknik chre\n",
      "> Referencia:  #qum# La esposa de don Jesus solo utiliza buena le√±a\n",
      "> Predicci√≥n:                                                                                                    \n",
      "\n",
      "> Entrada:     Njeel ri xkarawa ºn xpoch ºik rech chenim xchaq ºjik\n",
      "> Referencia:  #qum# Todo la arveja se\n",
      "> Predicci√≥n:  Njeel ri xkarawa ºn xpoch ºik rech chenim xchaq ºjik\n",
      "\n",
      "> Entrada:     Pri qtinmit qal chik kchkunsxik ri qyolb ºaal\n",
      "> Referencia:  #qum# En nuestro pueblo ya no se usa nuestro idioma\n",
      "> Predicci√≥n:  \n",
      "\n",
      "> Entrada:     Ri ajtijnel tjin kirtijuuj c hemo rchkunsxik ri su º\n",
      "> Referencia:  #qum# El estudiante est√° aprendiendo como\n",
      "> Predicci√≥n:                                                                                                    \n",
      "\n",
      "> Entrada:     Ri ixoq tz ºulmaj rum ri rchjiil\n",
      "> Referencia:  #qum# La mujer estaba abrazada por su marido\n",
      "> Predicci√≥n:  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar algunas predicciones\n",
    "print(\"\\n=== Ejemplos ===\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"> Entrada:     {es_qum_dataset['test'][i]['input']}\")\n",
    "    print(f\"> Referencia:  {es_qum_dataset['test'][i]['target']}\")\n",
    "    print(f\"> Predicci√≥n:  {predictions[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XR9Gk30mUYq",
    "outputId": "41303eff-e81d-491e-f77b-66b14c204641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== M√©tricas BLEU ===\n",
      "BLEU-1: 0.21\n",
      "BLEU-2: 0.00\n",
      "BLEU-3: 0.00\n",
      "BLEU-4: 0.00\n",
      "BLEU total: 0.00\n",
      "\n",
      "=== M√©tricas ROUGE ===\n",
      "ROUGE-1:   0.44\n",
      "ROUGE-2:   0.00\n",
      "ROUGE-L:   0.43\n",
      "ROUGE-Lsum:0.45\n",
      "\n",
      "=== Otras M√©tricas ===\n",
      "METEOR:     0.09\n"
     ]
    }
   ],
   "source": [
    "bleu_score = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "\n",
    "print(\"\\n=== M√©tricas BLEU ===\")\n",
    "print(f\"BLEU-1: {bleu_score['precisions'][0]*100:.2f}\")\n",
    "print(f\"BLEU-2: {bleu_score['precisions'][1]*100:.2f}\")\n",
    "print(f\"BLEU-3: {bleu_score['precisions'][2]*100:.2f}\")\n",
    "print(f\"BLEU-4: {bleu_score['precisions'][3]*100:.2f}\")\n",
    "print(f\"BLEU total: {bleu_score['bleu']*100:.2f}\")\n",
    "\n",
    "rouge_score = rouge.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(\"\\n=== M√©tricas ROUGE ===\")\n",
    "print(f\"ROUGE-1:   {rouge_score['rouge1']*100:.2f}\")\n",
    "print(f\"ROUGE-2:   {rouge_score['rouge2']*100:.2f}\")\n",
    "print(f\"ROUGE-L:   {rouge_score['rougeL']*100:.2f}\")\n",
    "print(f\"ROUGE-Lsum:{rouge_score['rougeLsum']*100:.2f}\")\n",
    "\n",
    "meteor_score = meteor.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(\"\\n=== Otras M√©tricas ===\")\n",
    "print(f\"METEOR:     {meteor_score['meteor']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJfs1A_sBkzy",
    "outputId": "03db1c7f-fc29-41fb-ae18-c64961faf4f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en 'results_es_qum_zeroshot.tsv'\n"
     ]
    }
   ],
   "source": [
    "with open(\"results_en_qum_zeroshot.tsv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    writer.writerow([\"input\", \"reference\", \"prediction\"])\n",
    "\n",
    "    for example, pred, ref in zip(es_qum_dataset[\"test\"], predictions, references):\n",
    "        writer.writerow([example[\"input\"], ref, pred])\n",
    "\n",
    "print(\"‚úÖ Resultados guardados en 'results_es_qum_zeroshot.tsv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjB3SBkqn1JG"
   },
   "source": [
    "#### 2. Finetuning ES-QUC y Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8uBCVbR3obZG",
    "outputId": "e392fbc2-218e-40f0-8cba-cc3046e639a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Traduciendo: Ingl√©s ‚Üí Espa√±ol ‚Üí Sipakapense\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 321/321 [09:42<00:00,  1.82s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions_intermediate = []\n",
    "references_intermediate = []\n",
    "\n",
    "print(\"\\nüîπ Traduciendo: Ingl√©s ‚Üí Espa√±ol ‚Üí Sipakapense\\n\")\n",
    "\n",
    "for item in tqdm(es_qum_dataset[\"test\"]):\n",
    "    input_text = item[\"input\"]\n",
    "    reference = item[\"target\"]\n",
    "\n",
    "    # Paso 1: ingl√©s ‚Üí espa√±ol\n",
    "    inter = translate_text(finetune_model, finetune_tokenizer, input_text, \"eng_Latn\", \"spa_Latn\")\n",
    "\n",
    "    # Paso 2: espa√±ol ‚Üí \"Sipakapense\"\n",
    "    pred = translate_text(finetune_model, finetune_tokenizer, inter, \"spa_Latn\", \"qum\")\n",
    "\n",
    "    predictions_intermediate.append(pred)\n",
    "    references_intermediate.append(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "qVv0v6pUvm-e"
   },
   "outputs": [],
   "source": [
    "clean_pred_intermediate = [pred.removeprefix(\"qum\").strip() for pred in predictions_intermediate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2roPLoJoy2L",
    "outputId": "f2e3760b-1b57-415f-97fb-9af7d2dfa71d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplos Fine-Tuned ===\n",
      "\n",
      "> Entrada:     #qum# La esposa de don Jesus solo utiliza buena le√±a\n",
      "> Referencia:  wu rxqiil ta º xuux xaq utz laj si º kchuknik chre\n",
      "> Predicci√≥n:  ri ri ri rb ºiik ri ri ri rb ºaj\n",
      "\n",
      "> Entrada:     #qum# Todo la arveja se\n",
      "> Referencia:  Njeel ri xkarawa ºn xpoch ºik rech chenim xchaq ºjik\n",
      "> Predicci√≥n:  ri xtz ºal\n",
      "\n",
      "> Entrada:     #qum# En nuestro pueblo ya no se usa nuestro idioma\n",
      "> Referencia:  Pri qtinmit qal chik kchkunsxik ri qyolb ºaal\n",
      "> Predicci√≥n:  xb ºi º xb ºi º xb ºalb ºan\n",
      "\n",
      "> Entrada:     #qum# El estudiante est√° aprendiendo como\n",
      "> Referencia:  Ri ajtijnel tjin kirtijuuj c hemo rchkunsxik ri su º\n",
      "> Predicci√≥n:  wu º ri xk ºo ºj\n",
      "\n",
      "> Entrada:     #qum# La mujer estaba abrazada por su marido\n",
      "> Referencia:  Ri ixoq tz ºulmaj rum ri rchjiil\n",
      "> Predicci√≥n:  xtz ºi º xb ºa ºl ri xb ºi º\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Ejemplos Fine-Tuned ===\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"> Entrada:     {es_qum_dataset['test'][i]['input']}\")\n",
    "    print(f\"> Referencia:  {es_qum_dataset['test'][i]['target']}\")\n",
    "    print(f\"> Predicci√≥n:  {clean_pred_intermediate[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcM-8kilozFz",
    "outputId": "bbbdcf92-2f40-4ca5-96d9-56763f7291bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== M√©tricas BLEU ===\n",
      "BLEU-1: 12.49\n",
      "BLEU-2: 0.00\n",
      "BLEU-3: 0.00\n",
      "BLEU-4: 0.00\n",
      "BLEU total: 0.00\n",
      "\n",
      "=== M√©tricas ROUGE ===\n",
      "ROUGE-1:   11.80\n",
      "ROUGE-2:   0.11\n",
      "ROUGE-L:   11.32\n",
      "ROUGE-Lsum:11.26\n",
      "\n",
      "=== Otras M√©tricas ===\n",
      "METEOR:     4.82\n"
     ]
    }
   ],
   "source": [
    "bleu_score = bleu.compute(predictions=clean_pred_intermediate, references=[[ref] for ref in references_intermediate])\n",
    "\n",
    "print(\"\\n=== M√©tricas BLEU ===\")\n",
    "print(f\"BLEU-1: {bleu_score['precisions'][0]*100:.2f}\")\n",
    "print(f\"BLEU-2: {bleu_score['precisions'][1]*100:.2f}\")\n",
    "print(f\"BLEU-3: {bleu_score['precisions'][2]*100:.2f}\")\n",
    "print(f\"BLEU-4: {bleu_score['precisions'][3]*100:.2f}\")\n",
    "print(f\"BLEU total: {bleu_score['bleu']*100:.2f}\")\n",
    "\n",
    "rouge_score = rouge.compute(predictions=clean_pred_intermediate, references=references_intermediate)\n",
    "\n",
    "print(\"\\n=== M√©tricas ROUGE ===\")\n",
    "print(f\"ROUGE-1:   {rouge_score['rouge1']*100:.2f}\")\n",
    "print(f\"ROUGE-2:   {rouge_score['rouge2']*100:.2f}\")\n",
    "print(f\"ROUGE-L:   {rouge_score['rougeL']*100:.2f}\")\n",
    "print(f\"ROUGE-Lsum:{rouge_score['rougeLsum']*100:.2f}\")\n",
    "\n",
    "meteor_score = meteor.compute(predictions=clean_pred_intermediate, references=references_intermediate)\n",
    "\n",
    "print(\"\\n=== Otras M√©tricas ===\")\n",
    "print(f\"METEOR:     {meteor_score['meteor']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MTsr6mJBWrm",
    "outputId": "4a27939d-7c6d-467d-81a8-c04e08bd66e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en 'results_es_qum_finetune_intermediate.tsv'\n"
     ]
    }
   ],
   "source": [
    "with open(\"results_en_qum_finetune_intermediate.tsv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    writer.writerow([\"input\", \"reference\", \"prediction\"])\n",
    "\n",
    "    for example, pred, ref in zip(es_qum_dataset[\"test\"], predictions_intermediate, references_intermediate):\n",
    "        writer.writerow([example[\"input\"], ref, pred])\n",
    "\n",
    "print(\"‚úÖ Resultados guardados en 'results_es_qum_finetune_intermediate.tsv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_UFY-dToFsb"
   },
   "source": [
    "#### 3. Finetuning ES-QUC y Traducci√≥n Directa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0UrnNGqobuo",
    "outputId": "7f41e97d-87a1-46d3-99b9-a9de50ffb7ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Traduciendo: ingl√©s ‚Üí Sipakapense (K‚Äôiche‚Äô)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 321/321 [04:03<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_direct = []\n",
    "references_direct = []\n",
    "\n",
    "print(\"\\nüîπ Traduciendo: ingl√©s ‚Üí Sipakapense\\n\")\n",
    "\n",
    "for item in tqdm(es_qum_dataset[\"test\"]):\n",
    "    input_text = item[\"input\"]\n",
    "    reference = item[\"target\"]\n",
    "\n",
    "    pred = translate_text(finetune_model, finetune_tokenizer, input_text, \"eng_Latn\", \"qum\")\n",
    "\n",
    "    predictions_direct.append(pred)\n",
    "    references_direct.append(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "chF42cMCu0k2"
   },
   "outputs": [],
   "source": [
    "clean_pred_direct = [pred.removeprefix(\"qum\").strip() for pred in predictions_direct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WGGj_XKctmn9",
    "outputId": "c9dc16e8-fd41-471c-d3d0-e6eeb9f5d03c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplos Fine-Tuned ===\n",
      "\n",
      "> Entrada:     #qum# La esposa de don Jesus solo utiliza buena le√±a\n",
      "> Referencia:  wu rxqiil ta º xuux xaq utz laj si º kchuknik chre\n",
      "> Predicci√≥n:   º xk ºo ºl ri xk ºu º ri xk ºo ºl\n",
      "\n",
      "> Entrada:     #qum# Todo la arveja se\n",
      "> Referencia:  Njeel ri xkarawa ºn xpoch ºik rech chenim xchaq ºjik\n",
      "> Predicci√≥n:  rb ºal xb ºanb ºal\n",
      "\n",
      "> Entrada:     #qum# En nuestro pueblo ya no se usa nuestro idioma\n",
      "> Referencia:  Pri qtinmit qal chik kchkunsxik ri qyolb ºaal\n",
      "> Predicci√≥n:  q ºal q ºo ºb ºe ºn q ºo ºb ºal\n",
      "\n",
      "> Entrada:     #qum# El estudiante est√° aprendiendo como\n",
      "> Referencia:  Ri ajtijnel tjin kirtijuuj c hemo rchkunsxik ri su º\n",
      "> Predicci√≥n:  ri xk ºo ºn xk ºo º\n",
      "\n",
      "> Entrada:     #qum# La mujer estaba abrazada por su marido\n",
      "> Referencia:  Ri ixoq tz ºulmaj rum ri rchjiil\n",
      "> Predicci√≥n:  xq ºo ºn ri xb ºi º\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Ejemplos Fine-Tuned ===\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"> Entrada:     {es_qum_dataset['test'][i]['input']}\")\n",
    "    print(f\"> Referencia:  {es_qum_dataset['test'][i]['target']}\")\n",
    "    print(f\"> Predicci√≥n:  {clean_pred_direct[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uNuiAUOytvUu",
    "outputId": "b81ed27b-2ef0-473a-9d69-18edcb90f658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== M√©tricas BLEU ===\n",
      "BLEU-1: 13.24\n",
      "BLEU-2: 0.00\n",
      "BLEU-3: 0.00\n",
      "BLEU-4: 0.00\n",
      "BLEU total: 0.00\n",
      "\n",
      "=== M√©tricas ROUGE ===\n",
      "ROUGE-1:   11.27\n",
      "ROUGE-2:   0.26\n",
      "ROUGE-L:   10.69\n",
      "ROUGE-Lsum:10.64\n",
      "\n",
      "=== Otras M√©tricas ===\n",
      "METEOR:     4.54\n"
     ]
    }
   ],
   "source": [
    "bleu_score = bleu.compute(predictions=clean_pred_direct, references=[[ref] for ref in references_direct])\n",
    "\n",
    "print(\"\\n=== M√©tricas BLEU ===\")\n",
    "print(f\"BLEU-1: {bleu_score['precisions'][0]*100:.2f}\")\n",
    "print(f\"BLEU-2: {bleu_score['precisions'][1]*100:.2f}\")\n",
    "print(f\"BLEU-3: {bleu_score['precisions'][2]*100:.2f}\")\n",
    "print(f\"BLEU-4: {bleu_score['precisions'][3]*100:.2f}\")\n",
    "print(f\"BLEU total: {bleu_score['bleu']*100:.2f}\")\n",
    "\n",
    "rouge_score = rouge.compute(predictions=clean_pred_direct, references=references_direct)\n",
    "\n",
    "print(\"\\n=== M√©tricas ROUGE ===\")\n",
    "print(f\"ROUGE-1:   {rouge_score['rouge1']*100:.2f}\")\n",
    "print(f\"ROUGE-2:   {rouge_score['rouge2']*100:.2f}\")\n",
    "print(f\"ROUGE-L:   {rouge_score['rougeL']*100:.2f}\")\n",
    "print(f\"ROUGE-Lsum:{rouge_score['rougeLsum']*100:.2f}\")\n",
    "\n",
    "meteor_score = meteor.compute(predictions=clean_pred_direct, references=references_direct)\n",
    "\n",
    "print(\"\\n=== Otras M√©tricas ===\")\n",
    "print(f\"METEOR:     {meteor_score['meteor']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2o0_ZKITBrRf",
    "outputId": "83b6fbe8-6ec8-4e4b-a338-505b76aa476b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en 'results_en_qum_finetune_direct.tsv'\n"
     ]
    }
   ],
   "source": [
    "filename = \"results_en_qum_finetune_direct.tsv\"\n",
    "with open(filename, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    writer.writerow([\"input\", \"reference\", \"prediction\"])\n",
    "\n",
    "    for example, pred, ref in zip(es_qum_dataset[\"test\"], predictions_direct, references_direct):\n",
    "        writer.writerow([example[\"input\"], ref, pred])\n",
    "\n",
    "print(f\"‚úÖ Resultados guardados en '{filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCaQTajaoPyr"
   },
   "source": [
    "#### 4. Finetuning EN-QUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7u9Ij-k23zQB",
    "outputId": "0cb1f47c-8066-499f-8545-4f7d71d94a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Traduciendo: ingl√©s ‚Üí K‚Äôiche‚Äô (dataset sint√©tico directo)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 321/321 [13:03<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions_en_qum = []\n",
    "references_en_qum = []\n",
    "\n",
    "print(\"\\nüîπ Traduciendo: ingl√©s ‚Üí K‚Äôiche‚Äô (dataset sint√©tico directo)\\n\")\n",
    "\n",
    "for item in tqdm(en_qum_dataset[\"test\"]):\n",
    "    input_text = item[\"input\"]\n",
    "    reference = item[\"target\"]\n",
    "    pred = translate_text(en_qum_model, en_qum_tokenizer, input_text, \"eng_Latn\", \"quc_Latn\")\n",
    "\n",
    "    predictions_en_qum.append(pred)\n",
    "    references_en_qum.append(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XO8mA9IDiFzd",
    "outputId": "50178c1c-45f4-4673-c223-5630f8885d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplos Fine-Tuned ===\n",
      "\n",
      "> Entrada:     The Commission shall adopt implementing acts in accordance with Article 21 of the Financial Regulation.\n",
      "> Referencia:  #qum# La esposa de don Jesus solo utiliza buena le√±a\n",
      "> Predicci√≥n:  La Comisi√≥n aprueba actos de ejecuci√≥n de conformidad con el art√≠culo 21 del Reglamento Financiero.\n",
      "\n",
      "> Entrada:     The Commission shall adopt implementing acts in accordance with Article 21 of the Financial Regulation.\n",
      "> Referencia:  #qum# Todo la arveja se\n",
      "> Predicci√≥n:            \n",
      "\n",
      "> Entrada:     The Commission shall adopt implementing acts in accordance with Article 21 of the Financial Regulation.\n",
      "> Referencia:  #qum# En nuestro pueblo ya no se usa nuestro idioma\n",
      "> Predicci√≥n:              \n",
      "\n",
      "> Entrada:     The Commission has decided to extend the period of validity of the agreement to the Member States.\n",
      "> Referencia:  #qum# El estudiante est√° aprendiendo como\n",
      "> Predicci√≥n:  la Comisi√≥n decidi√≥ prorrogar el periodo de validez del acuerdo a los Estados miembros.\n",
      "\n",
      "> Entrada:     The Commission shall adopt the following implementing acts:\n",
      "> Referencia:  #qum# La mujer estaba abrazada por su marido\n",
      "> Predicci√≥n:        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Ejemplos Fine-Tuned ===\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"> Entrada:     {en_qum_dataset['test'][i]['input']}\")\n",
    "    print(f\"> Referencia:  {en_qum_dataset['test'][i]['target']}\")\n",
    "    print(f\"> Predicci√≥n:  {predictions_en_qum[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UUh-Dvk3iLoy",
    "outputId": "6f382bc5-f056-4380-81fe-0701fbaa9ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== M√©tricas BLEU ===\n",
      "BLEU-1: 3.03\n",
      "BLEU-2: 0.12\n",
      "BLEU-3: 0.00\n",
      "BLEU-4: 0.00\n",
      "BLEU total: 0.00\n",
      "\n",
      "=== M√©tricas ROUGE ===\n",
      "ROUGE-1:   4.07\n",
      "ROUGE-2:   0.14\n",
      "ROUGE-L:   3.70\n",
      "ROUGE-Lsum:3.71\n",
      "\n",
      "=== Otras M√©tricas ===\n",
      "METEOR:     2.62\n"
     ]
    }
   ],
   "source": [
    "bleu_score = bleu.compute(predictions=predictions_en_qum, references=[[ref] for ref in references_en_qum])\n",
    "\n",
    "print(\"\\n=== M√©tricas BLEU ===\")\n",
    "print(f\"BLEU-1: {bleu_score['precisions'][0]*100:.2f}\")\n",
    "print(f\"BLEU-2: {bleu_score['precisions'][1]*100:.2f}\")\n",
    "print(f\"BLEU-3: {bleu_score['precisions'][2]*100:.2f}\")\n",
    "print(f\"BLEU-4: {bleu_score['precisions'][3]*100:.2f}\")\n",
    "print(f\"BLEU total: {bleu_score['bleu']*100:.2f}\")\n",
    "\n",
    "rouge_score = rouge.compute(predictions=predictions_en_qum, references=references_en_qum)\n",
    "\n",
    "print(\"\\n=== M√©tricas ROUGE ===\")\n",
    "print(f\"ROUGE-1:   {rouge_score['rouge1']*100:.2f}\")\n",
    "print(f\"ROUGE-2:   {rouge_score['rouge2']*100:.2f}\")\n",
    "print(f\"ROUGE-L:   {rouge_score['rougeL']*100:.2f}\")\n",
    "print(f\"ROUGE-Lsum:{rouge_score['rougeLsum']*100:.2f}\")\n",
    "\n",
    "meteor_score = meteor.compute(predictions=predictions_en_qum, references=references_en_qum)\n",
    "\n",
    "print(\"\\n=== Otras M√©tricas ===\")\n",
    "print(f\"METEOR:     {meteor_score['meteor']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uTytWvytiOA-",
    "outputId": "fccc3534-5ff0-4e2e-bc7b-0d17e8d4cb2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en 'results_en_qum_directo.tsv'\n"
     ]
    }
   ],
   "source": [
    "filename = \"results_en_qum_directo.tsv\"\n",
    "with open(filename, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    writer.writerow([\"input\", \"reference\", \"prediction\"])\n",
    "\n",
    "    for example, pred, ref in zip(es_qum_dataset[\"test\"], predictions_en_qum, references_en_qum):\n",
    "        writer.writerow([example[\"input\"], ref, pred])\n",
    "\n",
    "print(f\"‚úÖ Resultados guardados en '{filename}'\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "g5rb6MT0A5mD",
    "6x8Nds_8Y1Mm",
    "o6ngW-l5c1aq",
    "qjWCp3bkc27u",
    "U9jCIC05CCG_",
    "ljNvMeB3ezyA",
    "rjB3SBkqn1JG",
    "y_UFY-dToFsb"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
