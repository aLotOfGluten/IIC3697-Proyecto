{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96PapqzwAUkB"
   },
   "source": [
    "# Experimentos de Traducción Inglés -> Sipakapense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5rb6MT0A5mD"
   },
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yFaCwcFLx9HV"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Hg_qHsB95EzQ"
   },
   "outputs": [],
   "source": [
    "!pip install -U bitsandbytes\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NF14LcemARSd"
   },
   "outputs": [],
   "source": [
    "!pip install -U accelerate peft transformers sentencepiece datasets\n",
    "!pip install evaluate\n",
    "!pip install rouge_score\n",
    "!pip install nltk\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7-HRnAKmA8LR"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6x8Nds_8Y1Mm"
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smVHNrAeY5ck"
   },
   "source": [
    "Dataset se puede encontrar en el [siguiente enlace](https://github.com/transducens/mayanv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1ViYHauY4v3",
    "outputId": "d3d8d5d8-4283-4c63-9386-6648fd025cde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mayanv'...\n",
      "remote: Enumerating objects: 177, done.\u001b[K\n",
      "remote: Counting objects: 100% (177/177), done.\u001b[K\n",
      "remote: Compressing objects: 100% (163/163), done.\u001b[K\n",
      "remote: Total 177 (delta 22), reused 157 (delta 14), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (177/177), 1.35 MiB | 2.03 MiB/s, done.\n",
      "Resolving deltas: 100% (22/22), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/transducens/mayanv.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ghoF4-noMjaC"
   },
   "outputs": [],
   "source": [
    "def generate_dataset(language, train_folder=\"train\", test_folder=\"test\", base_path=\"mayanv/MayanV\"):\n",
    "    # Rutas\n",
    "    train_lang_path = f\"{base_path}/{language}/{train_folder}/data.{language}\"\n",
    "    test_lang_path = f\"{base_path}/{language}/{test_folder}/data.{language}\"\n",
    "\n",
    "    train_es_path = f\"{base_path}/{language}/{train_folder}/data.es\"\n",
    "    test_es_path = f\"{base_path}/{language}/{test_folder}/data.es\"\n",
    "\n",
    "    # Carga manual de archivos\n",
    "    def load_lines(path):\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    train_src = load_lines(train_lang_path)\n",
    "    train_tgt = load_lines(train_es_path)\n",
    "\n",
    "    test_src = load_lines(test_lang_path)\n",
    "    test_tgt = load_lines(test_es_path)\n",
    "\n",
    "    # Crea datasets\n",
    "    train_dataset = Dataset.from_dict({\"input\": train_src, \"target\": train_tgt})\n",
    "    test_dataset = Dataset.from_dict({\"input\": test_src, \"target\": test_tgt})\n",
    "\n",
    "    return DatasetDict({\n",
    "        \"train\": train_dataset,\n",
    "        \"test\": test_dataset,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4l0xcZcOgsmx"
   },
   "outputs": [],
   "source": [
    "es_qum_dataset = generate_dataset(\"qum\", train_folder=\"test\", test_folder=\"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6y8Xh2RBAmS"
   },
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6ngW-l5c1aq"
   },
   "source": [
    "### 1. Modelo Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397,
     "referenced_widgets": [
      "afd1b2ee815647fb8f6a0f223afce9bb",
      "904c99dabdb04069aea5e260bee7b2ed",
      "cb891dd6095e450e83e389864dc9b209",
      "5c9d6998a89442b7b5e43b955c1b0cc5",
      "ff9995c7be4a4fd89a35423c1b183197",
      "11c0e984f95b49b384574018ae73a3c5",
      "90a7daa1f6bb4ae19733920f881a60a5",
      "80e4ce296ea143039fc2775fe21f7dea",
      "07dc90720c00485ea80c4f1bf611e4da",
      "664759ce7da7411ca1c614593d7fdf46",
      "a9281c41be7b4d82bad24354bd8cec58",
      "2786730bc2c54c349a88168c43be917c",
      "94e9b7fae59949a4afd625aec8c34113",
      "130f01c93c834c039b098da9c881fe15",
      "f1e27e02b3984a839c143d17ae5a61ec",
      "3c7f69442ae8455dac22c6f254a733a9",
      "066b0a5024254bb490eba5e2ddcda532",
      "d1c8252e75e44761b1edbaaa3ae6b791",
      "ebebe98a51444d27ae231064c179e24e",
      "e68b9392916b44e0af992d3724ef94d6",
      "d918b18191a54008b65982afd7a667c1",
      "841a49af7e2341409c4d3cc0edc5c2a9",
      "83f012c486164c33bfe4bb633fa42221",
      "25cd6808058f4e9ebe97c454541d35eb",
      "cc763f0f8a094e80bd4069f1d202d555",
      "fd3a7d3ec12a42ddb02e2a8342a169d2",
      "c7f5c18f83c142dfbbf057ca836aa0bc",
      "769729478f244791b21ca1ba44b7eafd",
      "9ec5d9f813e44dbf87441760c4c372db",
      "ccf5fed14e5445f580bde7ff9f4a2ab7",
      "a9ecb48b9b2b4037bd48ed30cf084cff",
      "9c24cfe629ff4c5089823f141819d92e",
      "1e9685a333bf49a5ae7b86bbdc14aec9",
      "98bcf5fd7e2741f8beb7ec69e10c5147",
      "c55d241cc57f4e8186a60db86e3752bf",
      "492558c15de04370a6d573f866732b2f",
      "79fcd1a2401743e69752c09510c80086",
      "8e7ee2e8ec2241658606e7d38aa100d1",
      "d4de236fba484d7bb178dab358447b3f",
      "d8ff026dfdee471dbb51d8ac6c8cebf7",
      "196284ba752f433a9aed183e16f9de71",
      "b144bc4304c24bcea17f83c4ebd91aab",
      "d99e32bcf649435d9a7c455d4f73fa19",
      "28f7abd737514b3992572a7261f44a5d",
      "99e91256be3b46a6b6ba95976b38f2e3",
      "8f6e8660444c4676beb0204522b3de63",
      "a879b6c3782d4a80967c4a87a9f9eb9d",
      "2d9c2e09f069468aa20a100c96b3ffb9",
      "3b8da0ca8f7b4604b274c8cb9b0854d7",
      "eb55864238f34b46888c455480f50ac8",
      "4e58dba3ca2e4104b6aa0a68ef26131c",
      "fd7dd6cea2564773afd5a3e73c62ee57",
      "4dda373e1318461a9a91092a0d27a842",
      "3a9b6256c4d4496c99961521e8be6407",
      "5a8b4432d43440c8b9551213cb3d7466",
      "cd4536f686ec4783a15f91670d88b189",
      "0d96704e29ed43b2804f27676729b98e",
      "1594fbe69ffe4f31b6ea7e19faf32594",
      "bd2e429a79a44a509193426bb3b170ef",
      "1de9eb90694e4d429bce8f1c7d08cb95",
      "f6798caa6afa4a72ab0168fded0933d9",
      "1b33669e1f084aa4bcec76785ab2126d",
      "ecd186d515c84f83be3164e29a07f678",
      "efb2623c87764c15a542d6cd0bddef47",
      "bd3b68dc847548188b9b72327d642eef",
      "3acf021716c540e3a9a76faa72fafc94",
      "686a6902cc7944e092f15a75a8fd3f3a",
      "f865e80e68e942edbdd0aa039063c603",
      "14b37af4900e44ffbdf4e34d6d60bfff",
      "49045c11f4fa494a8082e013885e3132",
      "2e79f195f7fd47b994982f5a27631511",
      "8c0c4e8d87b340b6bdc58cc095777da2",
      "bd9abe7632d449fd89c9cd4c1612b9d8",
      "79f73fb3133f4a74b5b0c7d7ba06d4d2",
      "781a1670981c473796ed2ef58dd7ca08",
      "d37d374932284c529b61053256f6c675",
      "866ff764a5d441278a2ebe807dd1af28",
      "00782f5b0aa549d7a22435f146ca36aa",
      "13af87960f1c41b883106eea07ffbeae",
      "d96950adfc844f90aeb67bf826c61c0b",
      "032708db70c648ea90b7a325d393d0dc",
      "2c199354d1cc41afbe8c3cf5b664bc90",
      "62677446875e4e0394ea016f5ffeaec7",
      "7f0c81fee6704830967f368619182f5d",
      "710c21d07a5c40259f452ed514709c31",
      "b5c164cedce84facb9445269e6cef79c",
      "9183404984e94442bebee604d778316b",
      "5afa887358cd4848a5d5927a13a7620c"
     ]
    },
    "id": "vu8_JYKFBErT",
    "outputId": "c4549215-815b-4fcf-e18d-a735684c6990"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd1b2ee815647fb8f6a0f223afce9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2786730bc2c54c349a88168c43be917c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f012c486164c33bfe4bb633fa42221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98bcf5fd7e2741f8beb7ec69e10c5147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e91256be3b46a6b6ba95976b38f2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4536f686ec4783a15f91670d88b189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686a6902cc7944e092f15a75a8fd3f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00782f5b0aa549d7a22435f146ca36aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "zeroshot_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "zeroshot_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XHu6X_ULjgGH"
   },
   "outputs": [],
   "source": [
    "zeroshot_tokenizer.src_lang = \"eng_Latn\"\n",
    "forced_bos_id = zeroshot_tokenizer.convert_tokens_to_ids(\"quc_Latn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjWCp3bkc27u"
   },
   "source": [
    "### 2. Modelo con Finetuning Español-Sipakapense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397,
     "referenced_widgets": [
      "cac3110d105c4a8dbec2586eaf94fc34",
      "b7feb908c3d04a28ae1203d30f37886e",
      "5157e0a055d24f8792c0ff978f3cc6dd",
      "2f7b86d5099b4bfbba242d09f9f51784",
      "60d172891a714947b58c4b2beb6b6d86",
      "84dd7cd6a10f4fd1a46814f98f13a612",
      "2166164f7ebd42cc8ba2a0f53918b20a",
      "cb09b570e8d3425e9cc0a65bbb87fe09",
      "47ba86eafbab4850ae6d766f02d5158b",
      "ac9c6614e7c24b8099e81ad7747e7a7b",
      "20e3e3a6b5ea46ea82dccfe6f47e6b1b",
      "1da63fd1e85b4ea0aac883c6b4835276",
      "1207501eeeb542b8bcd021f334273c34",
      "fa65369032ef49eebef4e569bb16e8b9",
      "0cddb01266994f1388dbca2c805a2c11",
      "f5bfe0b06f74418bac8eab55c2f75719",
      "3900f275d2fb40a58b374856ab84ca61",
      "9fc99743cd134b849429f40f9213229f",
      "4cc1a3b4f8a346098fd363a63d96c40f",
      "d5ecc35af7194654a266ec0533706e2c",
      "b7fcf235a9d147ca99632bb326976b89",
      "9ad0954f7bdf421a926021eec59c6d70",
      "7991c21a7e064f28ae9660268be282af",
      "cd513793249f415b8af8b44bcc8ae6ae",
      "0756b55a80224b2cb8636031bd400c5c",
      "a4b92bd7e58e4d47a1ced1bbcb998b55",
      "aaa04cbca3ef48578271b15fb84c653e",
      "88f9d35e531f4586a3c7c609e69e79c5",
      "efa41214852b425c83ff741584da38e0",
      "1c07a06c5ac04060bf521a1d8a37fb0c",
      "85f1a96f455b4406b5ccea1fff1e1f8c",
      "ef1c0e91a50f45f8aa1b7ca8b0bc6f5b",
      "f78b2f8fc75e490e8121e57454b73286",
      "c4099109a3f747c9bbead39673a48baf",
      "18840f6e36d84159bc6e1189d9913760",
      "5ae2b42b83154f5d978ada78244c2ae6",
      "639819d82e9641a2bf8182903a0ea65d",
      "de533b259a704719a8dde48692d7b8ab",
      "21f989533a7a44e1964d46bedc38e468",
      "91ad31ececdd450998bb910db770a28a",
      "3c52bb10091443ca8f41cdbf91f3fdab",
      "9c7fae1c7efb48528c6a9b52aa491a99",
      "6ae26a6cd31c49aba082b19737e5e4ac",
      "6bd51422ab0940a79892fe5beb8694cb",
      "e7eae7da663a42d5af4484fdde0bbfe3",
      "03e6891231fb4378bf72f7de4daddca1",
      "e9b52aa07215463ebd1260edbd739acd",
      "be5371f817f245e7abe72f38a7c378df",
      "710bc3f3082b48babdd1df67c7d445b7",
      "df13ac30b926449c90ad58da70eec4f4",
      "3f7d5e738814472681fca9291a31a13e",
      "16ab0c66534a4048b3ccbf8b8cc5ea24",
      "bd34506de1204810beff81c6af29b935",
      "b203748cde484f17ae2b7c77b8b1680e",
      "054e8136680c40edaa978c010b7e8a30",
      "7a05e8788bb24d569fa99fef24984821",
      "86c08b9c63f943289f131233425b9292",
      "0072120e6a2445d882db8d3bb42fa59f",
      "36569700ceda464d824ea0bd8014fbae",
      "bbd2e201249b418e83bad359a946b6a1",
      "6adf3a15680e4675b7fd4a23c330d91f",
      "6302b375780a41e3b4c603fb6cd27c9e",
      "89562245bcc043c08396d14f0fcc2579",
      "49e91b56464747b18063f84dfef0bad0",
      "21821795a95e4a4b81d328621ed34561",
      "c8e4ece38aa0436fada10bce538afd6d",
      "59fb31515e6f4cf3886dc464d0b93245",
      "00eea24a096e40ed91be26456f036b66",
      "28cab3728e9648fb8cf27d5854f307e9",
      "09967ea2407044679a04271d5ad12a9d",
      "6a31659db6b8435bad98a5a57eb40220",
      "5daef335e59f49ec8dcfda97006dc31c",
      "b831d882b5ba4ab192fc51cd8990ed91",
      "386842879368479a95a1f45bc9190a74",
      "8620e063aced4436a0437b5ba069d629",
      "8839918072b548658d65233d5aeb31be",
      "a7a525b41a2443b2b41034d0a24499ef",
      "6defadbd0aab4d639a905b4dbd3c3faf",
      "e60c511508fa4028b29c603104cd62b1",
      "8d5285d2edda416baf70a725992ac3ec",
      "b54233f883e6499495a1c3e1757c4061",
      "efd138698921446b833f6436b1668cf7",
      "e0d01f14335244438d1429e4dc8a7c9f",
      "7b0b6031272e474ca0148b2b084ce4fe",
      "6e798de7f5404c938b1be009c660de8f",
      "d9607597331140d58ad6cd3a7a62e2a5",
      "d6d7ba5265df46b19baca56f5e7105bf",
      "850dcf697f5e4814bef791be9418f88a"
     ]
    },
    "id": "j0zKtLz_K7Uc",
    "outputId": "402fd5f5-2c72-4c18-b6a3-f4d33ea97f05"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac3110d105c4a8dbec2586eaf94fc34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da63fd1e85b4ea0aac883c6b4835276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7991c21a7e064f28ae9660268be282af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4099109a3f747c9bbead39673a48baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7eae7da663a42d5af4484fdde0bbfe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a05e8788bb24d569fa99fef24984821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59fb31515e6f4cf3886dc464d0b93245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6defadbd0aab4d639a905b4dbd3c3faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "finetune_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "\n",
    "finetune_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Configurar LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "# Aplicar QLoRA\n",
    "finetune_model = get_peft_model(finetune_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "c9dfd240f1514875989b55174d06307f",
      "d2ce9cf3dade432eaabddc7be352e52d",
      "efe03bed64c1434d80e148f10efca664",
      "6b81b26744f149409410a6630f4c724f",
      "2b0aeb73c975427ab3bce3a21a144326",
      "1e3d5d0b552f47adbaa07733a1784fb9",
      "09ec14cd278847bd8082fc1a2a93bb1c",
      "09babbd93a99420989b3fbcb840faaa9",
      "4f1adec9090e428e82248aa5f7e87721",
      "c446b8cd15614b5cb584ffbb48ed73b5",
      "38f23e002e014459afd40d5ad025792f",
      "445978df90ee4ec2ae9779a9c21fc1ca",
      "baa46cdaa39b4e0680073a746eefe307",
      "8c691feec04d4fa19884ca72ccffb872",
      "c18ad957292b49be90789aa7e378a0bb",
      "fb07469281ab4c13af51e12bf1ba1c4e",
      "de5a8a4a33944ebcb4ad08b01be8ab3b",
      "9997e8f346d94eb2b918769fba482f24",
      "d22b23fb226d4f409af4daf3019c2a31",
      "d6f5714423ee4c7c802216440b67e972",
      "3447722eef6c44f4b2f0206b6171bc9c",
      "c2c51ccf18de4cdc8943cc2a82a4afc8"
     ]
    },
    "id": "R2iPhpoQnSc2",
    "outputId": "92e640f8-946b-48a1-e922-27b8557fa366"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9dfd240f1514875989b55174d06307f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445978df90ee4ec2ae9779a9c21fc1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    max_length = 128\n",
    "\n",
    "    inputs = finetune_tokenizer(\n",
    "        examples[\"input\"],\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    targets = finetune_tokenizer(\n",
    "        examples[\"target\"],\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "tokenized_train = es_qum_dataset[\"train\"].map(preprocess_function, batched=True)\n",
    "tokenized_test = es_qum_dataset[\"test\"].map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vf7lJXOmsYB1"
   },
   "outputs": [],
   "source": [
    "def translate_text(model, tokenizer, text, src_lang, tgt_lang):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    forced_bos_id = tokenizer.convert_tokens_to_ids(tgt_lang)\n",
    "\n",
    "    # Detecta el dispositivo (GPU o CPU)\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Tokeniza y mueve a la misma device\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    # Generación\n",
    "    outputs = model.generate(**inputs, forced_bos_token_id=forced_bos_id)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "aXgDM4lAnagN",
    "outputId": "0a0f4d1e-6fb1-4352-a660-dfc70933fa7c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipython-input-13-2171961071.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 03:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>8.078200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./qlora_finetuned_qum_nllb/tokenizer_config.json',\n",
       " './qlora_finetuned_qum_nllb/special_tokens_map.json',\n",
       " './qlora_finetuned_qum_nllb/sentencepiece.bpe.model',\n",
       " './qlora_finetuned_qum_nllb/added_tokens.json',\n",
       " './qlora_finetuned_qum_nllb/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qlora_finetuned_qum_nllb\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs_qlora\",\n",
    "    save_total_limit=2,\n",
    "    bf16=False,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=finetune_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=finetune_tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "finetune_model.save_pretrained(\"./qlora_finetuned_qum_nllb\")\n",
    "finetune_tokenizer.save_pretrained(\"./qlora_finetuned_qum_nllb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dazLUZlhKKHk"
   },
   "source": [
    "### 3. Modelo con Finetuning Inglés-Sipakapense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VY4VIVD98VVY"
   },
   "source": [
    "#### Crear dataset directo (artificial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cq7pfc8XeVl"
   },
   "source": [
    "Para ejecutar esta parte se requiere haber definido la función `translate_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397,
     "referenced_widgets": [
      "cf86da6a12754d609ca56b09c48a7600",
      "2c14f8bed6ed4565b27eda5c6885fe7d",
      "1065adc0406b40bca59cd2f3dd9a7ce9",
      "17f0c0db9ed14c3f8c8f52e0c98f2fae",
      "1e7280f25e79422e9641c89801b853ef",
      "051067453a8c4728afc53804061e5c30",
      "17b3da49899d4d7bb57ee6df1d638503",
      "e429f0a6bd434b4bbfa2f368a5c6a010",
      "2d56f88931eb412685f0eb480c64ade4",
      "0f589446130b4d50bf466831b04dcfd4",
      "5315a7f978e74ed6888d0281b89b5f04",
      "8fefce6d95b140e1882e1868ee7e4b54",
      "fa1dd20bd1a34571aa8ab7f415c90db3",
      "35c0af7a80cf4617baa7b6af8b37c2a3",
      "ef7aefc8ec3045978523c6d0cfc3165b",
      "a94a0cb413eb494a8111149a0511f61f",
      "634e85740af0462dbdfc6cd352809810",
      "b7dc2fd2493e4f80844b8c0c22195db9",
      "c39786ebdfcc40789d33352681652b64",
      "3d76a6f3d5624642817f7cb05219fb60",
      "4475a41b34304bb5890f9c89c09578cf",
      "069cef0e8990411fbc8611552323dba9",
      "d09b07ca75774338bcbf49d73a6fe983",
      "d03bc2e6d7d14c049c87e324ab0fa288",
      "71acf1e83671457c8fac7aa487391c05",
      "dffa486ba72940c9ab9c05891fc225d6",
      "c63f4794dca74a14a9ac58472d3239f6",
      "4a499eb5032e429b915dfe8c5b09c814",
      "94e7e4a4378848b4b465156eee320219",
      "d645b18e5e6a42c381da2f3630f4bd8b",
      "2c7fc6756f3849b0adb4568d6acc490a",
      "72d69f2def3e4d56a4595aa8d869dc9f",
      "2d17e481c5b44ddcb9ae307583d5a66c",
      "552ac75247894dbc8cbb164cdf6ee9a3",
      "252b55a11628481498606ff29c84a452",
      "26aac17209074d83a0129bf952e4ba92",
      "8c724e43341145ba9faab1a43feb91f7",
      "4370322bbd77475088879e3ca5365c80",
      "ea488858cf47470088b20e0744761320",
      "10427d4a638c40c392a217b832a3eff4",
      "858291e3eef44c77bcf92bba5c14a22b",
      "940e1779066d4f5fa2a181f6544a1b46",
      "f9fab1eaf23d4076ba791a1c3316a254",
      "3aa7b16bea244abab3eeea6b85c6db1d",
      "b3ac59540b034842aff126ac45a10c58",
      "b2fbb67b3de64365abc215b0738b68e8",
      "2222613c8b304fb8a9f113844fe9d5cd",
      "12248f4f5f6a47c78b6391af806ca70f",
      "2cc9861d967e482f91975aab08672ef1",
      "0fc392a251b94d689e86b456a6295e51",
      "ea6f75184e2e40329df1f747d86df215",
      "1bc6a0f637d94f9a8124ddf91a53918c",
      "3f7b2f983907475fb00f1b2625d5ed0f",
      "4bc8298692aa4f4bb7aadeae07c959a3",
      "0c7c297963794af78dfb10fa6028a3dc",
      "99b49923502d49a6bb3ae53313f04b51",
      "fdbf029c7b2e46628bbb9692eac1189c",
      "c2fcf7a705af4f55bf4f347920af95c0",
      "4e96fa7ac06f4844aa08e230d906a504",
      "60f30c0e4aab454bac3995ca99ccaf4d",
      "20d92fb86bc4429da4561bbd6009aff3",
      "31b18a905c4246769c2da646e6d80f60",
      "5d68d4b46b4c4544b309cd212d65732d",
      "1d11ffc703bb4657966ddfcc746090b0",
      "f6317bc2a97a4574836122594c885dc8",
      "03ac4c532645426b8d103aa173b48df4",
      "64a4fe12f749449db882a65a3bd391c0",
      "61252e5887c3432c9a57cfb38b642075",
      "390c414f9d5941b883b0ada7e89840db",
      "53121884068d4def991d4d6f7a8c42db",
      "d99f4b19147d44d8846a0ee30279faa7",
      "bb8a9abf791b4d708b54741a7a643641",
      "d533e30159ca42b4aa8b141868d96a72",
      "7026303fad68465683618c1d0cba84f9",
      "b7b82e7231ef456d846d70af6d2cc712",
      "ad5f246b0ec44c1780ac4b2b57826e2e",
      "e098af38ec7b4d4fa311ea70c54aece8",
      "48d167bc737d4de8aa759106cc4234d3",
      "fc3d0d38db1147519ac553447dde05bd",
      "4881a1eafc2b4aca91884603622fb1cf",
      "6cba59b62f154376a4f862a575570c81",
      "ddf932c2db4f440ba11ee8efd2d7cbd5",
      "3fb63d1324684fbe8de175ef55dff96d",
      "7d81d9038c5d4c8b88970f4d9d43168e",
      "dd5957ffc4b048e79b7dba8c590e73e7",
      "06fc01b759984185bb8a78c49f3851b8",
      "8c58870a3cec49109429507b428a87ea",
      "7950dea829c64162981e3d7d086924e9"
     ]
    },
    "id": "WWP5k7eHBeGc",
    "outputId": "e4bb5d65-360b-4106-82ab-94ff04e49788"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf86da6a12754d609ca56b09c48a7600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fefce6d95b140e1882e1868ee7e4b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09b07ca75774338bcbf49d73a6fe983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552ac75247894dbc8cbb164cdf6ee9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ac59540b034842aff126ac45a10c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b49923502d49a6bb3ae53313f04b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a4fe12f749449db882a65a3bd391c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d167bc737d4de8aa759106cc4234d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "mid_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "mid_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "mid_tokenizer.src_lang = \"spa_Latn\"\n",
    "mid_forced_bos_id = mid_tokenizer.convert_tokens_to_ids(\"eng_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rvt-fnEaK6vM",
    "outputId": "0731d7d6-35f9-4bb5-dfc6-a7f8a1c9f5dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Traduciendo split 'train' de español a inglés...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/1000 [00:15<4:20:34, 15.65s/it]\u001b[A\n",
      "  0%|          | 2/1000 [00:23<3:03:10, 11.01s/it]\u001b[A\n",
      "  0%|          | 3/1000 [00:29<2:21:55,  8.54s/it]\u001b[A\n",
      "  0%|          | 4/1000 [00:33<1:56:49,  7.04s/it]\u001b[A\n",
      "  0%|          | 5/1000 [00:38<1:45:58,  6.39s/it]\u001b[A\n",
      "  1%|          | 6/1000 [00:44<1:42:37,  6.19s/it]\u001b[A\n",
      "  1%|          | 7/1000 [00:49<1:32:02,  5.56s/it]\u001b[A\n",
      "  1%|          | 8/1000 [00:53<1:27:26,  5.29s/it]\u001b[A\n",
      "  1%|          | 9/1000 [00:59<1:30:09,  5.46s/it]\u001b[A\n",
      "  1%|          | 10/1000 [01:02<1:19:02,  4.79s/it]\u001b[A\n",
      "  1%|          | 11/1000 [01:14<1:54:21,  6.94s/it]\u001b[A\n",
      "  1%|          | 12/1000 [01:21<1:54:24,  6.95s/it]\u001b[A\n",
      "  1%|▏         | 13/1000 [01:34<2:21:58,  8.63s/it]\u001b[A\n",
      "  1%|▏         | 14/1000 [01:40<2:08:14,  7.80s/it]\u001b[A\n",
      "  2%|▏         | 15/1000 [01:54<2:40:50,  9.80s/it]\u001b[A\n",
      "  2%|▏         | 16/1000 [01:59<2:15:34,  8.27s/it]\u001b[A\n",
      "  2%|▏         | 17/1000 [02:03<1:55:19,  7.04s/it]\u001b[A\n",
      "  2%|▏         | 18/1000 [02:08<1:43:45,  6.34s/it]\u001b[A\n",
      "  2%|▏         | 19/1000 [02:12<1:33:35,  5.72s/it]\u001b[A\n",
      "  2%|▏         | 20/1000 [02:16<1:26:00,  5.27s/it]\u001b[A\n",
      "  2%|▏         | 21/1000 [02:25<1:41:22,  6.21s/it]\u001b[A\n",
      "  2%|▏         | 22/1000 [02:34<1:59:29,  7.33s/it]\u001b[A\n",
      "  2%|▏         | 23/1000 [02:39<1:46:43,  6.55s/it]\u001b[A\n",
      "  2%|▏         | 24/1000 [02:43<1:34:06,  5.79s/it]\u001b[A\n",
      "  2%|▎         | 25/1000 [02:48<1:30:38,  5.58s/it]\u001b[A\n",
      "  3%|▎         | 26/1000 [02:52<1:23:26,  5.14s/it]\u001b[A\n",
      "  3%|▎         | 27/1000 [02:57<1:20:36,  4.97s/it]\u001b[A\n",
      "  3%|▎         | 28/1000 [03:00<1:10:36,  4.36s/it]\u001b[A\n",
      "  3%|▎         | 29/1000 [03:04<1:11:27,  4.42s/it]\u001b[A\n",
      "  3%|▎         | 30/1000 [03:10<1:18:19,  4.85s/it]\u001b[A\n",
      "  3%|▎         | 31/1000 [03:15<1:19:13,  4.91s/it]\u001b[A\n",
      "  3%|▎         | 32/1000 [03:19<1:12:04,  4.47s/it]\u001b[A\n",
      "  3%|▎         | 33/1000 [03:23<1:09:59,  4.34s/it]\u001b[A\n",
      "  3%|▎         | 34/1000 [03:28<1:14:31,  4.63s/it]\u001b[A\n",
      "  4%|▎         | 35/1000 [03:33<1:14:34,  4.64s/it]\u001b[A\n",
      "  4%|▎         | 36/1000 [03:38<1:16:15,  4.75s/it]\u001b[A\n",
      "  4%|▎         | 37/1000 [03:44<1:25:28,  5.33s/it]\u001b[A\n",
      "  4%|▍         | 38/1000 [03:49<1:21:44,  5.10s/it]\u001b[A\n",
      "  4%|▍         | 39/1000 [03:56<1:31:27,  5.71s/it]\u001b[A\n",
      "  4%|▍         | 40/1000 [04:01<1:25:12,  5.33s/it]\u001b[A\n",
      "  4%|▍         | 41/1000 [04:04<1:16:46,  4.80s/it]\u001b[A\n",
      "  4%|▍         | 42/1000 [04:09<1:17:48,  4.87s/it]\u001b[A\n",
      "  4%|▍         | 43/1000 [04:15<1:22:58,  5.20s/it]\u001b[A\n",
      "  4%|▍         | 44/1000 [04:20<1:21:18,  5.10s/it]\u001b[A\n",
      "  4%|▍         | 45/1000 [04:24<1:13:45,  4.63s/it]\u001b[A\n",
      "  5%|▍         | 46/1000 [04:33<1:36:39,  6.08s/it]\u001b[A\n",
      "  5%|▍         | 47/1000 [04:38<1:30:38,  5.71s/it]\u001b[A\n",
      "  5%|▍         | 48/1000 [04:43<1:27:14,  5.50s/it]\u001b[A\n",
      "  5%|▍         | 49/1000 [04:48<1:23:05,  5.24s/it]\u001b[A\n",
      "  5%|▌         | 50/1000 [04:52<1:18:16,  4.94s/it]\u001b[A\n",
      "  5%|▌         | 51/1000 [04:55<1:07:51,  4.29s/it]\u001b[A\n",
      "  5%|▌         | 52/1000 [04:59<1:10:37,  4.47s/it]\u001b[A\n",
      "  5%|▌         | 53/1000 [05:03<1:07:28,  4.27s/it]\u001b[A\n",
      "  5%|▌         | 54/1000 [05:08<1:10:04,  4.44s/it]\u001b[A\n",
      "  6%|▌         | 55/1000 [05:13<1:10:00,  4.45s/it]\u001b[A\n",
      "  6%|▌         | 56/1000 [05:17<1:10:36,  4.49s/it]\u001b[A\n",
      "  6%|▌         | 57/1000 [05:20<1:00:52,  3.87s/it]\u001b[A\n",
      "  6%|▌         | 58/1000 [05:25<1:06:35,  4.24s/it]\u001b[A\n",
      "  6%|▌         | 59/1000 [05:29<1:07:29,  4.30s/it]\u001b[A\n",
      "  6%|▌         | 60/1000 [05:34<1:11:38,  4.57s/it]\u001b[A\n",
      "  6%|▌         | 61/1000 [05:39<1:10:47,  4.52s/it]\u001b[A\n",
      "  6%|▌         | 62/1000 [05:43<1:09:14,  4.43s/it]\u001b[A\n",
      "  6%|▋         | 63/1000 [05:48<1:11:34,  4.58s/it]\u001b[A\n",
      "  6%|▋         | 64/1000 [05:53<1:12:41,  4.66s/it]\u001b[A\n",
      "  6%|▋         | 65/1000 [06:00<1:24:53,  5.45s/it]\u001b[A\n",
      "  7%|▋         | 66/1000 [06:05<1:22:37,  5.31s/it]\u001b[A\n",
      "  7%|▋         | 67/1000 [06:10<1:20:26,  5.17s/it]\u001b[A\n",
      "  7%|▋         | 68/1000 [06:15<1:22:01,  5.28s/it]\u001b[A\n",
      "  7%|▋         | 69/1000 [06:21<1:24:41,  5.46s/it]\u001b[A\n",
      "  7%|▋         | 70/1000 [06:26<1:20:33,  5.20s/it]\u001b[A\n",
      "  7%|▋         | 71/1000 [06:32<1:25:18,  5.51s/it]\u001b[A\n",
      "  7%|▋         | 72/1000 [06:39<1:31:58,  5.95s/it]\u001b[A\n",
      "  7%|▋         | 73/1000 [06:44<1:28:25,  5.72s/it]\u001b[A\n",
      "  7%|▋         | 74/1000 [06:50<1:27:51,  5.69s/it]\u001b[A\n",
      "  8%|▊         | 75/1000 [06:55<1:22:50,  5.37s/it]\u001b[A\n",
      "  8%|▊         | 76/1000 [07:02<1:30:18,  5.86s/it]\u001b[A\n",
      "  8%|▊         | 77/1000 [07:07<1:26:38,  5.63s/it]\u001b[A\n",
      "  8%|▊         | 78/1000 [07:11<1:21:42,  5.32s/it]\u001b[A\n",
      "  8%|▊         | 79/1000 [07:16<1:20:32,  5.25s/it]\u001b[A\n",
      "  8%|▊         | 80/1000 [07:21<1:20:00,  5.22s/it]\u001b[A\n",
      "  8%|▊         | 81/1000 [07:30<1:34:03,  6.14s/it]\u001b[A\n",
      "  8%|▊         | 82/1000 [07:34<1:26:48,  5.67s/it]\u001b[A\n",
      "  8%|▊         | 83/1000 [07:39<1:21:18,  5.32s/it]\u001b[A\n",
      "  8%|▊         | 84/1000 [07:44<1:22:35,  5.41s/it]\u001b[A\n",
      "  8%|▊         | 85/1000 [07:49<1:17:42,  5.10s/it]\u001b[A\n",
      "  9%|▊         | 86/1000 [07:52<1:11:12,  4.67s/it]\u001b[A\n",
      "  9%|▊         | 87/1000 [07:58<1:16:38,  5.04s/it]\u001b[A\n",
      "  9%|▉         | 88/1000 [08:03<1:15:10,  4.95s/it]\u001b[A\n",
      "  9%|▉         | 89/1000 [08:07<1:11:43,  4.72s/it]\u001b[A\n",
      "  9%|▉         | 90/1000 [08:12<1:10:04,  4.62s/it]\u001b[A\n",
      "  9%|▉         | 91/1000 [08:16<1:09:30,  4.59s/it]\u001b[A\n",
      "  9%|▉         | 92/1000 [08:22<1:13:13,  4.84s/it]\u001b[A\n",
      "  9%|▉         | 93/1000 [08:26<1:10:53,  4.69s/it]\u001b[A\n",
      "  9%|▉         | 94/1000 [08:30<1:09:05,  4.58s/it]\u001b[A\n",
      " 10%|▉         | 95/1000 [08:33<1:02:35,  4.15s/it]\u001b[A\n",
      " 10%|▉         | 96/1000 [08:37<59:47,  3.97s/it]  \u001b[A\n",
      " 10%|▉         | 97/1000 [08:43<1:09:10,  4.60s/it]\u001b[A\n",
      " 10%|▉         | 98/1000 [08:49<1:17:32,  5.16s/it]\u001b[A\n",
      " 10%|▉         | 99/1000 [08:54<1:14:14,  4.94s/it]\u001b[A\n",
      " 10%|█         | 100/1000 [08:58<1:10:58,  4.73s/it]\u001b[A\n",
      " 10%|█         | 101/1000 [09:03<1:11:55,  4.80s/it]\u001b[A\n",
      " 10%|█         | 102/1000 [09:08<1:11:15,  4.76s/it]\u001b[A\n",
      " 10%|█         | 103/1000 [09:11<1:03:13,  4.23s/it]\u001b[A\n",
      " 10%|█         | 104/1000 [09:15<1:05:00,  4.35s/it]\u001b[A\n",
      " 10%|█         | 105/1000 [09:18<56:44,  3.80s/it]  \u001b[A\n",
      " 11%|█         | 106/1000 [09:24<1:05:57,  4.43s/it]\u001b[A\n",
      " 11%|█         | 107/1000 [09:29<1:08:46,  4.62s/it]\u001b[A\n",
      " 11%|█         | 108/1000 [09:34<1:11:30,  4.81s/it]\u001b[A\n",
      " 11%|█         | 109/1000 [09:45<1:36:10,  6.48s/it]\u001b[A\n",
      " 11%|█         | 110/1000 [09:49<1:28:07,  5.94s/it]\u001b[A\n",
      " 11%|█         | 111/1000 [09:56<1:31:04,  6.15s/it]\u001b[A\n",
      " 11%|█         | 112/1000 [10:01<1:24:41,  5.72s/it]\u001b[A\n",
      " 11%|█▏        | 113/1000 [10:04<1:16:25,  5.17s/it]\u001b[A\n",
      " 11%|█▏        | 114/1000 [10:10<1:17:04,  5.22s/it]\u001b[A\n",
      " 12%|█▏        | 115/1000 [10:17<1:25:41,  5.81s/it]\u001b[A\n",
      " 12%|█▏        | 116/1000 [10:22<1:22:51,  5.62s/it]\u001b[A\n",
      " 12%|█▏        | 117/1000 [10:27<1:17:35,  5.27s/it]\u001b[A\n",
      " 12%|█▏        | 118/1000 [10:31<1:15:14,  5.12s/it]\u001b[A\n",
      " 12%|█▏        | 119/1000 [10:37<1:15:46,  5.16s/it]\u001b[A\n",
      " 12%|█▏        | 120/1000 [10:40<1:06:08,  4.51s/it]\u001b[A\n",
      " 12%|█▏        | 121/1000 [10:45<1:08:48,  4.70s/it]\u001b[A\n",
      " 12%|█▏        | 122/1000 [10:48<1:04:26,  4.40s/it]\u001b[A\n",
      " 12%|█▏        | 123/1000 [10:51<58:12,  3.98s/it]  \u001b[A\n",
      " 12%|█▏        | 124/1000 [10:58<1:08:48,  4.71s/it]\u001b[A\n",
      " 12%|█▎        | 125/1000 [11:04<1:16:20,  5.24s/it]\u001b[A\n",
      " 13%|█▎        | 126/1000 [11:07<1:04:54,  4.46s/it]\u001b[A\n",
      " 13%|█▎        | 127/1000 [11:12<1:08:15,  4.69s/it]\u001b[A\n",
      " 13%|█▎        | 128/1000 [11:18<1:13:33,  5.06s/it]\u001b[A\n",
      " 13%|█▎        | 129/1000 [11:24<1:15:33,  5.20s/it]\u001b[A\n",
      " 13%|█▎        | 130/1000 [11:28<1:11:37,  4.94s/it]\u001b[A\n",
      " 13%|█▎        | 131/1000 [11:33<1:10:46,  4.89s/it]\u001b[A\n",
      " 13%|█▎        | 132/1000 [11:40<1:18:45,  5.44s/it]\u001b[A\n",
      " 13%|█▎        | 133/1000 [11:43<1:11:42,  4.96s/it]\u001b[A\n",
      " 13%|█▎        | 134/1000 [11:47<1:06:03,  4.58s/it]\u001b[A\n",
      " 14%|█▎        | 135/1000 [11:52<1:07:47,  4.70s/it]\u001b[A\n",
      " 14%|█▎        | 136/1000 [12:01<1:25:06,  5.91s/it]\u001b[A\n",
      " 14%|█▎        | 137/1000 [12:05<1:17:18,  5.38s/it]\u001b[A\n",
      " 14%|█▍        | 138/1000 [12:12<1:26:21,  6.01s/it]\u001b[A\n",
      " 14%|█▍        | 139/1000 [12:18<1:22:39,  5.76s/it]\u001b[A\n",
      " 14%|█▍        | 140/1000 [12:21<1:13:34,  5.13s/it]\u001b[A\n",
      " 14%|█▍        | 141/1000 [12:26<1:10:57,  4.96s/it]\u001b[A\n",
      " 14%|█▍        | 142/1000 [12:30<1:05:43,  4.60s/it]\u001b[A\n",
      " 14%|█▍        | 143/1000 [12:36<1:12:44,  5.09s/it]\u001b[A\n",
      " 14%|█▍        | 144/1000 [12:41<1:12:34,  5.09s/it]\u001b[A\n",
      " 14%|█▍        | 145/1000 [12:47<1:15:05,  5.27s/it]\u001b[A\n",
      " 15%|█▍        | 146/1000 [12:51<1:11:39,  5.03s/it]\u001b[A\n",
      " 15%|█▍        | 147/1000 [12:56<1:11:01,  5.00s/it]\u001b[A\n",
      " 15%|█▍        | 148/1000 [13:02<1:14:43,  5.26s/it]\u001b[A\n",
      " 15%|█▍        | 149/1000 [13:07<1:13:35,  5.19s/it]\u001b[A\n",
      " 15%|█▌        | 150/1000 [13:14<1:22:37,  5.83s/it]\u001b[A\n",
      " 15%|█▌        | 151/1000 [13:18<1:12:23,  5.12s/it]\u001b[A\n",
      " 15%|█▌        | 152/1000 [13:21<1:05:52,  4.66s/it]\u001b[A\n",
      " 15%|█▌        | 153/1000 [13:24<58:21,  4.13s/it]  \u001b[A\n",
      " 15%|█▌        | 154/1000 [13:28<58:27,  4.15s/it]\u001b[A\n",
      " 16%|█▌        | 155/1000 [13:32<57:50,  4.11s/it]\u001b[A\n",
      " 16%|█▌        | 156/1000 [13:38<1:05:43,  4.67s/it]\u001b[A\n",
      " 16%|█▌        | 157/1000 [13:43<1:05:31,  4.66s/it]\u001b[A\n",
      " 16%|█▌        | 158/1000 [13:48<1:06:06,  4.71s/it]\u001b[A\n",
      " 16%|█▌        | 159/1000 [13:51<1:01:41,  4.40s/it]\u001b[A\n",
      " 16%|█▌        | 160/1000 [13:56<1:03:47,  4.56s/it]\u001b[A\n",
      " 16%|█▌        | 161/1000 [14:01<1:04:33,  4.62s/it]\u001b[A\n",
      " 16%|█▌        | 162/1000 [14:07<1:08:55,  4.94s/it]\u001b[A\n",
      " 16%|█▋        | 163/1000 [14:12<1:08:28,  4.91s/it]\u001b[A\n",
      " 16%|█▋        | 164/1000 [14:15<1:00:55,  4.37s/it]\u001b[A\n",
      " 16%|█▋        | 165/1000 [14:19<1:02:19,  4.48s/it]\u001b[A\n",
      " 17%|█▋        | 166/1000 [14:25<1:04:40,  4.65s/it]\u001b[A\n",
      " 17%|█▋        | 167/1000 [14:30<1:07:37,  4.87s/it]\u001b[A\n",
      " 17%|█▋        | 168/1000 [14:33<1:01:32,  4.44s/it]\u001b[A\n",
      " 17%|█▋        | 169/1000 [14:38<1:01:20,  4.43s/it]\u001b[A\n",
      " 17%|█▋        | 170/1000 [14:42<1:00:27,  4.37s/it]\u001b[A\n",
      " 17%|█▋        | 171/1000 [14:46<1:00:12,  4.36s/it]\u001b[A\n",
      " 17%|█▋        | 172/1000 [14:51<1:01:37,  4.47s/it]\u001b[A\n",
      " 17%|█▋        | 173/1000 [14:55<58:42,  4.26s/it]  \u001b[A\n",
      " 17%|█▋        | 174/1000 [15:00<1:00:25,  4.39s/it]\u001b[A\n",
      " 18%|█▊        | 175/1000 [15:04<1:00:43,  4.42s/it]\u001b[A\n",
      " 18%|█▊        | 176/1000 [15:09<1:02:27,  4.55s/it]\u001b[A\n",
      " 18%|█▊        | 177/1000 [15:13<1:02:07,  4.53s/it]\u001b[A\n",
      " 18%|█▊        | 178/1000 [15:18<1:03:53,  4.66s/it]\u001b[A\n",
      " 18%|█▊        | 179/1000 [15:22<1:01:37,  4.50s/it]\u001b[A\n",
      " 18%|█▊        | 180/1000 [15:25<52:44,  3.86s/it]  \u001b[A\n",
      " 18%|█▊        | 181/1000 [15:30<57:09,  4.19s/it]\u001b[A\n",
      " 18%|█▊        | 182/1000 [15:33<54:08,  3.97s/it]\u001b[A\n",
      " 18%|█▊        | 183/1000 [15:37<54:50,  4.03s/it]\u001b[A\n",
      " 18%|█▊        | 184/1000 [15:41<54:20,  4.00s/it]\u001b[A\n",
      " 18%|█▊        | 185/1000 [15:45<53:16,  3.92s/it]\u001b[A\n",
      " 19%|█▊        | 186/1000 [15:51<1:01:10,  4.51s/it]\u001b[A\n",
      " 19%|█▊        | 187/1000 [15:53<52:56,  3.91s/it]  \u001b[A\n",
      " 19%|█▉        | 188/1000 [15:58<55:00,  4.06s/it]\u001b[A\n",
      " 19%|█▉        | 189/1000 [16:03<57:42,  4.27s/it]\u001b[A\n",
      " 19%|█▉        | 190/1000 [16:06<52:45,  3.91s/it]\u001b[A\n",
      " 19%|█▉        | 191/1000 [16:10<56:21,  4.18s/it]\u001b[A\n",
      " 19%|█▉        | 192/1000 [16:15<58:30,  4.35s/it]\u001b[A\n",
      " 19%|█▉        | 193/1000 [16:20<1:00:34,  4.50s/it]\u001b[A\n",
      " 19%|█▉        | 194/1000 [16:25<1:00:57,  4.54s/it]\u001b[A\n",
      " 20%|█▉        | 195/1000 [16:28<57:31,  4.29s/it]  \u001b[A\n",
      " 20%|█▉        | 196/1000 [16:35<1:06:43,  4.98s/it]\u001b[A\n",
      " 20%|█▉        | 197/1000 [16:41<1:11:45,  5.36s/it]\u001b[A\n",
      " 20%|█▉        | 198/1000 [16:47<1:12:54,  5.45s/it]\u001b[A\n",
      " 20%|█▉        | 199/1000 [16:52<1:10:52,  5.31s/it]\u001b[A\n",
      " 20%|██        | 200/1000 [16:57<1:10:41,  5.30s/it]\u001b[A\n",
      " 20%|██        | 201/1000 [17:01<1:03:26,  4.76s/it]\u001b[A\n",
      " 20%|██        | 202/1000 [17:05<1:01:23,  4.62s/it]\u001b[A\n",
      " 20%|██        | 203/1000 [17:09<57:17,  4.31s/it]  \u001b[A\n",
      " 20%|██        | 204/1000 [17:12<54:29,  4.11s/it]\u001b[A\n",
      " 20%|██        | 205/1000 [17:16<53:55,  4.07s/it]\u001b[A\n",
      " 21%|██        | 206/1000 [17:24<1:10:08,  5.30s/it]\u001b[A\n",
      " 21%|██        | 207/1000 [17:30<1:12:16,  5.47s/it]\u001b[A\n",
      " 21%|██        | 208/1000 [17:34<1:07:21,  5.10s/it]\u001b[A\n",
      " 21%|██        | 209/1000 [17:39<1:06:35,  5.05s/it]\u001b[A\n",
      " 21%|██        | 210/1000 [17:44<1:03:52,  4.85s/it]\u001b[A\n",
      " 21%|██        | 211/1000 [17:47<58:09,  4.42s/it]  \u001b[A\n",
      " 21%|██        | 212/1000 [17:56<1:13:32,  5.60s/it]\u001b[A\n",
      " 21%|██▏       | 213/1000 [18:01<1:12:58,  5.56s/it]\u001b[A\n",
      " 21%|██▏       | 214/1000 [18:07<1:15:46,  5.78s/it]\u001b[A\n",
      " 22%|██▏       | 215/1000 [18:13<1:16:05,  5.82s/it]\u001b[A\n",
      " 22%|██▏       | 216/1000 [18:19<1:16:54,  5.89s/it]\u001b[A\n",
      " 22%|██▏       | 217/1000 [18:24<1:10:45,  5.42s/it]\u001b[A\n",
      " 22%|██▏       | 218/1000 [18:29<1:09:21,  5.32s/it]\u001b[A\n",
      " 22%|██▏       | 219/1000 [18:33<1:04:01,  4.92s/it]\u001b[A\n",
      " 22%|██▏       | 220/1000 [18:38<1:06:49,  5.14s/it]\u001b[A\n",
      " 22%|██▏       | 221/1000 [18:43<1:05:43,  5.06s/it]\u001b[A\n",
      " 22%|██▏       | 222/1000 [18:50<1:11:35,  5.52s/it]\u001b[A\n",
      " 22%|██▏       | 223/1000 [18:55<1:10:13,  5.42s/it]\u001b[A\n",
      " 22%|██▏       | 224/1000 [18:59<1:05:43,  5.08s/it]\u001b[A\n",
      " 22%|██▎       | 225/1000 [19:03<1:02:11,  4.82s/it]\u001b[A\n",
      " 23%|██▎       | 226/1000 [19:08<1:01:35,  4.77s/it]\u001b[A\n",
      " 23%|██▎       | 227/1000 [19:12<59:37,  4.63s/it]  \u001b[A\n",
      " 23%|██▎       | 228/1000 [19:14<48:49,  3.79s/it]\u001b[A\n",
      " 23%|██▎       | 229/1000 [19:18<49:34,  3.86s/it]\u001b[A\n",
      " 23%|██▎       | 230/1000 [19:23<51:24,  4.01s/it]\u001b[A\n",
      " 23%|██▎       | 231/1000 [19:28<55:21,  4.32s/it]\u001b[A\n",
      " 23%|██▎       | 232/1000 [19:32<55:34,  4.34s/it]\u001b[A\n",
      " 23%|██▎       | 233/1000 [19:37<58:56,  4.61s/it]\u001b[A\n",
      " 23%|██▎       | 234/1000 [19:42<57:27,  4.50s/it]\u001b[A\n",
      " 24%|██▎       | 235/1000 [19:46<58:36,  4.60s/it]\u001b[A\n",
      " 24%|██▎       | 236/1000 [19:51<57:24,  4.51s/it]\u001b[A\n",
      " 24%|██▎       | 237/1000 [19:57<1:02:48,  4.94s/it]\u001b[A\n",
      " 24%|██▍       | 238/1000 [20:01<1:01:33,  4.85s/it]\u001b[A\n",
      " 24%|██▍       | 239/1000 [20:04<54:22,  4.29s/it]  \u001b[A\n",
      " 24%|██▍       | 240/1000 [20:09<55:50,  4.41s/it]\u001b[A\n",
      " 24%|██▍       | 241/1000 [20:14<59:00,  4.67s/it]\u001b[A\n",
      " 24%|██▍       | 242/1000 [20:19<58:49,  4.66s/it]\u001b[A\n",
      " 24%|██▍       | 243/1000 [20:25<1:05:59,  5.23s/it]\u001b[A\n",
      " 24%|██▍       | 244/1000 [20:29<59:19,  4.71s/it]  \u001b[A\n",
      " 24%|██▍       | 245/1000 [20:33<56:54,  4.52s/it]\u001b[A\n",
      " 25%|██▍       | 246/1000 [20:37<55:53,  4.45s/it]\u001b[A\n",
      " 25%|██▍       | 247/1000 [20:43<59:14,  4.72s/it]\u001b[A\n",
      " 25%|██▍       | 248/1000 [20:47<58:55,  4.70s/it]\u001b[A\n",
      " 25%|██▍       | 249/1000 [20:52<1:00:08,  4.81s/it]\u001b[A\n",
      " 25%|██▌       | 250/1000 [20:56<55:56,  4.47s/it]  \u001b[A\n",
      " 25%|██▌       | 251/1000 [21:01<57:35,  4.61s/it]\u001b[A\n",
      " 25%|██▌       | 252/1000 [21:06<57:48,  4.64s/it]\u001b[A\n",
      " 25%|██▌       | 253/1000 [21:11<58:36,  4.71s/it]\u001b[A\n",
      " 25%|██▌       | 254/1000 [21:15<56:43,  4.56s/it]\u001b[A\n",
      " 26%|██▌       | 255/1000 [21:17<48:46,  3.93s/it]\u001b[A\n",
      " 26%|██▌       | 256/1000 [21:22<50:05,  4.04s/it]\u001b[A\n",
      " 26%|██▌       | 257/1000 [21:26<52:11,  4.22s/it]\u001b[A\n",
      " 26%|██▌       | 258/1000 [21:31<53:33,  4.33s/it]\u001b[A\n",
      " 26%|██▌       | 259/1000 [21:35<53:00,  4.29s/it]\u001b[A\n",
      " 26%|██▌       | 260/1000 [21:39<52:59,  4.30s/it]\u001b[A\n",
      " 26%|██▌       | 261/1000 [21:44<55:00,  4.47s/it]\u001b[A\n",
      " 26%|██▌       | 262/1000 [21:49<57:43,  4.69s/it]\u001b[A\n",
      " 26%|██▋       | 263/1000 [21:56<1:05:59,  5.37s/it]\u001b[A\n",
      " 26%|██▋       | 264/1000 [22:01<1:02:04,  5.06s/it]\u001b[A\n",
      " 26%|██▋       | 265/1000 [22:07<1:06:30,  5.43s/it]\u001b[A\n",
      " 27%|██▋       | 266/1000 [22:14<1:14:08,  6.06s/it]\u001b[A\n",
      " 27%|██▋       | 267/1000 [22:17<1:00:33,  4.96s/it]\u001b[A\n",
      " 27%|██▋       | 268/1000 [22:21<57:30,  4.71s/it]  \u001b[A\n",
      " 27%|██▋       | 269/1000 [22:25<55:20,  4.54s/it]\u001b[A\n",
      " 27%|██▋       | 270/1000 [22:30<56:44,  4.66s/it]\u001b[A\n",
      " 27%|██▋       | 271/1000 [22:34<55:11,  4.54s/it]\u001b[A\n",
      " 27%|██▋       | 272/1000 [22:39<55:09,  4.55s/it]\u001b[A\n",
      " 27%|██▋       | 273/1000 [22:44<55:33,  4.59s/it]\u001b[A\n",
      " 27%|██▋       | 274/1000 [22:49<57:48,  4.78s/it]\u001b[A\n",
      " 28%|██▊       | 275/1000 [22:52<51:14,  4.24s/it]\u001b[A\n",
      " 28%|██▊       | 276/1000 [22:57<53:54,  4.47s/it]\u001b[A\n",
      " 28%|██▊       | 277/1000 [23:01<51:51,  4.30s/it]\u001b[A\n",
      " 28%|██▊       | 278/1000 [23:05<53:12,  4.42s/it]\u001b[A\n",
      " 28%|██▊       | 279/1000 [23:08<48:16,  4.02s/it]\u001b[A\n",
      " 28%|██▊       | 280/1000 [23:13<49:55,  4.16s/it]\u001b[A\n",
      " 28%|██▊       | 281/1000 [23:18<54:24,  4.54s/it]\u001b[A\n",
      " 28%|██▊       | 282/1000 [23:25<1:00:58,  5.10s/it]\u001b[A\n",
      " 28%|██▊       | 283/1000 [23:29<56:29,  4.73s/it]  \u001b[A\n",
      " 28%|██▊       | 284/1000 [23:33<56:41,  4.75s/it]\u001b[A\n",
      " 28%|██▊       | 285/1000 [23:38<56:08,  4.71s/it]\u001b[A\n",
      " 29%|██▊       | 286/1000 [23:43<57:36,  4.84s/it]\u001b[A\n",
      " 29%|██▊       | 287/1000 [23:49<1:00:17,  5.07s/it]\u001b[A\n",
      " 29%|██▉       | 288/1000 [23:53<57:21,  4.83s/it]  \u001b[A\n",
      " 29%|██▉       | 289/1000 [23:59<1:01:29,  5.19s/it]\u001b[A\n",
      " 29%|██▉       | 290/1000 [24:03<57:37,  4.87s/it]  \u001b[A\n",
      " 29%|██▉       | 291/1000 [24:07<54:54,  4.65s/it]\u001b[A\n",
      " 29%|██▉       | 292/1000 [24:13<58:54,  4.99s/it]\u001b[A\n",
      " 29%|██▉       | 293/1000 [24:18<58:47,  4.99s/it]\u001b[A\n",
      " 29%|██▉       | 294/1000 [24:24<1:01:49,  5.25s/it]\u001b[A\n",
      " 30%|██▉       | 295/1000 [25:00<2:50:08, 14.48s/it]\u001b[A\n",
      " 30%|██▉       | 296/1000 [25:05<2:15:56, 11.59s/it]\u001b[A\n",
      " 30%|██▉       | 297/1000 [25:10<1:52:39,  9.62s/it]\u001b[A\n",
      " 30%|██▉       | 298/1000 [25:16<1:38:48,  8.45s/it]\u001b[A\n",
      " 30%|██▉       | 299/1000 [25:20<1:23:28,  7.15s/it]\u001b[A\n",
      " 30%|███       | 300/1000 [25:25<1:15:31,  6.47s/it]\u001b[A\n",
      " 30%|███       | 301/1000 [25:29<1:09:45,  5.99s/it]\u001b[A\n",
      " 30%|███       | 302/1000 [25:34<1:03:10,  5.43s/it]\u001b[A\n",
      " 30%|███       | 303/1000 [25:38<58:01,  4.99s/it]  \u001b[A\n",
      " 30%|███       | 304/1000 [25:40<49:41,  4.28s/it]\u001b[A\n",
      " 30%|███       | 305/1000 [25:44<46:30,  4.01s/it]\u001b[A\n",
      " 31%|███       | 306/1000 [25:48<49:00,  4.24s/it]\u001b[A\n",
      " 31%|███       | 307/1000 [25:53<50:08,  4.34s/it]\u001b[A\n",
      " 31%|███       | 308/1000 [25:56<46:58,  4.07s/it]\u001b[A\n",
      " 31%|███       | 309/1000 [26:01<48:14,  4.19s/it]\u001b[A\n",
      " 31%|███       | 310/1000 [26:06<52:19,  4.55s/it]\u001b[A\n",
      " 31%|███       | 311/1000 [26:09<47:18,  4.12s/it]\u001b[A\n",
      " 31%|███       | 312/1000 [26:14<50:30,  4.40s/it]\u001b[A\n",
      " 31%|███▏      | 313/1000 [26:19<51:34,  4.50s/it]\u001b[A\n",
      " 31%|███▏      | 314/1000 [26:23<48:36,  4.25s/it]\u001b[A\n",
      " 32%|███▏      | 315/1000 [26:25<42:51,  3.75s/it]\u001b[A\n",
      " 32%|███▏      | 316/1000 [26:28<39:10,  3.44s/it]\u001b[A\n",
      " 32%|███▏      | 317/1000 [26:31<36:12,  3.18s/it]\u001b[A\n",
      " 32%|███▏      | 318/1000 [26:35<40:13,  3.54s/it]\u001b[A\n",
      " 32%|███▏      | 319/1000 [26:39<39:58,  3.52s/it]\u001b[A\n",
      " 32%|███▏      | 320/1000 [26:46<54:03,  4.77s/it]\u001b[A\n",
      " 32%|███▏      | 321/1000 [26:50<52:07,  4.61s/it]\u001b[A\n",
      " 32%|███▏      | 322/1000 [26:54<46:50,  4.15s/it]\u001b[A\n",
      " 32%|███▏      | 323/1000 [26:59<50:42,  4.49s/it]\u001b[A\n",
      " 32%|███▏      | 324/1000 [27:07<1:04:31,  5.73s/it]\u001b[A\n",
      " 32%|███▎      | 325/1000 [27:13<1:05:31,  5.83s/it]\u001b[A\n",
      " 33%|███▎      | 326/1000 [27:23<1:19:18,  7.06s/it]\u001b[A\n",
      " 33%|███▎      | 327/1000 [27:28<1:09:48,  6.22s/it]\u001b[A\n",
      " 33%|███▎      | 328/1000 [27:34<1:08:51,  6.15s/it]\u001b[A\n",
      " 33%|███▎      | 329/1000 [27:39<1:04:57,  5.81s/it]\u001b[A\n",
      " 33%|███▎      | 330/1000 [27:43<1:00:09,  5.39s/it]\u001b[A\n",
      " 33%|███▎      | 331/1000 [27:48<58:58,  5.29s/it]  \u001b[A\n",
      " 33%|███▎      | 332/1000 [27:53<55:51,  5.02s/it]\u001b[A\n",
      " 33%|███▎      | 333/1000 [27:57<52:42,  4.74s/it]\u001b[A\n",
      " 33%|███▎      | 334/1000 [28:02<53:28,  4.82s/it]\u001b[A\n",
      " 34%|███▎      | 335/1000 [28:06<51:17,  4.63s/it]\u001b[A\n",
      " 34%|███▎      | 336/1000 [28:09<46:21,  4.19s/it]\u001b[A\n",
      " 34%|███▎      | 337/1000 [28:14<48:50,  4.42s/it]\u001b[A\n",
      " 34%|███▍      | 338/1000 [28:19<50:01,  4.53s/it]\u001b[A\n",
      " 34%|███▍      | 339/1000 [28:23<48:10,  4.37s/it]\u001b[A\n",
      " 34%|███▍      | 340/1000 [28:29<54:24,  4.95s/it]\u001b[A\n",
      " 34%|███▍      | 341/1000 [28:34<54:17,  4.94s/it]\u001b[A\n",
      " 34%|███▍      | 342/1000 [28:39<53:52,  4.91s/it]\u001b[A\n",
      " 34%|███▍      | 343/1000 [28:44<54:20,  4.96s/it]\u001b[A\n",
      " 34%|███▍      | 344/1000 [28:49<54:18,  4.97s/it]\u001b[A\n",
      " 34%|███▍      | 345/1000 [28:53<50:08,  4.59s/it]\u001b[A\n",
      " 35%|███▍      | 346/1000 [28:57<50:32,  4.64s/it]\u001b[A\n",
      " 35%|███▍      | 347/1000 [29:02<49:58,  4.59s/it]\u001b[A\n",
      " 35%|███▍      | 348/1000 [29:07<52:04,  4.79s/it]\u001b[A\n",
      " 35%|███▍      | 349/1000 [29:12<51:38,  4.76s/it]\u001b[A\n",
      " 35%|███▌      | 350/1000 [29:16<51:04,  4.71s/it]\u001b[A\n",
      " 35%|███▌      | 351/1000 [29:19<45:10,  4.18s/it]\u001b[A\n",
      " 35%|███▌      | 352/1000 [29:24<45:46,  4.24s/it]\u001b[A\n",
      " 35%|███▌      | 353/1000 [29:28<45:52,  4.25s/it]\u001b[A\n",
      " 35%|███▌      | 354/1000 [29:33<48:11,  4.48s/it]\u001b[A\n",
      " 36%|███▌      | 355/1000 [29:39<53:58,  5.02s/it]\u001b[A\n",
      " 36%|███▌      | 356/1000 [29:44<51:49,  4.83s/it]\u001b[A\n",
      " 36%|███▌      | 357/1000 [29:46<45:15,  4.22s/it]\u001b[A\n",
      " 36%|███▌      | 358/1000 [29:51<45:16,  4.23s/it]\u001b[A\n",
      " 36%|███▌      | 359/1000 [29:54<41:57,  3.93s/it]\u001b[A\n",
      " 36%|███▌      | 360/1000 [29:59<46:36,  4.37s/it]\u001b[A\n",
      " 36%|███▌      | 361/1000 [30:03<45:09,  4.24s/it]\u001b[A\n",
      " 36%|███▌      | 362/1000 [30:08<47:22,  4.46s/it]\u001b[A\n",
      " 36%|███▋      | 363/1000 [30:14<52:39,  4.96s/it]\u001b[A\n",
      " 36%|███▋      | 364/1000 [30:18<49:44,  4.69s/it]\u001b[A\n",
      " 36%|███▋      | 365/1000 [30:24<52:58,  5.01s/it]\u001b[A\n",
      " 37%|███▋      | 366/1000 [30:29<53:20,  5.05s/it]\u001b[A\n",
      " 37%|███▋      | 367/1000 [30:32<45:51,  4.35s/it]\u001b[A\n",
      " 37%|███▋      | 368/1000 [30:37<47:22,  4.50s/it]\u001b[A\n",
      " 37%|███▋      | 369/1000 [30:42<48:15,  4.59s/it]\u001b[A\n",
      " 37%|███▋      | 370/1000 [30:46<48:23,  4.61s/it]\u001b[A\n",
      " 37%|███▋      | 371/1000 [30:51<49:44,  4.75s/it]\u001b[A\n",
      " 37%|███▋      | 372/1000 [30:56<49:38,  4.74s/it]\u001b[A\n",
      " 37%|███▋      | 373/1000 [30:59<44:50,  4.29s/it]\u001b[A\n",
      " 37%|███▋      | 374/1000 [31:05<50:26,  4.84s/it]\u001b[A\n",
      " 38%|███▊      | 375/1000 [31:10<48:35,  4.67s/it]\u001b[A\n",
      " 38%|███▊      | 376/1000 [31:17<55:59,  5.38s/it]\u001b[A\n",
      " 38%|███▊      | 377/1000 [31:21<53:39,  5.17s/it]\u001b[A\n",
      " 38%|███▊      | 378/1000 [31:26<52:32,  5.07s/it]\u001b[A\n",
      " 38%|███▊      | 379/1000 [31:31<51:41,  4.99s/it]\u001b[A\n",
      " 38%|███▊      | 380/1000 [31:38<56:26,  5.46s/it]\u001b[A\n",
      " 38%|███▊      | 381/1000 [31:42<53:45,  5.21s/it]\u001b[A\n",
      " 38%|███▊      | 382/1000 [31:47<53:11,  5.16s/it]\u001b[A\n",
      " 38%|███▊      | 383/1000 [31:52<51:29,  5.01s/it]\u001b[A\n",
      " 38%|███▊      | 384/1000 [32:02<1:06:36,  6.49s/it]\u001b[A\n",
      " 38%|███▊      | 385/1000 [32:07<1:01:34,  6.01s/it]\u001b[A\n",
      " 39%|███▊      | 386/1000 [32:12<58:04,  5.67s/it]  \u001b[A\n",
      " 39%|███▊      | 387/1000 [32:17<57:31,  5.63s/it]\u001b[A\n",
      " 39%|███▉      | 388/1000 [32:24<59:50,  5.87s/it]\u001b[A\n",
      " 39%|███▉      | 389/1000 [32:29<56:44,  5.57s/it]\u001b[A\n",
      " 39%|███▉      | 390/1000 [32:34<55:28,  5.46s/it]\u001b[A\n",
      " 39%|███▉      | 391/1000 [32:37<48:10,  4.75s/it]\u001b[A\n",
      " 39%|███▉      | 392/1000 [32:42<48:39,  4.80s/it]\u001b[A\n",
      " 39%|███▉      | 393/1000 [32:47<48:28,  4.79s/it]\u001b[A\n",
      " 39%|███▉      | 394/1000 [32:51<48:02,  4.76s/it]\u001b[A\n",
      " 40%|███▉      | 395/1000 [32:56<47:33,  4.72s/it]\u001b[A\n",
      " 40%|███▉      | 396/1000 [33:00<45:22,  4.51s/it]\u001b[A\n",
      " 40%|███▉      | 397/1000 [33:04<44:53,  4.47s/it]\u001b[A\n",
      " 40%|███▉      | 398/1000 [33:08<41:59,  4.18s/it]\u001b[A\n",
      " 40%|███▉      | 399/1000 [33:13<45:08,  4.51s/it]\u001b[A\n",
      " 40%|████      | 400/1000 [33:18<46:38,  4.66s/it]\u001b[A\n",
      " 40%|████      | 401/1000 [33:22<46:03,  4.61s/it]\u001b[A\n",
      " 40%|████      | 402/1000 [33:28<48:04,  4.82s/it]\u001b[A\n",
      " 40%|████      | 403/1000 [33:31<42:01,  4.22s/it]\u001b[A\n",
      " 40%|████      | 404/1000 [33:37<49:06,  4.94s/it]\u001b[A\n",
      " 40%|████      | 405/1000 [33:42<47:21,  4.78s/it]\u001b[A\n",
      " 41%|████      | 406/1000 [33:47<48:33,  4.90s/it]\u001b[A\n",
      " 41%|████      | 407/1000 [33:52<47:51,  4.84s/it]\u001b[A\n",
      " 41%|████      | 408/1000 [33:56<46:43,  4.74s/it]\u001b[A\n",
      " 41%|████      | 409/1000 [34:00<44:40,  4.54s/it]\u001b[A\n",
      " 41%|████      | 410/1000 [34:05<45:23,  4.62s/it]\u001b[A\n",
      " 41%|████      | 411/1000 [34:10<46:34,  4.74s/it]\u001b[A\n",
      " 41%|████      | 412/1000 [34:16<50:25,  5.15s/it]\u001b[A\n",
      " 41%|████▏     | 413/1000 [34:21<48:27,  4.95s/it]\u001b[A\n",
      " 41%|████▏     | 414/1000 [34:23<41:32,  4.25s/it]\u001b[A\n",
      " 42%|████▏     | 415/1000 [34:27<41:39,  4.27s/it]\u001b[A\n",
      " 42%|████▏     | 416/1000 [34:31<40:50,  4.20s/it]\u001b[A\n",
      " 42%|████▏     | 417/1000 [34:37<43:08,  4.44s/it]\u001b[A\n",
      " 42%|████▏     | 418/1000 [34:41<43:47,  4.51s/it]\u001b[A\n",
      " 42%|████▏     | 419/1000 [34:46<44:36,  4.61s/it]\u001b[A\n",
      " 42%|████▏     | 420/1000 [34:50<41:19,  4.27s/it]\u001b[A\n",
      " 42%|████▏     | 421/1000 [34:54<41:30,  4.30s/it]\u001b[A\n",
      " 42%|████▏     | 422/1000 [34:59<45:01,  4.67s/it]\u001b[A\n",
      " 42%|████▏     | 423/1000 [35:05<47:19,  4.92s/it]\u001b[A\n",
      " 42%|████▏     | 424/1000 [35:10<47:45,  4.97s/it]\u001b[A\n",
      " 42%|████▎     | 425/1000 [35:15<47:32,  4.96s/it]\u001b[A\n",
      " 43%|████▎     | 426/1000 [35:19<44:32,  4.66s/it]\u001b[A\n",
      " 43%|████▎     | 427/1000 [35:21<38:16,  4.01s/it]\u001b[A\n",
      " 43%|████▎     | 428/1000 [35:24<34:27,  3.62s/it]\u001b[A\n",
      " 43%|████▎     | 429/1000 [35:29<38:13,  4.02s/it]\u001b[A\n",
      " 43%|████▎     | 430/1000 [35:33<38:07,  4.01s/it]\u001b[A\n",
      " 43%|████▎     | 431/1000 [35:38<40:00,  4.22s/it]\u001b[A\n",
      " 43%|████▎     | 432/1000 [35:43<43:08,  4.56s/it]\u001b[A\n",
      " 43%|████▎     | 433/1000 [35:54<1:01:50,  6.54s/it]\u001b[A\n",
      " 43%|████▎     | 434/1000 [36:00<59:52,  6.35s/it]  \u001b[A\n",
      " 44%|████▎     | 435/1000 [36:05<55:34,  5.90s/it]\u001b[A\n",
      " 44%|████▎     | 436/1000 [36:09<51:20,  5.46s/it]\u001b[A\n",
      " 44%|████▎     | 437/1000 [36:16<55:34,  5.92s/it]\u001b[A\n",
      " 44%|████▍     | 438/1000 [36:20<48:28,  5.18s/it]\u001b[A\n",
      " 44%|████▍     | 439/1000 [36:25<47:53,  5.12s/it]\u001b[A\n",
      " 44%|████▍     | 440/1000 [36:30<48:31,  5.20s/it]\u001b[A\n",
      " 44%|████▍     | 441/1000 [36:35<46:44,  5.02s/it]\u001b[A\n",
      " 44%|████▍     | 442/1000 [36:36<36:59,  3.98s/it]\u001b[A\n",
      " 44%|████▍     | 443/1000 [36:46<53:10,  5.73s/it]\u001b[A\n",
      " 44%|████▍     | 444/1000 [36:51<51:25,  5.55s/it]\u001b[A\n",
      " 44%|████▍     | 445/1000 [36:56<47:38,  5.15s/it]\u001b[A\n",
      " 45%|████▍     | 446/1000 [37:00<45:05,  4.88s/it]\u001b[A\n",
      " 45%|████▍     | 447/1000 [37:04<42:21,  4.60s/it]\u001b[A\n",
      " 45%|████▍     | 448/1000 [37:09<43:12,  4.70s/it]\u001b[A\n",
      " 45%|████▍     | 449/1000 [37:15<47:09,  5.14s/it]\u001b[A\n",
      " 45%|████▌     | 450/1000 [37:18<42:31,  4.64s/it]\u001b[A\n",
      " 45%|████▌     | 451/1000 [37:23<42:04,  4.60s/it]\u001b[A\n",
      " 45%|████▌     | 452/1000 [37:27<40:53,  4.48s/it]\u001b[A\n",
      " 45%|████▌     | 453/1000 [37:34<47:01,  5.16s/it]\u001b[A\n",
      " 45%|████▌     | 454/1000 [37:39<46:06,  5.07s/it]\u001b[A\n",
      " 46%|████▌     | 455/1000 [37:43<43:59,  4.84s/it]\u001b[A\n",
      " 46%|████▌     | 456/1000 [37:46<40:13,  4.44s/it]\u001b[A\n",
      " 46%|████▌     | 457/1000 [37:51<40:45,  4.50s/it]\u001b[A\n",
      " 46%|████▌     | 458/1000 [37:56<42:21,  4.69s/it]\u001b[A\n",
      " 46%|████▌     | 459/1000 [38:01<43:40,  4.84s/it]\u001b[A\n",
      " 46%|████▌     | 460/1000 [38:06<43:47,  4.86s/it]\u001b[A\n",
      " 46%|████▌     | 461/1000 [38:13<47:21,  5.27s/it]\u001b[A\n",
      " 46%|████▌     | 462/1000 [38:16<43:34,  4.86s/it]\u001b[A\n",
      " 46%|████▋     | 463/1000 [38:22<45:03,  5.03s/it]\u001b[A\n",
      " 46%|████▋     | 464/1000 [38:27<45:26,  5.09s/it]\u001b[A\n",
      " 46%|████▋     | 465/1000 [38:31<43:24,  4.87s/it]\u001b[A\n",
      " 47%|████▋     | 466/1000 [38:35<40:31,  4.55s/it]\u001b[A\n",
      " 47%|████▋     | 467/1000 [38:38<36:42,  4.13s/it]\u001b[A\n",
      " 47%|████▋     | 468/1000 [38:43<37:41,  4.25s/it]\u001b[A\n",
      " 47%|████▋     | 469/1000 [38:48<38:39,  4.37s/it]\u001b[A\n",
      " 47%|████▋     | 470/1000 [38:53<40:36,  4.60s/it]\u001b[A\n",
      " 47%|████▋     | 471/1000 [39:00<46:32,  5.28s/it]\u001b[A\n",
      " 47%|████▋     | 472/1000 [39:09<56:56,  6.47s/it]\u001b[A\n",
      " 47%|████▋     | 473/1000 [39:13<51:56,  5.91s/it]\u001b[A\n",
      " 47%|████▋     | 474/1000 [39:19<49:46,  5.68s/it]\u001b[A\n",
      " 48%|████▊     | 475/1000 [39:22<44:23,  5.07s/it]\u001b[A\n",
      " 48%|████▊     | 476/1000 [39:28<44:51,  5.14s/it]\u001b[A\n",
      " 48%|████▊     | 477/1000 [39:32<41:45,  4.79s/it]\u001b[A\n",
      " 48%|████▊     | 478/1000 [39:36<40:33,  4.66s/it]\u001b[A\n",
      " 48%|████▊     | 479/1000 [39:38<34:36,  3.99s/it]\u001b[A\n",
      " 48%|████▊     | 480/1000 [39:44<38:28,  4.44s/it]\u001b[A\n",
      " 48%|████▊     | 481/1000 [39:48<36:48,  4.26s/it]\u001b[A\n",
      " 48%|████▊     | 482/1000 [39:53<38:40,  4.48s/it]\u001b[A\n",
      " 48%|████▊     | 483/1000 [39:59<42:44,  4.96s/it]\u001b[A\n",
      " 48%|████▊     | 484/1000 [40:04<43:05,  5.01s/it]\u001b[A\n",
      " 48%|████▊     | 485/1000 [40:08<42:00,  4.89s/it]\u001b[A\n",
      " 49%|████▊     | 486/1000 [40:13<40:47,  4.76s/it]\u001b[A\n",
      " 49%|████▊     | 487/1000 [40:18<41:47,  4.89s/it]\u001b[A\n",
      " 49%|████▉     | 488/1000 [40:23<41:53,  4.91s/it]\u001b[A\n",
      " 49%|████▉     | 489/1000 [40:28<41:11,  4.84s/it]\u001b[A\n",
      " 49%|████▉     | 490/1000 [40:33<41:37,  4.90s/it]\u001b[A\n",
      " 49%|████▉     | 491/1000 [40:37<40:04,  4.72s/it]\u001b[A\n",
      " 49%|████▉     | 492/1000 [40:40<34:45,  4.11s/it]\u001b[A\n",
      " 49%|████▉     | 493/1000 [40:45<38:02,  4.50s/it]\u001b[A\n",
      " 49%|████▉     | 494/1000 [40:49<37:03,  4.39s/it]\u001b[A\n",
      " 50%|████▉     | 495/1000 [40:53<36:27,  4.33s/it]\u001b[A\n",
      " 50%|████▉     | 496/1000 [40:56<32:12,  3.83s/it]\u001b[A\n",
      " 50%|████▉     | 497/1000 [41:01<34:44,  4.14s/it]\u001b[A\n",
      " 50%|████▉     | 498/1000 [41:05<34:31,  4.13s/it]\u001b[A\n",
      " 50%|████▉     | 499/1000 [41:10<36:40,  4.39s/it]\u001b[A\n",
      " 50%|█████     | 500/1000 [41:15<37:33,  4.51s/it]\u001b[A\n",
      " 50%|█████     | 501/1000 [41:19<36:50,  4.43s/it]\u001b[A\n",
      " 50%|█████     | 502/1000 [41:23<35:48,  4.31s/it]\u001b[A\n",
      " 50%|█████     | 503/1000 [41:28<37:14,  4.50s/it]\u001b[A\n",
      " 50%|█████     | 504/1000 [41:33<38:10,  4.62s/it]\u001b[A\n",
      " 50%|█████     | 505/1000 [41:40<42:52,  5.20s/it]\u001b[A\n",
      " 51%|█████     | 506/1000 [41:44<41:17,  5.01s/it]\u001b[A\n",
      " 51%|█████     | 507/1000 [41:49<41:31,  5.05s/it]\u001b[A\n",
      " 51%|█████     | 508/1000 [41:53<38:37,  4.71s/it]\u001b[A\n",
      " 51%|█████     | 509/1000 [41:58<39:02,  4.77s/it]\u001b[A\n",
      " 51%|█████     | 510/1000 [42:03<39:20,  4.82s/it]\u001b[A\n",
      " 51%|█████     | 511/1000 [42:07<37:37,  4.62s/it]\u001b[A\n",
      " 51%|█████     | 512/1000 [42:11<36:26,  4.48s/it]\u001b[A\n",
      " 51%|█████▏    | 513/1000 [42:16<37:31,  4.62s/it]\u001b[A\n",
      " 51%|█████▏    | 514/1000 [42:21<37:30,  4.63s/it]\u001b[A\n",
      " 52%|█████▏    | 515/1000 [42:27<39:54,  4.94s/it]\u001b[A\n",
      " 52%|█████▏    | 516/1000 [42:31<39:09,  4.85s/it]\u001b[A\n",
      " 52%|█████▏    | 517/1000 [42:35<37:27,  4.65s/it]\u001b[A\n",
      " 52%|█████▏    | 518/1000 [42:40<37:10,  4.63s/it]\u001b[A\n",
      " 52%|█████▏    | 519/1000 [42:45<37:36,  4.69s/it]\u001b[A\n",
      " 52%|█████▏    | 520/1000 [42:50<37:51,  4.73s/it]\u001b[A\n",
      " 52%|█████▏    | 521/1000 [42:55<39:29,  4.95s/it]\u001b[A\n",
      " 52%|█████▏    | 522/1000 [43:00<38:09,  4.79s/it]\u001b[A\n",
      " 52%|█████▏    | 523/1000 [43:02<32:20,  4.07s/it]\u001b[A\n",
      " 52%|█████▏    | 524/1000 [43:07<34:12,  4.31s/it]\u001b[A\n",
      " 52%|█████▎    | 525/1000 [43:11<33:34,  4.24s/it]\u001b[A\n",
      " 53%|█████▎    | 526/1000 [43:17<36:55,  4.67s/it]\u001b[A\n",
      " 53%|█████▎    | 527/1000 [43:22<37:33,  4.77s/it]\u001b[A\n",
      " 53%|█████▎    | 528/1000 [43:27<39:56,  5.08s/it]\u001b[A\n",
      " 53%|█████▎    | 529/1000 [43:32<39:08,  4.99s/it]\u001b[A\n",
      " 53%|█████▎    | 530/1000 [43:37<38:45,  4.95s/it]\u001b[A\n",
      " 53%|█████▎    | 531/1000 [43:47<50:15,  6.43s/it]\u001b[A\n",
      " 53%|█████▎    | 532/1000 [43:52<45:59,  5.90s/it]\u001b[A\n",
      " 53%|█████▎    | 533/1000 [43:56<41:49,  5.37s/it]\u001b[A\n",
      " 53%|█████▎    | 534/1000 [43:59<36:19,  4.68s/it]\u001b[A\n",
      " 54%|█████▎    | 535/1000 [44:03<35:04,  4.53s/it]\u001b[A\n",
      " 54%|█████▎    | 536/1000 [44:06<31:45,  4.11s/it]\u001b[A\n",
      " 54%|█████▎    | 537/1000 [44:12<34:51,  4.52s/it]\u001b[A\n",
      " 54%|█████▍    | 538/1000 [44:15<33:27,  4.35s/it]\u001b[A\n",
      " 54%|█████▍    | 539/1000 [44:20<33:24,  4.35s/it]\u001b[A\n",
      " 54%|█████▍    | 540/1000 [44:23<31:28,  4.10s/it]\u001b[A\n",
      " 54%|█████▍    | 541/1000 [44:25<24:42,  3.23s/it]\u001b[A\n",
      " 54%|█████▍    | 542/1000 [44:29<26:40,  3.49s/it]\u001b[A\n",
      " 54%|█████▍    | 543/1000 [44:33<27:52,  3.66s/it]\u001b[A\n",
      " 54%|█████▍    | 544/1000 [44:38<30:57,  4.07s/it]\u001b[A\n",
      " 55%|█████▍    | 545/1000 [44:42<31:56,  4.21s/it]\u001b[A\n",
      " 55%|█████▍    | 546/1000 [44:48<35:09,  4.65s/it]\u001b[A\n",
      " 55%|█████▍    | 547/1000 [44:51<31:52,  4.22s/it]\u001b[A\n",
      " 55%|█████▍    | 548/1000 [44:57<35:19,  4.69s/it]\u001b[A\n",
      " 55%|█████▍    | 549/1000 [45:03<37:14,  4.95s/it]\u001b[A\n",
      " 55%|█████▌    | 550/1000 [45:07<36:37,  4.88s/it]\u001b[A\n",
      " 55%|█████▌    | 551/1000 [45:12<36:30,  4.88s/it]\u001b[A\n",
      " 55%|█████▌    | 552/1000 [45:17<37:27,  5.02s/it]\u001b[A\n",
      " 55%|█████▌    | 553/1000 [45:22<35:26,  4.76s/it]\u001b[A\n",
      " 55%|█████▌    | 554/1000 [45:24<30:36,  4.12s/it]\u001b[A\n",
      " 56%|█████▌    | 555/1000 [45:31<36:33,  4.93s/it]\u001b[A\n",
      " 56%|█████▌    | 556/1000 [45:35<33:49,  4.57s/it]\u001b[A\n",
      " 56%|█████▌    | 557/1000 [45:39<33:12,  4.50s/it]\u001b[A\n",
      " 56%|█████▌    | 558/1000 [45:44<33:22,  4.53s/it]\u001b[A\n",
      " 56%|█████▌    | 559/1000 [45:48<33:36,  4.57s/it]\u001b[A\n",
      " 56%|█████▌    | 560/1000 [45:58<45:38,  6.22s/it]\u001b[A\n",
      " 56%|█████▌    | 561/1000 [46:03<41:30,  5.67s/it]\u001b[A\n",
      " 56%|█████▌    | 562/1000 [46:07<38:07,  5.22s/it]\u001b[A\n",
      " 56%|█████▋    | 563/1000 [46:12<37:20,  5.13s/it]\u001b[A\n",
      " 56%|█████▋    | 564/1000 [46:17<36:12,  4.98s/it]\u001b[A\n",
      " 56%|█████▋    | 565/1000 [46:22<36:10,  4.99s/it]\u001b[A\n",
      " 57%|█████▋    | 566/1000 [46:26<34:55,  4.83s/it]\u001b[A\n",
      " 57%|█████▋    | 567/1000 [46:31<35:05,  4.86s/it]\u001b[A\n",
      " 57%|█████▋    | 568/1000 [46:34<31:13,  4.34s/it]\u001b[A\n",
      " 57%|█████▋    | 569/1000 [46:38<30:32,  4.25s/it]\u001b[A\n",
      " 57%|█████▋    | 570/1000 [46:42<29:13,  4.08s/it]\u001b[A\n",
      " 57%|█████▋    | 571/1000 [46:46<30:28,  4.26s/it]\u001b[A\n",
      " 57%|█████▋    | 572/1000 [46:51<31:14,  4.38s/it]\u001b[A\n",
      " 57%|█████▋    | 573/1000 [46:57<34:52,  4.90s/it]\u001b[A\n",
      " 57%|█████▋    | 574/1000 [47:02<34:14,  4.82s/it]\u001b[A\n",
      " 57%|█████▊    | 575/1000 [47:06<32:47,  4.63s/it]\u001b[A\n",
      " 58%|█████▊    | 576/1000 [47:11<33:29,  4.74s/it]\u001b[A\n",
      " 58%|█████▊    | 577/1000 [47:15<31:47,  4.51s/it]\u001b[A\n",
      " 58%|█████▊    | 578/1000 [47:19<31:32,  4.48s/it]\u001b[A\n",
      " 58%|█████▊    | 579/1000 [47:23<29:09,  4.15s/it]\u001b[A\n",
      " 58%|█████▊    | 580/1000 [47:25<25:39,  3.67s/it]\u001b[A\n",
      " 58%|█████▊    | 581/1000 [47:30<26:53,  3.85s/it]\u001b[A\n",
      " 58%|█████▊    | 582/1000 [47:33<24:46,  3.56s/it]\u001b[A\n",
      " 58%|█████▊    | 583/1000 [47:38<28:38,  4.12s/it]\u001b[A\n",
      " 58%|█████▊    | 584/1000 [47:41<26:58,  3.89s/it]\u001b[A\n",
      " 58%|█████▊    | 585/1000 [47:46<27:48,  4.02s/it]\u001b[A\n",
      " 59%|█████▊    | 586/1000 [47:54<36:51,  5.34s/it]\u001b[A\n",
      " 59%|█████▊    | 587/1000 [48:01<39:58,  5.81s/it]\u001b[A\n",
      " 59%|█████▉    | 588/1000 [48:06<38:07,  5.55s/it]\u001b[A\n",
      " 59%|█████▉    | 589/1000 [48:09<33:50,  4.94s/it]\u001b[A\n",
      " 59%|█████▉    | 590/1000 [48:12<29:22,  4.30s/it]\u001b[A\n",
      " 59%|█████▉    | 591/1000 [48:17<30:26,  4.47s/it]\u001b[A\n",
      " 59%|█████▉    | 592/1000 [48:22<30:18,  4.46s/it]\u001b[A\n",
      " 59%|█████▉    | 593/1000 [48:25<27:27,  4.05s/it]\u001b[A\n",
      " 59%|█████▉    | 594/1000 [48:29<28:28,  4.21s/it]\u001b[A\n",
      " 60%|█████▉    | 595/1000 [48:34<29:25,  4.36s/it]\u001b[A\n",
      " 60%|█████▉    | 596/1000 [48:38<28:21,  4.21s/it]\u001b[A\n",
      " 60%|█████▉    | 597/1000 [48:43<30:41,  4.57s/it]\u001b[A\n",
      " 60%|█████▉    | 598/1000 [48:46<27:26,  4.10s/it]\u001b[A\n",
      " 60%|█████▉    | 599/1000 [48:51<28:01,  4.19s/it]\u001b[A\n",
      " 60%|██████    | 600/1000 [48:54<26:28,  3.97s/it]\u001b[A\n",
      " 60%|██████    | 601/1000 [49:01<31:30,  4.74s/it]\u001b[A\n",
      " 60%|██████    | 602/1000 [49:05<30:32,  4.61s/it]\u001b[A\n",
      " 60%|██████    | 603/1000 [49:10<31:51,  4.81s/it]\u001b[A\n",
      " 60%|██████    | 604/1000 [49:14<30:04,  4.56s/it]\u001b[A\n",
      " 60%|██████    | 605/1000 [49:19<31:26,  4.78s/it]\u001b[A\n",
      " 61%|██████    | 606/1000 [49:24<31:11,  4.75s/it]\u001b[A\n",
      " 61%|██████    | 607/1000 [49:28<29:25,  4.49s/it]\u001b[A\n",
      " 61%|██████    | 608/1000 [49:32<27:38,  4.23s/it]\u001b[A\n",
      " 61%|██████    | 609/1000 [49:35<26:49,  4.12s/it]\u001b[A\n",
      " 61%|██████    | 610/1000 [49:40<26:54,  4.14s/it]\u001b[A\n",
      " 61%|██████    | 611/1000 [49:45<28:48,  4.44s/it]\u001b[A\n",
      " 61%|██████    | 612/1000 [49:49<28:54,  4.47s/it]\u001b[A\n",
      " 61%|██████▏   | 613/1000 [49:54<29:41,  4.60s/it]\u001b[A\n",
      " 61%|██████▏   | 614/1000 [49:57<26:26,  4.11s/it]\u001b[A\n",
      " 62%|██████▏   | 615/1000 [50:01<25:27,  3.97s/it]\u001b[A\n",
      " 62%|██████▏   | 616/1000 [50:05<24:53,  3.89s/it]\u001b[A\n",
      " 62%|██████▏   | 617/1000 [50:11<29:27,  4.61s/it]\u001b[A\n",
      " 62%|██████▏   | 618/1000 [50:16<30:21,  4.77s/it]\u001b[A\n",
      " 62%|██████▏   | 619/1000 [50:21<29:44,  4.68s/it]\u001b[A\n",
      " 62%|██████▏   | 620/1000 [50:23<26:10,  4.13s/it]\u001b[A\n",
      " 62%|██████▏   | 621/1000 [50:29<29:42,  4.70s/it]\u001b[A\n",
      " 62%|██████▏   | 622/1000 [50:32<26:23,  4.19s/it]\u001b[A\n",
      " 62%|██████▏   | 623/1000 [50:36<25:47,  4.11s/it]\u001b[A\n",
      " 62%|██████▏   | 624/1000 [50:41<26:08,  4.17s/it]\u001b[A\n",
      " 62%|██████▎   | 625/1000 [50:47<30:43,  4.92s/it]\u001b[A\n",
      " 63%|██████▎   | 626/1000 [50:53<31:42,  5.09s/it]\u001b[A\n",
      " 63%|██████▎   | 627/1000 [50:57<29:43,  4.78s/it]\u001b[A\n",
      " 63%|██████▎   | 628/1000 [51:02<30:22,  4.90s/it]\u001b[A\n",
      " 63%|██████▎   | 629/1000 [51:05<27:42,  4.48s/it]\u001b[A\n",
      " 63%|██████▎   | 630/1000 [51:10<27:43,  4.50s/it]\u001b[A\n",
      " 63%|██████▎   | 631/1000 [51:15<28:54,  4.70s/it]\u001b[A\n",
      " 63%|██████▎   | 632/1000 [51:20<29:27,  4.80s/it]\u001b[A\n",
      " 63%|██████▎   | 633/1000 [51:24<28:04,  4.59s/it]\u001b[A\n",
      " 63%|██████▎   | 634/1000 [51:29<28:51,  4.73s/it]\u001b[A\n",
      " 64%|██████▎   | 635/1000 [51:34<28:47,  4.73s/it]\u001b[A\n",
      " 64%|██████▎   | 636/1000 [51:37<25:45,  4.25s/it]\u001b[A\n",
      " 64%|██████▎   | 637/1000 [51:41<24:00,  3.97s/it]\u001b[A\n",
      " 64%|██████▍   | 638/1000 [51:44<23:06,  3.83s/it]\u001b[A\n",
      " 64%|██████▍   | 639/1000 [51:48<23:31,  3.91s/it]\u001b[A\n",
      " 64%|██████▍   | 640/1000 [51:54<26:54,  4.48s/it]\u001b[A\n",
      " 64%|██████▍   | 641/1000 [51:59<27:21,  4.57s/it]\u001b[A\n",
      " 64%|██████▍   | 642/1000 [52:03<26:03,  4.37s/it]\u001b[A\n",
      " 64%|██████▍   | 643/1000 [52:08<27:50,  4.68s/it]\u001b[A\n",
      " 64%|██████▍   | 644/1000 [52:12<26:59,  4.55s/it]\u001b[A\n",
      " 64%|██████▍   | 645/1000 [52:17<27:38,  4.67s/it]\u001b[A\n",
      " 65%|██████▍   | 646/1000 [52:22<28:31,  4.84s/it]\u001b[A\n",
      " 65%|██████▍   | 647/1000 [52:27<28:42,  4.88s/it]\u001b[A\n",
      " 65%|██████▍   | 648/1000 [52:32<28:40,  4.89s/it]\u001b[A\n",
      " 65%|██████▍   | 649/1000 [52:36<26:12,  4.48s/it]\u001b[A\n",
      " 65%|██████▌   | 650/1000 [52:40<25:03,  4.29s/it]\u001b[A\n",
      " 65%|██████▌   | 651/1000 [52:45<26:09,  4.50s/it]\u001b[A\n",
      " 65%|██████▌   | 652/1000 [52:50<26:59,  4.65s/it]\u001b[A\n",
      " 65%|██████▌   | 653/1000 [52:55<27:07,  4.69s/it]\u001b[A\n",
      " 65%|██████▌   | 654/1000 [52:58<24:32,  4.26s/it]\u001b[A\n",
      " 66%|██████▌   | 655/1000 [53:03<25:56,  4.51s/it]\u001b[A\n",
      " 66%|██████▌   | 656/1000 [53:07<25:04,  4.37s/it]\u001b[A\n",
      " 66%|██████▌   | 657/1000 [53:14<30:10,  5.28s/it]\u001b[A\n",
      " 66%|██████▌   | 658/1000 [53:20<31:27,  5.52s/it]\u001b[A\n",
      " 66%|██████▌   | 659/1000 [53:26<31:59,  5.63s/it]\u001b[A\n",
      " 66%|██████▌   | 660/1000 [53:31<30:15,  5.34s/it]\u001b[A\n",
      " 66%|██████▌   | 661/1000 [53:36<28:52,  5.11s/it]\u001b[A\n",
      " 66%|██████▌   | 662/1000 [53:40<27:32,  4.89s/it]\u001b[A\n",
      " 66%|██████▋   | 663/1000 [53:44<25:43,  4.58s/it]\u001b[A\n",
      " 66%|██████▋   | 664/1000 [53:49<25:57,  4.63s/it]\u001b[A\n",
      " 66%|██████▋   | 665/1000 [53:54<27:50,  4.99s/it]\u001b[A\n",
      " 67%|██████▋   | 666/1000 [53:59<26:58,  4.85s/it]\u001b[A\n",
      " 67%|██████▋   | 667/1000 [54:03<26:23,  4.75s/it]\u001b[A\n",
      " 67%|██████▋   | 668/1000 [54:06<23:06,  4.18s/it]\u001b[A\n",
      " 67%|██████▋   | 669/1000 [54:11<23:39,  4.29s/it]\u001b[A\n",
      " 67%|██████▋   | 670/1000 [54:17<26:09,  4.76s/it]\u001b[A\n",
      " 67%|██████▋   | 671/1000 [54:23<29:10,  5.32s/it]\u001b[A\n",
      " 67%|██████▋   | 672/1000 [54:26<25:25,  4.65s/it]\u001b[A\n",
      " 67%|██████▋   | 673/1000 [54:32<26:55,  4.94s/it]\u001b[A\n",
      " 67%|██████▋   | 674/1000 [54:34<22:50,  4.20s/it]\u001b[A\n",
      " 68%|██████▊   | 675/1000 [54:37<20:05,  3.71s/it]\u001b[A\n",
      " 68%|██████▊   | 676/1000 [54:41<20:41,  3.83s/it]\u001b[A\n",
      " 68%|██████▊   | 677/1000 [54:46<22:13,  4.13s/it]\u001b[A\n",
      " 68%|██████▊   | 678/1000 [54:50<22:38,  4.22s/it]\u001b[A\n",
      " 68%|██████▊   | 679/1000 [54:54<21:07,  3.95s/it]\u001b[A\n",
      " 68%|██████▊   | 680/1000 [55:00<25:26,  4.77s/it]\u001b[A\n",
      " 68%|██████▊   | 681/1000 [55:04<23:48,  4.48s/it]\u001b[A\n",
      " 68%|██████▊   | 682/1000 [55:09<24:44,  4.67s/it]\u001b[A\n",
      " 68%|██████▊   | 683/1000 [55:14<25:18,  4.79s/it]\u001b[A\n",
      " 68%|██████▊   | 684/1000 [55:19<25:31,  4.85s/it]\u001b[A\n",
      " 68%|██████▊   | 685/1000 [55:26<28:36,  5.45s/it]\u001b[A\n",
      " 69%|██████▊   | 686/1000 [55:30<25:11,  4.81s/it]\u001b[A\n",
      " 69%|██████▊   | 687/1000 [55:34<25:20,  4.86s/it]\u001b[A\n",
      " 69%|██████▉   | 688/1000 [55:38<23:30,  4.52s/it]\u001b[A\n",
      " 69%|██████▉   | 689/1000 [55:42<22:32,  4.35s/it]\u001b[A\n",
      " 69%|██████▉   | 690/1000 [55:47<23:33,  4.56s/it]\u001b[A\n",
      " 69%|██████▉   | 691/1000 [55:52<24:26,  4.74s/it]\u001b[A\n",
      " 69%|██████▉   | 692/1000 [55:57<24:37,  4.80s/it]\u001b[A\n",
      " 69%|██████▉   | 693/1000 [56:06<30:27,  5.95s/it]\u001b[A\n",
      " 69%|██████▉   | 694/1000 [56:11<28:22,  5.56s/it]\u001b[A\n",
      " 70%|██████▉   | 695/1000 [56:16<28:35,  5.62s/it]\u001b[A\n",
      " 70%|██████▉   | 696/1000 [56:20<25:20,  5.00s/it]\u001b[A\n",
      " 70%|██████▉   | 697/1000 [56:25<25:29,  5.05s/it]\u001b[A\n",
      " 70%|██████▉   | 698/1000 [56:30<24:55,  4.95s/it]\u001b[A\n",
      " 70%|██████▉   | 699/1000 [56:33<22:33,  4.50s/it]\u001b[A\n",
      " 70%|███████   | 700/1000 [56:38<22:17,  4.46s/it]\u001b[A\n",
      " 70%|███████   | 701/1000 [56:43<23:04,  4.63s/it]\u001b[A\n",
      " 70%|███████   | 702/1000 [56:46<21:46,  4.38s/it]\u001b[A\n",
      " 70%|███████   | 703/1000 [56:51<22:34,  4.56s/it]\u001b[A\n",
      " 70%|███████   | 704/1000 [56:55<21:33,  4.37s/it]\u001b[A\n",
      " 70%|███████   | 705/1000 [57:00<21:37,  4.40s/it]\u001b[A\n",
      " 71%|███████   | 706/1000 [57:04<20:59,  4.28s/it]\u001b[A\n",
      " 71%|███████   | 707/1000 [57:08<21:25,  4.39s/it]\u001b[A\n",
      " 71%|███████   | 708/1000 [57:13<21:11,  4.35s/it]\u001b[A\n",
      " 71%|███████   | 709/1000 [57:18<22:02,  4.54s/it]\u001b[A\n",
      " 71%|███████   | 710/1000 [57:23<22:28,  4.65s/it]\u001b[A\n",
      " 71%|███████   | 711/1000 [57:28<23:05,  4.79s/it]\u001b[A\n",
      " 71%|███████   | 712/1000 [57:34<24:33,  5.12s/it]\u001b[A\n",
      " 71%|███████▏  | 713/1000 [57:38<23:40,  4.95s/it]\u001b[A\n",
      " 71%|███████▏  | 714/1000 [57:43<23:53,  5.01s/it]\u001b[A\n",
      " 72%|███████▏  | 715/1000 [57:48<23:47,  5.01s/it]\u001b[A\n",
      " 72%|███████▏  | 716/1000 [57:51<20:09,  4.26s/it]\u001b[A\n",
      " 72%|███████▏  | 717/1000 [57:55<19:21,  4.11s/it]\u001b[A\n",
      " 72%|███████▏  | 718/1000 [57:59<19:33,  4.16s/it]\u001b[A\n",
      " 72%|███████▏  | 719/1000 [58:03<19:46,  4.22s/it]\u001b[A\n",
      " 72%|███████▏  | 720/1000 [58:08<20:56,  4.49s/it]\u001b[A\n",
      " 72%|███████▏  | 721/1000 [58:14<22:30,  4.84s/it]\u001b[A\n",
      " 72%|███████▏  | 722/1000 [58:20<23:47,  5.14s/it]\u001b[A\n",
      " 72%|███████▏  | 723/1000 [58:24<23:00,  4.98s/it]\u001b[A\n",
      " 72%|███████▏  | 724/1000 [58:29<22:49,  4.96s/it]\u001b[A\n",
      " 72%|███████▎  | 725/1000 [58:36<24:42,  5.39s/it]\u001b[A\n",
      " 73%|███████▎  | 726/1000 [58:41<23:53,  5.23s/it]\u001b[A\n",
      " 73%|███████▎  | 727/1000 [58:49<27:32,  6.05s/it]\u001b[A\n",
      " 73%|███████▎  | 728/1000 [58:53<24:49,  5.48s/it]\u001b[A\n",
      " 73%|███████▎  | 729/1000 [58:58<24:56,  5.52s/it]\u001b[A\n",
      " 73%|███████▎  | 730/1000 [59:02<22:03,  4.90s/it]\u001b[A\n",
      " 73%|███████▎  | 731/1000 [59:07<21:46,  4.86s/it]\u001b[A\n",
      " 73%|███████▎  | 732/1000 [59:11<20:38,  4.62s/it]\u001b[A\n",
      " 73%|███████▎  | 733/1000 [59:16<21:34,  4.85s/it]\u001b[A\n",
      " 73%|███████▎  | 734/1000 [59:21<21:02,  4.75s/it]\u001b[A\n",
      " 74%|███████▎  | 735/1000 [59:25<20:58,  4.75s/it]\u001b[A\n",
      " 74%|███████▎  | 736/1000 [59:30<21:00,  4.78s/it]\u001b[A\n",
      " 74%|███████▎  | 737/1000 [59:34<19:15,  4.39s/it]\u001b[A\n",
      " 74%|███████▍  | 738/1000 [59:38<19:07,  4.38s/it]\u001b[A\n",
      " 74%|███████▍  | 739/1000 [59:43<19:36,  4.51s/it]\u001b[A\n",
      " 74%|███████▍  | 740/1000 [59:48<19:58,  4.61s/it]\u001b[A\n",
      " 74%|███████▍  | 741/1000 [59:52<19:11,  4.44s/it]\u001b[A\n",
      " 74%|███████▍  | 742/1000 [59:56<19:32,  4.55s/it]\u001b[A\n",
      " 74%|███████▍  | 743/1000 [59:59<17:10,  4.01s/it]\u001b[A\n",
      " 74%|███████▍  | 744/1000 [1:00:02<15:10,  3.56s/it]\u001b[A\n",
      " 74%|███████▍  | 745/1000 [1:00:07<16:51,  3.97s/it]\u001b[A\n",
      " 75%|███████▍  | 746/1000 [1:00:12<18:14,  4.31s/it]\u001b[A\n",
      " 75%|███████▍  | 747/1000 [1:00:15<17:12,  4.08s/it]\u001b[A\n",
      " 75%|███████▍  | 748/1000 [1:00:19<17:03,  4.06s/it]\u001b[A\n",
      " 75%|███████▍  | 749/1000 [1:00:24<17:15,  4.13s/it]\u001b[A\n",
      " 75%|███████▌  | 750/1000 [1:00:28<17:13,  4.13s/it]\u001b[A\n",
      " 75%|███████▌  | 751/1000 [1:00:34<19:25,  4.68s/it]\u001b[A\n",
      " 75%|███████▌  | 752/1000 [1:00:38<19:27,  4.71s/it]\u001b[A\n",
      " 75%|███████▌  | 753/1000 [1:00:43<19:21,  4.70s/it]\u001b[A\n",
      " 75%|███████▌  | 754/1000 [1:00:47<17:54,  4.37s/it]\u001b[A\n",
      " 76%|███████▌  | 755/1000 [1:00:51<17:30,  4.29s/it]\u001b[A\n",
      " 76%|███████▌  | 756/1000 [1:00:55<17:23,  4.28s/it]\u001b[A\n",
      " 76%|███████▌  | 757/1000 [1:01:00<18:03,  4.46s/it]\u001b[A\n",
      " 76%|███████▌  | 758/1000 [1:01:03<15:55,  3.95s/it]\u001b[A\n",
      " 76%|███████▌  | 759/1000 [1:01:10<20:18,  5.06s/it]\u001b[A\n",
      " 76%|███████▌  | 760/1000 [1:01:15<20:06,  5.03s/it]\u001b[A\n",
      " 76%|███████▌  | 761/1000 [1:01:20<19:36,  4.92s/it]\u001b[A\n",
      " 76%|███████▌  | 762/1000 [1:01:23<17:45,  4.48s/it]\u001b[A\n",
      " 76%|███████▋  | 763/1000 [1:01:28<17:54,  4.53s/it]\u001b[A\n",
      " 76%|███████▋  | 764/1000 [1:01:32<17:19,  4.40s/it]\u001b[A\n",
      " 76%|███████▋  | 765/1000 [1:01:37<17:24,  4.44s/it]\u001b[A\n",
      " 77%|███████▋  | 766/1000 [1:01:43<19:47,  5.08s/it]\u001b[A\n",
      " 77%|███████▋  | 767/1000 [1:01:48<19:12,  4.94s/it]\u001b[A\n",
      " 77%|███████▋  | 768/1000 [1:01:52<18:06,  4.68s/it]\u001b[A\n",
      " 77%|███████▋  | 769/1000 [1:01:56<16:45,  4.35s/it]\u001b[A\n",
      " 77%|███████▋  | 770/1000 [1:02:02<18:51,  4.92s/it]\u001b[A\n",
      " 77%|███████▋  | 771/1000 [1:02:07<18:36,  4.88s/it]\u001b[A\n",
      " 77%|███████▋  | 772/1000 [1:02:11<17:33,  4.62s/it]\u001b[A\n",
      " 77%|███████▋  | 773/1000 [1:02:16<18:19,  4.84s/it]\u001b[A\n",
      " 77%|███████▋  | 774/1000 [1:02:21<18:02,  4.79s/it]\u001b[A\n",
      " 78%|███████▊  | 775/1000 [1:02:25<17:41,  4.72s/it]\u001b[A\n",
      " 78%|███████▊  | 776/1000 [1:02:30<17:52,  4.79s/it]\u001b[A\n",
      " 78%|███████▊  | 777/1000 [1:02:35<17:45,  4.78s/it]\u001b[A\n",
      " 78%|███████▊  | 778/1000 [1:02:40<17:57,  4.85s/it]\u001b[A\n",
      " 78%|███████▊  | 779/1000 [1:02:43<15:30,  4.21s/it]\u001b[A\n",
      " 78%|███████▊  | 780/1000 [1:02:47<15:41,  4.28s/it]\u001b[A\n",
      " 78%|███████▊  | 781/1000 [1:02:52<16:03,  4.40s/it]\u001b[A\n",
      " 78%|███████▊  | 782/1000 [1:02:56<15:46,  4.34s/it]\u001b[A\n",
      " 78%|███████▊  | 783/1000 [1:03:00<15:37,  4.32s/it]\u001b[A\n",
      " 78%|███████▊  | 784/1000 [1:03:05<15:53,  4.42s/it]\u001b[A\n",
      " 78%|███████▊  | 785/1000 [1:03:10<16:15,  4.54s/it]\u001b[A\n",
      " 79%|███████▊  | 786/1000 [1:03:14<16:08,  4.53s/it]\u001b[A\n",
      " 79%|███████▊  | 787/1000 [1:03:18<15:10,  4.27s/it]\u001b[A\n",
      " 79%|███████▉  | 788/1000 [1:03:23<15:35,  4.42s/it]\u001b[A\n",
      " 79%|███████▉  | 789/1000 [1:03:27<15:20,  4.36s/it]\u001b[A\n",
      " 79%|███████▉  | 790/1000 [1:03:30<13:33,  3.87s/it]\u001b[A\n",
      " 79%|███████▉  | 791/1000 [1:03:34<13:40,  3.93s/it]\u001b[A\n",
      " 79%|███████▉  | 792/1000 [1:03:37<13:15,  3.83s/it]\u001b[A\n",
      " 79%|███████▉  | 793/1000 [1:03:41<12:40,  3.67s/it]\u001b[A\n",
      " 79%|███████▉  | 794/1000 [1:03:45<13:21,  3.89s/it]\u001b[A\n",
      " 80%|███████▉  | 795/1000 [1:03:49<13:49,  4.05s/it]\u001b[A\n",
      " 80%|███████▉  | 796/1000 [1:03:54<14:16,  4.20s/it]\u001b[A\n",
      " 80%|███████▉  | 797/1000 [1:03:59<15:26,  4.56s/it]\u001b[A\n",
      " 80%|███████▉  | 798/1000 [1:04:04<15:37,  4.64s/it]\u001b[A\n",
      " 80%|███████▉  | 799/1000 [1:04:09<15:59,  4.77s/it]\u001b[A\n",
      " 80%|████████  | 800/1000 [1:04:17<18:28,  5.54s/it]\u001b[A\n",
      " 80%|████████  | 801/1000 [1:04:21<17:32,  5.29s/it]\u001b[A\n",
      " 80%|████████  | 802/1000 [1:04:26<17:14,  5.22s/it]\u001b[A\n",
      " 80%|████████  | 803/1000 [1:04:31<16:25,  5.00s/it]\u001b[A\n",
      " 80%|████████  | 804/1000 [1:04:36<16:56,  5.18s/it]\u001b[A\n",
      " 80%|████████  | 805/1000 [1:04:41<16:22,  5.04s/it]\u001b[A\n",
      " 81%|████████  | 806/1000 [1:04:46<15:46,  4.88s/it]\u001b[A\n",
      " 81%|████████  | 807/1000 [1:04:51<16:19,  5.07s/it]\u001b[A\n",
      " 81%|████████  | 808/1000 [1:04:56<15:44,  4.92s/it]\u001b[A\n",
      " 81%|████████  | 809/1000 [1:05:00<15:08,  4.76s/it]\u001b[A\n",
      " 81%|████████  | 810/1000 [1:05:06<15:52,  5.02s/it]\u001b[A\n",
      " 81%|████████  | 811/1000 [1:05:08<12:41,  4.03s/it]\u001b[A\n",
      " 81%|████████  | 812/1000 [1:05:11<12:26,  3.97s/it]\u001b[A\n",
      " 81%|████████▏ | 813/1000 [1:05:18<15:06,  4.85s/it]\u001b[A\n",
      " 81%|████████▏ | 814/1000 [1:05:25<16:40,  5.38s/it]\u001b[A\n",
      " 82%|████████▏ | 815/1000 [1:05:30<16:43,  5.42s/it]\u001b[A\n",
      " 82%|████████▏ | 816/1000 [1:05:36<16:50,  5.49s/it]\u001b[A\n",
      " 82%|████████▏ | 817/1000 [1:05:43<18:00,  5.90s/it]\u001b[A\n",
      " 82%|████████▏ | 818/1000 [1:05:47<16:40,  5.50s/it]\u001b[A\n",
      " 82%|████████▏ | 819/1000 [1:05:51<15:15,  5.06s/it]\u001b[A\n",
      " 82%|████████▏ | 820/1000 [1:05:55<13:39,  4.56s/it]\u001b[A\n",
      " 82%|████████▏ | 821/1000 [1:05:58<12:13,  4.10s/it]\u001b[A\n",
      " 82%|████████▏ | 822/1000 [1:06:02<12:13,  4.12s/it]\u001b[A\n",
      " 82%|████████▏ | 823/1000 [1:06:07<12:35,  4.27s/it]\u001b[A\n",
      " 82%|████████▏ | 824/1000 [1:06:10<11:30,  3.92s/it]\u001b[A\n",
      " 82%|████████▎ | 825/1000 [1:06:14<11:54,  4.08s/it]\u001b[A\n",
      " 83%|████████▎ | 826/1000 [1:06:18<11:29,  3.97s/it]\u001b[A\n",
      " 83%|████████▎ | 827/1000 [1:06:23<12:24,  4.31s/it]\u001b[A\n",
      " 83%|████████▎ | 828/1000 [1:06:30<14:25,  5.03s/it]\u001b[A\n",
      " 83%|████████▎ | 829/1000 [1:06:33<13:12,  4.63s/it]\u001b[A\n",
      " 83%|████████▎ | 830/1000 [1:06:36<11:41,  4.13s/it]\u001b[A\n",
      " 83%|████████▎ | 831/1000 [1:06:41<12:10,  4.32s/it]\u001b[A\n",
      " 83%|████████▎ | 832/1000 [1:06:47<13:08,  4.69s/it]\u001b[A\n",
      " 83%|████████▎ | 833/1000 [1:06:50<12:12,  4.38s/it]\u001b[A\n",
      " 83%|████████▎ | 834/1000 [1:06:55<12:15,  4.43s/it]\u001b[A\n",
      " 84%|████████▎ | 835/1000 [1:07:01<13:16,  4.83s/it]\u001b[A\n",
      " 84%|████████▎ | 836/1000 [1:07:03<11:04,  4.05s/it]\u001b[A\n",
      " 84%|████████▎ | 837/1000 [1:07:06<10:22,  3.82s/it]\u001b[A\n",
      " 84%|████████▍ | 838/1000 [1:07:11<11:13,  4.15s/it]\u001b[A\n",
      " 84%|████████▍ | 839/1000 [1:07:15<10:39,  3.97s/it]\u001b[A\n",
      " 84%|████████▍ | 840/1000 [1:07:19<11:07,  4.17s/it]\u001b[A\n",
      " 84%|████████▍ | 841/1000 [1:07:22<10:05,  3.81s/it]\u001b[A\n",
      " 84%|████████▍ | 842/1000 [1:07:27<10:50,  4.12s/it]\u001b[A\n",
      " 84%|████████▍ | 843/1000 [1:07:32<11:06,  4.25s/it]\u001b[A\n",
      " 84%|████████▍ | 844/1000 [1:07:39<13:26,  5.17s/it]\u001b[A\n",
      " 84%|████████▍ | 845/1000 [1:07:44<12:54,  5.00s/it]\u001b[A\n",
      " 85%|████████▍ | 846/1000 [1:07:49<13:04,  5.09s/it]\u001b[A\n",
      " 85%|████████▍ | 847/1000 [1:07:55<13:53,  5.45s/it]\u001b[A\n",
      " 85%|████████▍ | 848/1000 [1:07:58<11:47,  4.65s/it]\u001b[A\n",
      " 85%|████████▍ | 849/1000 [1:08:03<11:58,  4.76s/it]\u001b[A\n",
      " 85%|████████▌ | 850/1000 [1:08:10<13:19,  5.33s/it]\u001b[A\n",
      " 85%|████████▌ | 851/1000 [1:08:17<14:58,  6.03s/it]\u001b[A\n",
      " 85%|████████▌ | 852/1000 [1:08:22<13:50,  5.61s/it]\u001b[A\n",
      " 85%|████████▌ | 853/1000 [1:08:24<11:28,  4.68s/it]\u001b[A\n",
      " 85%|████████▌ | 854/1000 [1:08:29<11:33,  4.75s/it]\u001b[A\n",
      " 86%|████████▌ | 855/1000 [1:08:35<11:50,  4.90s/it]\u001b[A\n",
      " 86%|████████▌ | 856/1000 [1:08:39<11:18,  4.71s/it]\u001b[A\n",
      " 86%|████████▌ | 857/1000 [1:08:43<10:49,  4.55s/it]\u001b[A\n",
      " 86%|████████▌ | 858/1000 [1:08:47<10:35,  4.48s/it]\u001b[A\n",
      " 86%|████████▌ | 859/1000 [1:08:52<10:30,  4.47s/it]\u001b[A\n",
      " 86%|████████▌ | 860/1000 [1:08:56<10:20,  4.43s/it]\u001b[A\n",
      " 86%|████████▌ | 861/1000 [1:09:03<11:54,  5.14s/it]\u001b[A\n",
      " 86%|████████▌ | 862/1000 [1:09:08<11:37,  5.05s/it]\u001b[A\n",
      " 86%|████████▋ | 863/1000 [1:09:12<11:15,  4.93s/it]\u001b[A\n",
      " 86%|████████▋ | 864/1000 [1:09:18<11:31,  5.09s/it]\u001b[A\n",
      " 86%|████████▋ | 865/1000 [1:09:22<11:02,  4.90s/it]\u001b[A\n",
      " 87%|████████▋ | 866/1000 [1:09:26<10:04,  4.51s/it]\u001b[A\n",
      " 87%|████████▋ | 867/1000 [1:09:30<09:51,  4.44s/it]\u001b[A\n",
      " 87%|████████▋ | 868/1000 [1:09:36<10:37,  4.83s/it]\u001b[A\n",
      " 87%|████████▋ | 869/1000 [1:09:40<09:39,  4.43s/it]\u001b[A\n",
      " 87%|████████▋ | 870/1000 [1:09:44<09:30,  4.39s/it]\u001b[A\n",
      " 87%|████████▋ | 871/1000 [1:09:49<09:44,  4.53s/it]\u001b[A\n",
      " 87%|████████▋ | 872/1000 [1:09:52<09:13,  4.32s/it]\u001b[A\n",
      " 87%|████████▋ | 873/1000 [1:09:57<09:19,  4.40s/it]\u001b[A\n",
      " 87%|████████▋ | 874/1000 [1:10:01<09:04,  4.32s/it]\u001b[A\n",
      " 88%|████████▊ | 875/1000 [1:10:06<09:14,  4.44s/it]\u001b[A\n",
      " 88%|████████▊ | 876/1000 [1:10:16<12:41,  6.14s/it]\u001b[A\n",
      " 88%|████████▊ | 877/1000 [1:10:21<11:36,  5.66s/it]\u001b[A\n",
      " 88%|████████▊ | 878/1000 [1:10:27<11:55,  5.87s/it]\u001b[A\n",
      " 88%|████████▊ | 879/1000 [1:10:31<10:56,  5.43s/it]\u001b[A\n",
      " 88%|████████▊ | 880/1000 [1:10:35<09:44,  4.87s/it]\u001b[A\n",
      " 88%|████████▊ | 881/1000 [1:10:39<09:15,  4.67s/it]\u001b[A\n",
      " 88%|████████▊ | 882/1000 [1:10:43<08:29,  4.32s/it]\u001b[A\n",
      " 88%|████████▊ | 883/1000 [1:10:46<07:44,  3.97s/it]\u001b[A\n",
      " 88%|████████▊ | 884/1000 [1:10:50<08:03,  4.17s/it]\u001b[A\n",
      " 88%|████████▊ | 885/1000 [1:10:55<08:14,  4.30s/it]\u001b[A\n",
      " 89%|████████▊ | 886/1000 [1:10:59<07:43,  4.06s/it]\u001b[A\n",
      " 89%|████████▊ | 887/1000 [1:11:03<08:03,  4.28s/it]\u001b[A\n",
      " 89%|████████▉ | 888/1000 [1:11:08<07:57,  4.26s/it]\u001b[A\n",
      " 89%|████████▉ | 889/1000 [1:11:12<07:48,  4.22s/it]\u001b[A\n",
      " 89%|████████▉ | 890/1000 [1:11:19<09:23,  5.12s/it]\u001b[A\n",
      " 89%|████████▉ | 891/1000 [1:11:23<08:38,  4.76s/it]\u001b[A\n",
      " 89%|████████▉ | 892/1000 [1:11:29<09:20,  5.19s/it]\u001b[A\n",
      " 89%|████████▉ | 893/1000 [1:11:34<09:02,  5.07s/it]\u001b[A\n",
      " 89%|████████▉ | 894/1000 [1:11:37<08:00,  4.53s/it]\u001b[A\n",
      " 90%|████████▉ | 895/1000 [1:11:42<08:22,  4.79s/it]\u001b[A\n",
      " 90%|████████▉ | 896/1000 [1:11:47<07:58,  4.60s/it]\u001b[A\n",
      " 90%|████████▉ | 897/1000 [1:11:49<06:58,  4.06s/it]\u001b[A\n",
      " 90%|████████▉ | 898/1000 [1:11:55<07:55,  4.66s/it]\u001b[A\n",
      " 90%|████████▉ | 899/1000 [1:11:58<06:40,  3.96s/it]\u001b[A\n",
      " 90%|█████████ | 900/1000 [1:12:04<07:51,  4.72s/it]\u001b[A\n",
      " 90%|█████████ | 901/1000 [1:12:09<07:59,  4.84s/it]\u001b[A\n",
      " 90%|█████████ | 902/1000 [1:12:14<07:50,  4.80s/it]\u001b[A\n",
      " 90%|█████████ | 903/1000 [1:12:19<07:38,  4.73s/it]\u001b[A\n",
      " 90%|█████████ | 904/1000 [1:12:26<08:50,  5.53s/it]\u001b[A\n",
      " 90%|█████████ | 905/1000 [1:12:31<08:25,  5.32s/it]\u001b[A\n",
      " 91%|█████████ | 906/1000 [1:12:35<07:42,  4.92s/it]\u001b[A\n",
      " 91%|█████████ | 907/1000 [1:12:38<06:39,  4.30s/it]\u001b[A\n",
      " 91%|█████████ | 908/1000 [1:12:43<07:14,  4.72s/it]\u001b[A\n",
      " 91%|█████████ | 909/1000 [1:12:48<07:14,  4.77s/it]\u001b[A\n",
      " 91%|█████████ | 910/1000 [1:12:53<07:09,  4.77s/it]\u001b[A\n",
      " 91%|█████████ | 911/1000 [1:12:57<06:52,  4.63s/it]\u001b[A\n",
      " 91%|█████████ | 912/1000 [1:13:03<07:01,  4.79s/it]\u001b[A\n",
      " 91%|█████████▏| 913/1000 [1:13:08<07:24,  5.11s/it]\u001b[A\n",
      " 91%|█████████▏| 914/1000 [1:13:14<07:19,  5.11s/it]\u001b[A\n",
      " 92%|█████████▏| 915/1000 [1:13:18<06:58,  4.92s/it]\u001b[A\n",
      " 92%|█████████▏| 916/1000 [1:13:24<07:30,  5.37s/it]\u001b[A\n",
      " 92%|█████████▏| 917/1000 [1:13:32<08:29,  6.13s/it]\u001b[A\n",
      " 92%|█████████▏| 918/1000 [1:13:37<07:58,  5.84s/it]\u001b[A\n",
      " 92%|█████████▏| 919/1000 [1:13:42<07:12,  5.34s/it]\u001b[A\n",
      " 92%|█████████▏| 920/1000 [1:13:46<06:39,  5.00s/it]\u001b[A\n",
      " 92%|█████████▏| 921/1000 [1:13:51<06:36,  5.02s/it]\u001b[A\n",
      " 92%|█████████▏| 922/1000 [1:13:56<06:25,  4.94s/it]\u001b[A\n",
      " 92%|█████████▏| 923/1000 [1:14:00<06:06,  4.76s/it]\u001b[A\n",
      " 92%|█████████▏| 924/1000 [1:14:05<06:03,  4.78s/it]\u001b[A\n",
      " 92%|█████████▎| 925/1000 [1:14:08<05:18,  4.24s/it]\u001b[A\n",
      " 93%|█████████▎| 926/1000 [1:14:12<05:14,  4.25s/it]\u001b[A\n",
      " 93%|█████████▎| 927/1000 [1:14:17<05:32,  4.56s/it]\u001b[A\n",
      " 93%|█████████▎| 928/1000 [1:14:21<05:10,  4.31s/it]\u001b[A\n",
      " 93%|█████████▎| 929/1000 [1:14:26<05:10,  4.37s/it]\u001b[A\n",
      " 93%|█████████▎| 930/1000 [1:14:33<06:02,  5.17s/it]\u001b[A\n",
      " 93%|█████████▎| 931/1000 [1:14:36<05:27,  4.75s/it]\u001b[A\n",
      " 93%|█████████▎| 932/1000 [1:14:41<05:17,  4.67s/it]\u001b[A\n",
      " 93%|█████████▎| 933/1000 [1:14:48<05:59,  5.37s/it]\u001b[A\n",
      " 93%|█████████▎| 934/1000 [1:14:53<05:39,  5.15s/it]\u001b[A\n",
      " 94%|█████████▎| 935/1000 [1:14:57<05:29,  5.08s/it]\u001b[A\n",
      " 94%|█████████▎| 936/1000 [1:15:04<05:56,  5.56s/it]\u001b[A\n",
      " 94%|█████████▎| 937/1000 [1:15:09<05:35,  5.32s/it]\u001b[A\n",
      " 94%|█████████▍| 938/1000 [1:15:11<04:36,  4.46s/it]\u001b[A\n",
      " 94%|█████████▍| 939/1000 [1:15:16<04:28,  4.39s/it]\u001b[A\n",
      " 94%|█████████▍| 940/1000 [1:15:25<05:46,  5.78s/it]\u001b[A\n",
      " 94%|█████████▍| 941/1000 [1:15:28<04:54,  4.99s/it]\u001b[A\n",
      " 94%|█████████▍| 942/1000 [1:15:33<04:49,  4.99s/it]\u001b[A\n",
      " 94%|█████████▍| 943/1000 [1:15:38<04:56,  5.21s/it]\u001b[A\n",
      " 94%|█████████▍| 944/1000 [1:15:41<04:12,  4.50s/it]\u001b[A\n",
      " 94%|█████████▍| 945/1000 [1:15:45<03:53,  4.24s/it]\u001b[A\n",
      " 95%|█████████▍| 946/1000 [1:15:51<04:22,  4.86s/it]\u001b[A\n",
      " 95%|█████████▍| 947/1000 [1:15:56<04:15,  4.82s/it]\u001b[A\n",
      " 95%|█████████▍| 948/1000 [1:16:01<04:07,  4.76s/it]\u001b[A\n",
      " 95%|█████████▍| 949/1000 [1:16:05<03:49,  4.51s/it]\u001b[A\n",
      " 95%|█████████▌| 950/1000 [1:16:09<03:37,  4.35s/it]\u001b[A\n",
      " 95%|█████████▌| 951/1000 [1:16:13<03:36,  4.42s/it]\u001b[A\n",
      " 95%|█████████▌| 952/1000 [1:16:17<03:30,  4.39s/it]\u001b[A\n",
      " 95%|█████████▌| 953/1000 [1:16:22<03:22,  4.31s/it]\u001b[A\n",
      " 95%|█████████▌| 954/1000 [1:16:29<03:59,  5.21s/it]\u001b[A\n",
      " 96%|█████████▌| 955/1000 [1:16:33<03:39,  4.87s/it]\u001b[A\n",
      " 96%|█████████▌| 956/1000 [1:16:38<03:35,  4.91s/it]\u001b[A\n",
      " 96%|█████████▌| 957/1000 [1:16:43<03:32,  4.93s/it]\u001b[A\n",
      " 96%|█████████▌| 958/1000 [1:16:47<03:18,  4.73s/it]\u001b[A\n",
      " 96%|█████████▌| 959/1000 [1:16:51<03:06,  4.54s/it]\u001b[A\n",
      " 96%|█████████▌| 960/1000 [1:16:56<03:09,  4.73s/it]\u001b[A\n",
      " 96%|█████████▌| 961/1000 [1:17:01<03:04,  4.72s/it]\u001b[A\n",
      " 96%|█████████▌| 962/1000 [1:17:05<02:47,  4.42s/it]\u001b[A\n",
      " 96%|█████████▋| 963/1000 [1:17:10<02:46,  4.50s/it]\u001b[A\n",
      " 96%|█████████▋| 964/1000 [1:17:14<02:43,  4.54s/it]\u001b[A\n",
      " 96%|█████████▋| 965/1000 [1:17:19<02:46,  4.77s/it]\u001b[A\n",
      " 97%|█████████▋| 966/1000 [1:17:24<02:34,  4.56s/it]\u001b[A\n",
      " 97%|█████████▋| 967/1000 [1:17:28<02:31,  4.58s/it]\u001b[A\n",
      " 97%|█████████▋| 968/1000 [1:17:33<02:29,  4.66s/it]\u001b[A\n",
      " 97%|█████████▋| 969/1000 [1:17:38<02:22,  4.61s/it]\u001b[A\n",
      " 97%|█████████▋| 970/1000 [1:17:40<01:56,  3.88s/it]\u001b[A\n",
      " 97%|█████████▋| 971/1000 [1:17:44<01:56,  4.00s/it]\u001b[A\n",
      " 97%|█████████▋| 972/1000 [1:17:55<02:50,  6.10s/it]\u001b[A\n",
      " 97%|█████████▋| 973/1000 [1:18:00<02:33,  5.67s/it]\u001b[A\n",
      " 97%|█████████▋| 974/1000 [1:18:04<02:16,  5.23s/it]\u001b[A\n",
      " 98%|█████████▊| 975/1000 [1:18:09<02:06,  5.07s/it]\u001b[A\n",
      " 98%|█████████▊| 976/1000 [1:18:14<02:01,  5.07s/it]\u001b[A\n",
      " 98%|█████████▊| 977/1000 [1:18:18<01:55,  5.01s/it]\u001b[A\n",
      " 98%|█████████▊| 978/1000 [1:18:23<01:47,  4.87s/it]\u001b[A\n",
      " 98%|█████████▊| 979/1000 [1:18:28<01:41,  4.85s/it]\u001b[A\n",
      " 98%|█████████▊| 980/1000 [1:18:31<01:27,  4.39s/it]\u001b[A\n",
      " 98%|█████████▊| 981/1000 [1:18:36<01:23,  4.41s/it]\u001b[A\n",
      " 98%|█████████▊| 982/1000 [1:18:42<01:30,  5.03s/it]\u001b[A\n",
      " 98%|█████████▊| 983/1000 [1:18:47<01:22,  4.86s/it]\u001b[A\n",
      " 98%|█████████▊| 984/1000 [1:18:51<01:17,  4.83s/it]\u001b[A\n",
      " 98%|█████████▊| 985/1000 [1:18:55<01:09,  4.61s/it]\u001b[A\n",
      " 99%|█████████▊| 986/1000 [1:19:00<01:05,  4.65s/it]\u001b[A\n",
      " 99%|█████████▊| 987/1000 [1:19:03<00:53,  4.15s/it]\u001b[A\n",
      " 99%|█████████▉| 988/1000 [1:19:07<00:49,  4.11s/it]\u001b[A\n",
      " 99%|█████████▉| 989/1000 [1:19:11<00:43,  3.96s/it]\u001b[A\n",
      " 99%|█████████▉| 990/1000 [1:19:15<00:40,  4.05s/it]\u001b[A\n",
      " 99%|█████████▉| 991/1000 [1:19:18<00:33,  3.77s/it]\u001b[A\n",
      " 99%|█████████▉| 992/1000 [1:19:22<00:31,  3.93s/it]\u001b[A\n",
      " 99%|█████████▉| 993/1000 [1:19:26<00:26,  3.83s/it]\u001b[A\n",
      " 99%|█████████▉| 994/1000 [1:19:30<00:23,  3.96s/it]\u001b[A\n",
      "100%|█████████▉| 995/1000 [1:19:34<00:19,  3.83s/it]\u001b[A\n",
      "100%|█████████▉| 996/1000 [1:19:39<00:16,  4.18s/it]\u001b[A\n",
      "100%|█████████▉| 997/1000 [1:19:44<00:13,  4.36s/it]\u001b[A\n",
      "100%|█████████▉| 998/1000 [1:19:47<00:07,  3.99s/it]\u001b[A\n",
      "100%|█████████▉| 999/1000 [1:19:51<00:04,  4.04s/it]\u001b[A\n",
      "100%|██████████| 1000/1000 [1:19:56<00:00,  4.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Traduciendo split 'test' de español a inglés...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321/321 [24:12<00:00,  4.52s/it]\n"
     ]
    }
   ],
   "source": [
    "def build_en_mayaV_split(split, model, tokenizer):\n",
    "    new_inputs = []\n",
    "    new_targets = []\n",
    "\n",
    "    print(f\"🔄 Traduciendo split '{split}' de español a inglés...\\n\")\n",
    "    for example in tqdm(es_qum_dataset[split]):\n",
    "        es_text = example[\"input\"]\n",
    "        en_text = translate_text(model, tokenizer, es_text, \"spa_Latn\", \"eng_Latn\")\n",
    "        new_inputs.append(en_text)\n",
    "        new_targets.append(example[\"target\"])\n",
    "\n",
    "    return Dataset.from_dict({\n",
    "        \"input\": new_inputs,\n",
    "        \"target\": new_targets\n",
    "    })\n",
    "\n",
    "# Generar splits\n",
    "en_qum_train = build_en_mayaV_split(\"train\", mid_model, mid_tokenizer)\n",
    "en_qum_test = build_en_mayaV_split(\"test\", mid_model, mid_tokenizer)\n",
    "\n",
    "# Combinar\n",
    "en_qum_dataset = DatasetDict({\n",
    "    \"train\": en_qum_train,\n",
    "    \"test\": en_qum_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5hInI7CrxB8H",
    "outputId": "afa5d842-9faa-46c2-bdda-bde4135e1e64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivos .en y .quc guardados en .\n"
     ]
    }
   ],
   "source": [
    "output_dir = \".\"\n",
    "\n",
    "import os\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Guardar cada split en .en (inglés) y .quc (quiché)\n",
    "for split in [\"train\", \"test\"]:\n",
    "    with open(f\"{output_dir}/{split}.en\", \"w\", encoding=\"utf-8\") as f_en, \\\n",
    "         open(f\"{output_dir}/{split}.quc\", \"w\", encoding=\"utf-8\") as f_quc:\n",
    "\n",
    "        for example in en_qum_dataset[split]:\n",
    "            f_en.write(example[\"input\"].strip() + \"\\n\")\n",
    "            f_quc.write(example[\"target\"].strip() + \"\\n\")\n",
    "\n",
    "print(\"✅ Archivos .en y .quc guardados en\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yg2pG-V8b5l"
   },
   "source": [
    "#### Realizar finetuning con datos artificiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397,
     "referenced_widgets": [
      "e2986057849c498f8f6654bee7c34214",
      "a169f9257b794cd9b494b95dd0f38d8e",
      "1f2baa738b4749dda309c71b6a813047",
      "753255a115f34c23991dcdd87cd4dd08",
      "4f4d0fb0bf2843d5b8729735da3ef9f0",
      "c5d2e0d9ffa44ec4af5478efcef22b12",
      "3eadaf0838264fca8e7b3545c2bd6e79",
      "46fc73721ace4f63a374b6e5a4d95648",
      "3127a852f1ef4d32bd8e27be19c11355",
      "83c9575a85e24621903afaf15012f205",
      "7bc50ca84517439f9c9c2f24d457d1e0",
      "3b5f552e890946f3b915e710ce0198e9",
      "946ef2d0c16e4cb8aaed25e3ea1db333",
      "4db67050037443c1afd03f9f1f03a5f1",
      "2c19ed51a38142f8a01d25619e7a6e4f",
      "c3382b5afdd74e2581150b9119f15b7f",
      "c9cd1f288ce04b3c94d7dc6d5cff24e4",
      "b3f48bd8141049679e938e5085a372b9",
      "89cf06d84f3b485db5d6d63f6832a149",
      "03b22ffba0a6455e862e371a9ec29978",
      "bcca652a491e4d1daae628a2641a3043",
      "1a4742fc417845dd96e9f0b948d5558b",
      "f3021cf9cd1246778ffce09ef73a0125",
      "3007df507d5845c38c413dea28fa036e",
      "1d2459bca3fb4e7990c857d03dfef871",
      "c578807c03de477b93cab5e2eaf23c0d",
      "5a5846f6f12448b5bef2a8c89e2e4bd9",
      "6fcaeddc80404dfd9f24b99fd4db5f86",
      "d702167de5b14f7795f2dd6cb8a71e0f",
      "a51cc680be354986a339d8483947686a",
      "fe8348ec0a1b4004a3c308e0a5e7bba2",
      "875609318c034f0db9c67f446fba01e3",
      "84154daf7cce478594bf4b29346c1913",
      "ffd7cbb0081d4db884851ae334e27848",
      "47d317d63111405497f3f253b3534b8b",
      "2dff662d6aa64bca92c533c3f5091609",
      "7c1e0f06cb444d46ba6069cbaa8f038c",
      "6c29b31862aa48b59c7d05a4c915dc62",
      "891adaf684ff41bbba513540d2a0733b",
      "ad3f9554e5d14a21bd5ab70fef795ae3",
      "8f73eb4d265b4e72b17db4b563d5f10c",
      "00faece2e95649b5b2d5f39b03abb5c0",
      "a5dd627485c14fd4aad2f937d54ca5f0",
      "430821b067c14e65b66569aea2f538b3",
      "5952329521244d718bff6fd1cc4d0a0d",
      "f1f0d4285dec429ca36963c47628965f",
      "bbb81fe8483f4eadba41900b2d046ac5",
      "6ec6555fc27c44bfb4db2c0c20b5b432",
      "b68b381b5301427ca86cf05070972cd4",
      "89e34892131541069c550537f0f21138",
      "087ed12f9de04e1191ef3c796e7c0e4a",
      "f2a150f69c30465f8f0464b696f729a4",
      "f6e2f896536648d8b23e97ffbd05fdef",
      "913b957c01654f8eb18e194d9587f4ae",
      "d13662f64f1445389b02a2d40c01e7dc",
      "68c4791de02e4442a6d3c2aeadb64634",
      "9611ddebfb4248b79d9843ec82fe9115",
      "96302ac40c5e408eacb6ee72ef4757d4",
      "72b8df47e4014f64b071fb115e22d80c",
      "988ffe33ea59421783c0356cb5edcb68",
      "fa3ccd5ffb704d0c97728e07f868fb6c",
      "f72b3d55a45c4c7d8a3d04a75dd4b11a",
      "c6fdd8658baf4d59b241631d2fc4f875",
      "60dbcb184d604968a1830aa3a7c7c8e2",
      "a0ce619326ac4915acabd88b8bc85cb8",
      "45214671e9ac4a76af8a18dd2e38015a",
      "a41b4ec251e24d55bd89b0531ebeffe5",
      "c1ca37e604a14abf97c5ce8df21424b1",
      "895226062800456eb30a8dcc20215ba2",
      "8b18a1629dc34d679e09050945fe46b5",
      "784ca8bedfab49379cc394318d2f0b53",
      "94743ea58b0d4baa97fbbba4c55d1d7f",
      "254d300a8d084202883da64a3a400e38",
      "c4abb342fdc84c01bd273e403ee9e8b5",
      "caa654cb425c4a9fb5dc19a30f76d58b",
      "971f7a4aeaf548159d2810173fb60af3",
      "49cbdc9fedfd4d1d9c97c1d6e9eebf7a",
      "28a1733700654a53a30c3791d213783b",
      "2c018b8f5bfc46ad9768a0ba67474f6e",
      "e041e5815d724d949b09b617034b831f",
      "14184416bab84361818c2c40c67d8c55",
      "cb9fd0d9fa2c4e959a063c4f6a2b1d56",
      "c4dbef832863421a95c2a4ac84639422",
      "5fc3650942ba4c5da75e55e4701febcf",
      "e6255d126d5a409db260a10a9d79d8e4",
      "e22bbb8c7cd9420a9474039a935cbb65",
      "b6c9387655b04d6a9913944cb1b6e872",
      "b86c5912707e44728291ea4bfa44f5e3"
     ]
    },
    "id": "LEUkIjpj33ln",
    "outputId": "b0e5a1c2-242e-422c-daa7-ce7943a4bfe2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2986057849c498f8f6654bee7c34214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5f552e890946f3b915e710ce0198e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3021cf9cd1246778ffce09ef73a0125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd7cbb0081d4db884851ae334e27848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5952329521244d718bff6fd1cc4d0a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c4791de02e4442a6d3c2aeadb64634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41b4ec251e24d55bd89b0531ebeffe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a1733700654a53a30c3791d213783b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "en_qum_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "en_qum_model = get_peft_model(base_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "ddf0a44eefe547479584c5deccecec7d",
      "6e01a2e2e2c543e1824f60e87adc13e2",
      "973e9b6bb52b4867aa722cb4db086c1f",
      "366f5d69d1ec48cfb4349c0107390cf0",
      "486ecc27023043eda51473d2b3492d12",
      "f6f9ea4b3ef540dcad94b0330219e142",
      "c03ce63581c249f7ac283c844c97a5e6",
      "98e7fef459b64108930a2b6a92650642",
      "8bd0547d288e4abeb1925c275fbcf671",
      "c4651321a5d4478c912466f5110ea974",
      "b2a6741a95c64810884157e8f7501a7a",
      "8b9b86f8d5144f66a51d4bab98f8aa5b",
      "dca49835efef4892bcc17fcdb74d4b8e",
      "dd4e879dc25a4183a66bcc3435269d86",
      "1e304ad12a734498addc6664f7b89be2",
      "33a8a989e0fb435ba546fbeaf20775bc",
      "eb9ea5e352d74748b58d8910eefc5675",
      "d7d24170d15642749241d1e8bdadbf02",
      "4202241df9b445f69a86c648ef79596d",
      "28d54a5244094cd89a911e52f81c7efe",
      "9993ca83ce6f4cf58dff004023f1eab4",
      "61fae0d2712c44abaf65227f5e8d8d17",
      "cae88b59f1c74b9780abed290b3ed04c",
      "c9f0f81278054cdf9e5d7c8dadcb2769",
      "6b514aff481e4c70a0574eca84c8f7b6",
      "275522673ba24747aca9970ccb6e3163",
      "afd4c9a1c567481fbcba8a4648e6033d",
      "29ddf51382f34d22ab380ba35ffa65f6",
      "501cf061b9804458bd3c6e5b916a5e45",
      "961b5cfa3526487998a6bd790096e1b1",
      "23e4157bd8c9487e89a727dea5ce5ae7",
      "a11b07827ca245fb875eca7efe58ff5c",
      "b2cc879e0ef94ae69142cb53bd5e6c1d",
      "c94f1a013a554a9dbf99f5011d0eb2a1",
      "a4c2ae4644d145fa9e0f3b60514f5274",
      "50c796bad6084ba581fe5a101a065470",
      "5edcd03065f445929b1fca23974fa03e",
      "17d15c46d3a84facb3029d29e3e13783",
      "ffe0ec4aed864cda90ce1470da4e6b6e",
      "005f2cb3acf447129e0bdfd10e3a2161",
      "c119b9cf901b414badbb34a449c88d15",
      "51b9174f94f94ae68892902f9978a9d5",
      "2593d6c44fdd4ba68ee925ee2f14b8f4",
      "489cbc32f841433893f4cdb8510b2907"
     ]
    },
    "id": "64iABUrW19Vf",
    "outputId": "63eba1d0-bef1-4739-fd4c-385c14fbcab8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf0a44eefe547479584c5deccecec7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9b86f8d5144f66a51d4bab98f8aa5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae88b59f1c74b9780abed290b3ed04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94f1a013a554a9dbf99f5011d0eb2a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = \".\"\n",
    "\n",
    "en_train = load_dataset(\"text\", data_files=f\"{data_dir}/train.en\")[\"train\"]\n",
    "quc_train = load_dataset(\"text\", data_files=f\"{data_dir}/train.quc\")[\"train\"]\n",
    "\n",
    "en_test = load_dataset(\"text\", data_files=f\"{data_dir}/test.en\")[\"train\"]\n",
    "quc_test = load_dataset(\"text\", data_files=f\"{data_dir}/test.quc\")[\"train\"]\n",
    "\n",
    "# Combinar train\n",
    "train_dict = {\n",
    "    \"input\": [x[\"text\"] for x in en_train],\n",
    "    \"target\": [x[\"text\"] for x in quc_train],\n",
    "}\n",
    "train_dataset = Dataset.from_dict(train_dict)\n",
    "\n",
    "# Combinar test\n",
    "test_dict = {\n",
    "    \"input\": [x[\"text\"] for x in en_test],\n",
    "    \"target\": [x[\"text\"] for x in quc_test],\n",
    "}\n",
    "test_dataset = Dataset.from_dict(test_dict)\n",
    "\n",
    "en_qum_dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "cc1dee25a6ea42f293b3c1452e614b45",
      "5ae282dcaebc4532b07911cfde8c476a",
      "bda7a75b2578438b9804f06ec48f9ce1",
      "71d3d1a788f248e9b305c457768eb964",
      "36c9a6a812bc43969da1fa528673813e",
      "6e3432c7f9994e83a4d756f79e8d1f41",
      "b80944bd8ef646e691336ceb94efa0b1",
      "39b685495cad461996c0406b43d5dfe7",
      "fe42c04a5857405d9a425a8a58262ca0",
      "8dee820a5ff946f7a09e95ab54082506",
      "52560adc15234804b1fa33a4cddb7013",
      "5d6a989635ee4ee6ae64f9a7c9457f3d",
      "533ab382d36546ceb9dd9d1c5668dffe",
      "0939b8080c9d4a058063d689fd03622e",
      "047b83d3b15445c49658d75ebade4aa0",
      "5dc440ae793145a2848af65d7bb0b600",
      "e75e444d3e3c4b0eb7427a1c992c0e85",
      "db7eb15a5d924f75924e10bc70ed0276",
      "58d70ef0f2c34635b9495a1fcc42eb8e",
      "b5ab57e926f9486f8fdcde87b2152bb8",
      "d762ea66d4804d7aba2e5640f219ccbb",
      "07f8894fa83c4d4999a9530194cad4a3"
     ]
    },
    "id": "w1sEWghP4B7C",
    "outputId": "c80ab1e6-da08-4ca7-971b-38c92103ed1b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1dee25a6ea42f293b3c1452e614b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6a989635ee4ee6ae64f9a7c9457f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function_en_qum(examples):\n",
    "    max_length = 128\n",
    "    inputs = en_qum_tokenizer(examples[\"input\"], max_length=max_length, truncation=True, padding=True)\n",
    "    targets = en_qum_tokenizer(examples[\"target\"], max_length=max_length, truncation=True, padding=True)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "tokenized_en_qum_train = en_qum_dataset[\"train\"].map(preprocess_function_en_qum, batched=True)\n",
    "tokenized_en_qum_test = en_qum_dataset[\"test\"].map(preprocess_function_en_qum, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxivqDvt4GEf",
    "outputId": "a9c3425e-49e3-4be1-df1e-0531be05ba4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "training_args_en_qum = TrainingArguments(\n",
    "    output_dir=\"./finetuned_en_qum_nllb\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs_en_qum\",\n",
    "    logging_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "WWYUxQWm4IU_",
    "outputId": "37c74abf-e1ee-419b-df05-bda9e7639303"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-15-1310942191.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_en_qum = Trainer(\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 01:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>10.082700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>8.990700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>8.157500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=8.834854166666666, metrics={'train_runtime': 93.4692, 'train_samples_per_second': 32.096, 'train_steps_per_second': 4.012, 'total_flos': 815382134784000.0, 'train_loss': 8.834854166666666, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_en_qum = Trainer(\n",
    "    model=en_qum_model,\n",
    "    args=training_args_en_qum,\n",
    "    train_dataset=tokenized_en_qum_train,\n",
    "    eval_dataset=tokenized_en_qum_test,\n",
    "    tokenizer=en_qum_tokenizer,\n",
    ")\n",
    "\n",
    "trainer_en_qum.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tc2QH1HJcuKn"
   },
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9jCIC05CCG_"
   },
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246,
     "referenced_widgets": [
      "fb03033fbcbe4ded97be54765a6ab1a2",
      "84c4818ba87749998eefca3124baafc8",
      "f1020622d8654dca9895c35b63f17a48",
      "9f1f7676d2184107a94c2b0f3b18d2ed",
      "1952d2f39e65418397bd9361bbeb41db",
      "0787c8c988ad40149a10871dfe068f62",
      "5adbda3ae5594a82a84eb6ce7b69e9a2",
      "3d5f0ba88106437a832b9a943d2b3c77",
      "aeae23788f0e48939a662b511111f411",
      "1238afe132ee49049ae2fcc7dcc965b6",
      "75997343ddad4b5e8aa0f1ee9b71ff4c",
      "6b36ccd8879f43baa8ef8411af2ede3d",
      "611195b6fd934b93941d6bf235a075e9",
      "640d155ef1c849adba78274f4325a18a",
      "1315ab33f7244475b9b1ccb6f8ad356b",
      "ebf02b559ac44cfaa723d6345cd74b48",
      "dd71d15892af4fdab7f5252b8bbbf01c",
      "682479bb5f7c485190030ca67c971a86",
      "d2a9aca3cc4e42c7b0bca6e887da2900",
      "a7ec2bbc849645c3bdf74b3fbce1b5d6",
      "ccaace4cf65549e486a75ee07cc927fb",
      "e6d7e8aa7ced4aa79d642ac1a262e029",
      "3196ac7b18b245ea87bdd38ab7743c82",
      "53478fa8343f4fb68a7539f4b6fc3333",
      "ed15ca96eb8e48c48247eaee8c049ae6",
      "a49476e0870444b3b25b7b27dedeb660",
      "98c91d54109941cc88675af796ced50b",
      "a2e4aaeb1d21410d9f822f6151b9592b",
      "8ed1c8d72d1047f7b130a57b16d854b4",
      "f8ff59fb9f01461183e565c77938a018",
      "0b592c4cc42f4aa4a0d46c1da7599864",
      "b0e5f5d7aecc4cdaa7016fd988f93eda",
      "c71f127ff3064d2b913b26d64f5b0854",
      "2861b72dae1e4437a5c1178228070f9a",
      "84fb6a7f421a4e56b5b14865136e47dc",
      "a87f83591b6f4530af9a6cc0bc4002a2",
      "d8165c7000234e25a8635261ce6b6511",
      "65cc2cde17c94dcdadd507b4ce072491",
      "dc6fbb0e02004870abd0ed565ea2c1e3",
      "098655de920d4e8085597a06c4fb1b5c",
      "456fc03105134acf8913ba79c483c626",
      "14049e8474094ba99cfe63c07f6ada4a",
      "f91722c5079a45c7b29fc58e5c204ae1",
      "b1aada240eb045b0b37deff4381cebaf",
      "905c5f7def6f47be945e69449c4a9e85",
      "5cca8d3027334b8aab4b930e2ff63fcb",
      "448d3f54b7524af8ba7aff7a7736faf2",
      "b039598b6cbe481fb35bf404bff12642",
      "dab1f5de965448dabadbbcd1211ca6a8",
      "ef96898149944e04a96b6b7b6b9f5731",
      "898868ffa8aa450c8f35be005f5ecc01",
      "d3b1c6c0557a499cb3931f340846957b",
      "74263e5accf04263803b64ff1400b8df",
      "0ec0b89ebcc1488fb3a1258d4f949a29",
      "f78517bb20434c3bbc421c1c960ab68a"
     ]
    },
    "id": "YEoaaYAZCDnX",
    "outputId": "ac1ae5ea-52e3-474f-a710-06d6ce96c34c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb03033fbcbe4ded97be54765a6ab1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b36ccd8879f43baa8ef8411af2ede3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3196ac7b18b245ea87bdd38ab7743c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2861b72dae1e4437a5c1178228070f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905c5f7def6f47be945e69449c4a9e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "meteor = evaluate.load(\"meteor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coKh9lECcw45"
   },
   "source": [
    "### Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljNvMeB3ezyA"
   },
   "source": [
    "#### 1. Zero-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h97Ae05Ce4E0"
   },
   "source": [
    "Como NLLB tiene el idioma K’iche’, se coloca este como idioma objetivo para las traducciones directas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqLQveUOffXM",
    "outputId": "581fbd91-a318-45db-f7ff-b1bcded0f5a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321/321 [1:17:38<00:00, 14.51s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for item in tqdm(es_qum_dataset[\"test\"]):\n",
    "    input_text = item[\"input\"]\n",
    "    reference = item[\"target\"]\n",
    "\n",
    "    inputs = zeroshot_tokenizer(input_text, return_tensors=\"pt\", truncation=True)\n",
    "    outputs = zeroshot_model.generate(**inputs, forced_bos_token_id=forced_bos_id)\n",
    "    pred = zeroshot_tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNH6mQC-j-jf",
    "outputId": "e5ae9f02-98c3-4435-b85d-cc926ea873e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplos ===\n",
      "\n",
      "> Entrada:     wu rxqiil taʼ xuux xaq utz laj siʼ kchuknik chre\n",
      "> Referencia:  #qum# La esposa de don Jesus solo utiliza buena leña\n",
      "> Predicción:                                                                                                    \n",
      "\n",
      "> Entrada:     Njeel ri xkarawaʼn xpochʼik rech chenim xchaqʼjik\n",
      "> Referencia:  #qum# Todo la arveja se\n",
      "> Predicción:  Njeel ri xkarawaʼn xpochʼik rech chenim xchaqʼjik\n",
      "\n",
      "> Entrada:     Pri qtinmit qal chik kchkunsxik ri qyolbʼaal\n",
      "> Referencia:  #qum# En nuestro pueblo ya no se usa nuestro idioma\n",
      "> Predicción:  \n",
      "\n",
      "> Entrada:     Ri ajtijnel tjin kirtijuuj c hemo rchkunsxik ri suʼ\n",
      "> Referencia:  #qum# El estudiante está aprendiendo como\n",
      "> Predicción:                                                                                                    \n",
      "\n",
      "> Entrada:     Ri ixoq tzʼulmaj rum ri rchjiil\n",
      "> Referencia:  #qum# La mujer estaba abrazada por su marido\n",
      "> Predicción:  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar algunas predicciones\n",
    "print(\"\\n=== Ejemplos ===\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"> Entrada:     {es_qum_dataset['test'][i]['input']}\")\n",
    "    print(f\"> Referencia:  {es_qum_dataset['test'][i]['target']}\")\n",
    "    print(f\"> Predicción:  {predictions[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XR9Gk30mUYq",
    "outputId": "41303eff-e81d-491e-f77b-66b14c204641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Métricas BLEU ===\n",
      "BLEU-1: 0.21\n",
      "BLEU-2: 0.00\n",
      "BLEU-3: 0.00\n",
      "BLEU-4: 0.00\n",
      "BLEU total: 0.00\n",
      "\n",
      "=== Métricas ROUGE ===\n",
      "ROUGE-1:   0.44\n",
      "ROUGE-2:   0.00\n",
      "ROUGE-L:   0.43\n",
      "ROUGE-Lsum:0.45\n",
      "\n",
      "=== Otras Métricas ===\n",
      "METEOR:     0.09\n"
     ]
    }
   ],
   "source": [
    "bleu_score = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "\n",
    "print(\"\\n=== Métricas BLEU ===\")\n",
    "print(f\"BLEU-1: {bleu_score['precisions'][0]*100:.2f}\")\n",
    "print(f\"BLEU-2: {bleu_score['precisions'][1]*100:.2f}\")\n",
    "print(f\"BLEU-3: {bleu_score['precisions'][2]*100:.2f}\")\n",
    "print(f\"BLEU-4: {bleu_score['precisions'][3]*100:.2f}\")\n",
    "print(f\"BLEU total: {bleu_score['bleu']*100:.2f}\")\n",
    "\n",
    "rouge_score = rouge.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(\"\\n=== Métricas ROUGE ===\")\n",
    "print(f\"ROUGE-1:   {rouge_score['rouge1']*100:.2f}\")\n",
    "print(f\"ROUGE-2:   {rouge_score['rouge2']*100:.2f}\")\n",
    "print(f\"ROUGE-L:   {rouge_score['rougeL']*100:.2f}\")\n",
    "print(f\"ROUGE-Lsum:{rouge_score['rougeLsum']*100:.2f}\")\n",
    "\n",
    "meteor_score = meteor.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(\"\\n=== Otras Métricas ===\")\n",
    "print(f\"METEOR:     {meteor_score['meteor']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJfs1A_sBkzy",
    "outputId": "03db1c7f-fc29-41fb-ae18-c64961faf4f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados guardados en 'results_es_qum_zeroshot.tsv'\n"
     ]
    }
   ],
   "source": [
    "with open(\"results_en_qum_zeroshot.tsv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    writer.writerow([\"input\", \"reference\", \"prediction\"])\n",
    "\n",
    "    for example, pred, ref in zip(es_qum_dataset[\"test\"], predictions, references):\n",
    "        writer.writerow([example[\"input\"], ref, pred])\n",
    "\n",
    "print(\"✅ Resultados guardados en 'results_es_qum_zeroshot.tsv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjB3SBkqn1JG"
   },
   "source": [
    "#### 2. Finetuning ES-QUC y Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8uBCVbR3obZG",
    "outputId": "289e6d27-2374-42be-a338-3a8bf62958d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Traduciendo: inglés → español → K’iche’ (vía intermediaria)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321/321 [06:39<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions_intermediate = []\n",
    "references_intermediate = []\n",
    "\n",
    "print(\"\\n🔹 Traduciendo: inglés → español → K’iche’ (vía intermediaria)\\n\")\n",
    "\n",
    "for item in tqdm(es_qum_dataset[\"test\"]):\n",
    "    input_text = item[\"input\"]\n",
    "    reference = item[\"target\"]\n",
    "\n",
    "    # Paso 1: inglés → español (modelo base)\n",
    "    inter = translate_text(finetune_model, finetune_tokenizer, input_text, \"eng_Latn\", \"spa_Latn\")\n",
    "\n",
    "    # Paso 2: español → K’iche’ (modelo fine-tuneado)\n",
    "    pred = translate_text(finetune_model, finetune_tokenizer, inter, \"spa_Latn\", \"quc_Latn\")\n",
    "\n",
    "    predictions_intermediate.append(pred)\n",
    "    references_intermediate.append(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2roPLoJoy2L",
    "outputId": "dced76a3-0b9a-4188-df24-3c73341098b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplos Fine-Tuned ===\n",
      "\n",
      "> Entrada:     wu rxqiil taʼ xuux xaq utz laj siʼ kchuknik chre\n",
      "> Referencia:  #qum# La esposa de don Jesus solo utiliza buena leña\n",
      "> Predicción:  #qum# El hombre que se ha tirado el pelo\n",
      "\n",
      "> Entrada:     Njeel ri xkarawaʼn xpochʼik rech chenim xchaqʼjik\n",
      "> Referencia:  #qum# Todo la arveja se\n",
      "> Predicción:  # #qum# La mujer se ha ido\n",
      "\n",
      "> Entrada:     Pri qtinmit qal chik kchkunsxik ri qyolbʼaal\n",
      "> Referencia:  #qum# En nuestro pueblo ya no se usa nuestro idioma\n",
      "> Predicción:  # La mujer se ha hecho el trabajo\n",
      "\n",
      "> Entrada:     Ri ajtijnel tjin kirtijuuj c hemo rchkunsxik ri suʼ\n",
      "> Referencia:  #qum# El estudiante está aprendiendo como\n",
      "> Predicción:  La gente se ha echado\n",
      "\n",
      "> Entrada:     Ri ixoq tzʼulmaj rum ri rchjiil\n",
      "> Referencia:  #qum# La mujer estaba abrazada por su marido\n",
      "> Predicción:  La gente se va a casa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Ejemplos Fine-Tuned ===\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"> Entrada:     {es_qum_dataset['test'][i]['input']}\")\n",
    "    print(f\"> Referencia:  {es_qum_dataset['test'][i]['target']}\")\n",
    "    print(f\"> Predicción:  {predictions_intermediate[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcM-8kilozFz",
    "outputId": "be358216-677e-4ede-9248-36a1179af813"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Métricas BLEU ===\n",
      "BLEU-1: 19.84\n",
      "BLEU-2: 6.16\n",
      "BLEU-3: 3.32\n",
      "BLEU-4: 0.78\n",
      "BLEU total: 2.82\n",
      "\n",
      "=== Métricas ROUGE ===\n",
      "ROUGE-1:   12.99\n",
      "ROUGE-2:   1.31\n",
      "ROUGE-L:   12.57\n",
      "ROUGE-Lsum:12.52\n",
      "\n",
      "=== Otras Métricas ===\n",
      "METEOR:     11.11\n"
     ]
    }
   ],
   "source": [
    "bleu_score = bleu.compute(predictions=predictions_intermediate, references=[[ref] for ref in references_intermediate])\n",
    "\n",
    "print(\"\\n=== Métricas BLEU ===\")\n",
    "print(f\"BLEU-1: {bleu_score['precisions'][0]*100:.2f}\")\n",
    "print(f\"BLEU-2: {bleu_score['precisions'][1]*100:.2f}\")\n",
    "print(f\"BLEU-3: {bleu_score['precisions'][2]*100:.2f}\")\n",
    "print(f\"BLEU-4: {bleu_score['precisions'][3]*100:.2f}\")\n",
    "print(f\"BLEU total: {bleu_score['bleu']*100:.2f}\")\n",
    "\n",
    "rouge_score = rouge.compute(predictions=predictions_intermediate, references=references_intermediate)\n",
    "\n",
    "print(\"\\n=== Métricas ROUGE ===\")\n",
    "print(f\"ROUGE-1:   {rouge_score['rouge1']*100:.2f}\")\n",
    "print(f\"ROUGE-2:   {rouge_score['rouge2']*100:.2f}\")\n",
    "print(f\"ROUGE-L:   {rouge_score['rougeL']*100:.2f}\")\n",
    "print(f\"ROUGE-Lsum:{rouge_score['rougeLsum']*100:.2f}\")\n",
    "\n",
    "meteor_score = meteor.compute(predictions=predictions_intermediate, references=references_intermediate)\n",
    "\n",
    "print(\"\\n=== Otras Métricas ===\")\n",
    "print(f\"METEOR:     {meteor_score['meteor']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MTsr6mJBWrm",
    "outputId": "6262e766-9132-4fe6-de89-d1482472bc08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados guardados en 'results_es_qum_finetune_intermediate.tsv'\n"
     ]
    }
   ],
   "source": [
    "with open(\"results_en_qum_finetune_intermediate.tsv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    writer.writerow([\"input\", \"reference\", \"prediction\"])\n",
    "\n",
    "    for example, pred, ref in zip(es_qum_dataset[\"test\"], predictions_intermediate, references_intermediate):\n",
    "        writer.writerow([example[\"input\"], ref, pred])\n",
    "\n",
    "print(\"✅ Resultados guardados en 'results_es_qum_finetune_intermediate.tsv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_UFY-dToFsb"
   },
   "source": [
    "#### 3. Finetuning ES-QUC y Traducción Directa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0UrnNGqobuo",
    "outputId": "139c767d-ac29-491c-e9b8-fcf95e979f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Traduciendo: inglés → K’iche’ (directo)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321/321 [03:44<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_direct = []\n",
    "references_direct = []\n",
    "\n",
    "print(\"\\n🔹 Traduciendo: inglés → K’iche’ (directo)\\n\")\n",
    "\n",
    "for item in tqdm(es_qum_dataset[\"test\"]):\n",
    "    input_text = item[\"input\"]\n",
    "    reference = item[\"target\"]\n",
    "    pred = translate_text(finetune_model, finetune_tokenizer, input_text, \"eng_Latn\", \"quc_Latn\")\n",
    "\n",
    "    predictions_direct.append(pred)\n",
    "    references_direct.append(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WGGj_XKctmn9",
    "outputId": "d7c6876d-b95b-479a-a7a1-d06d6d57f3e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplos Fine-Tuned ===\n",
      "\n",
      "> Entrada:     wu rxqiil taʼ xuux xaq utz laj siʼ kchuknik chre\n",
      "> Referencia:  #qum# La esposa de don Jesus solo utiliza buena leña\n",
      "> Predicción:  #qum# La mujer se ha hecho el uso de la\n",
      "\n",
      "> Entrada:     Njeel ri xkarawaʼn xpochʼik rech chenim xchaqʼjik\n",
      "> Referencia:  #qum# Todo la arveja se\n",
      "> Predicción:  # Cuando se despierta la casa de la mujer\n",
      "\n",
      "> Entrada:     Pri qtinmit qal chik kchkunsxik ri qyolbʼaal\n",
      "> Referencia:  #qum# En nuestro pueblo ya no se usa nuestro idioma\n",
      "> Predicción:  # El hombre que se ha quedado en la casa\n",
      "\n",
      "> Entrada:     Ri ajtijnel tjin kirtijuuj c hemo rchkunsxik ri suʼ\n",
      "> Referencia:  #qum# El estudiante está aprendiendo como\n",
      "> Predicción:  #qum# El hombre se ha ido a la casa\n",
      "\n",
      "> Entrada:     Ri ixoq tzʼulmaj rum ri rchjiil\n",
      "> Referencia:  #qum# La mujer estaba abrazada por su marido\n",
      "> Predicción:  # El hombre que se ha ido\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Ejemplos Fine-Tuned ===\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"> Entrada:     {es_qum_dataset['test'][i]['input']}\")\n",
    "    print(f\"> Referencia:  {es_qum_dataset['test'][i]['target']}\")\n",
    "    print(f\"> Predicción:  {predictions_direct[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uNuiAUOytvUu",
    "outputId": "d64a3861-1e83-498c-f10e-ee8101bbbdc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Métricas BLEU ===\n",
      "BLEU-1: 21.22\n",
      "BLEU-2: 9.45\n",
      "BLEU-3: 5.45\n",
      "BLEU-4: 1.59\n",
      "BLEU total: 5.68\n",
      "\n",
      "=== Métricas ROUGE ===\n",
      "ROUGE-1:   15.55\n",
      "ROUGE-2:   2.23\n",
      "ROUGE-L:   14.50\n",
      "ROUGE-Lsum:14.46\n",
      "\n",
      "=== Otras Métricas ===\n",
      "METEOR:     16.58\n"
     ]
    }
   ],
   "source": [
    "bleu_score = bleu.compute(predictions=predictions_direct, references=[[ref] for ref in references_direct])\n",
    "\n",
    "print(\"\\n=== Métricas BLEU ===\")\n",
    "print(f\"BLEU-1: {bleu_score['precisions'][0]*100:.2f}\")\n",
    "print(f\"BLEU-2: {bleu_score['precisions'][1]*100:.2f}\")\n",
    "print(f\"BLEU-3: {bleu_score['precisions'][2]*100:.2f}\")\n",
    "print(f\"BLEU-4: {bleu_score['precisions'][3]*100:.2f}\")\n",
    "print(f\"BLEU total: {bleu_score['bleu']*100:.2f}\")\n",
    "\n",
    "rouge_score = rouge.compute(predictions=predictions_direct, references=references_direct)\n",
    "\n",
    "print(\"\\n=== Métricas ROUGE ===\")\n",
    "print(f\"ROUGE-1:   {rouge_score['rouge1']*100:.2f}\")\n",
    "print(f\"ROUGE-2:   {rouge_score['rouge2']*100:.2f}\")\n",
    "print(f\"ROUGE-L:   {rouge_score['rougeL']*100:.2f}\")\n",
    "print(f\"ROUGE-Lsum:{rouge_score['rougeLsum']*100:.2f}\")\n",
    "\n",
    "meteor_score = meteor.compute(predictions=predictions_direct, references=references_direct)\n",
    "\n",
    "print(\"\\n=== Otras Métricas ===\")\n",
    "print(f\"METEOR:     {meteor_score['meteor']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2o0_ZKITBrRf",
    "outputId": "cebdbbbc-a7e0-4321-fc38-5991019f4408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados guardados en 'results_es_qum_finetune_direct.tsv'\n"
     ]
    }
   ],
   "source": [
    "filename = \"results_en_qum_finetune_direct.tsv\"\n",
    "with open(filename, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    writer.writerow([\"input\", \"reference\", \"prediction\"])\n",
    "\n",
    "    for example, pred, ref in zip(es_qum_dataset[\"test\"], predictions_direct, references_direct):\n",
    "        writer.writerow([example[\"input\"], ref, pred])\n",
    "\n",
    "print(f\"✅ Resultados guardados en '{filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCaQTajaoPyr"
   },
   "source": [
    "#### 4. Finetuning EN-QUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7u9Ij-k23zQB",
    "outputId": "0cb1f47c-8066-499f-8545-4f7d71d94a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Traduciendo: inglés → K’iche’ (dataset sintético directo)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321/321 [13:03<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions_en_qum = []\n",
    "references_en_qum = []\n",
    "\n",
    "print(\"\\n🔹 Traduciendo: inglés → K’iche’ (dataset sintético directo)\\n\")\n",
    "\n",
    "for item in tqdm(en_qum_dataset[\"test\"]):\n",
    "    input_text = item[\"input\"]\n",
    "    reference = item[\"target\"]\n",
    "    pred = translate_text(en_qum_model, en_qum_tokenizer, input_text, \"eng_Latn\", \"quc_Latn\")\n",
    "\n",
    "    predictions_en_qum.append(pred)\n",
    "    references_en_qum.append(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XO8mA9IDiFzd",
    "outputId": "50178c1c-45f4-4673-c223-5630f8885d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplos Fine-Tuned ===\n",
      "\n",
      "> Entrada:     The Commission shall adopt implementing acts in accordance with Article 21 of the Financial Regulation.\n",
      "> Referencia:  #qum# La esposa de don Jesus solo utiliza buena leña\n",
      "> Predicción:  La Comisión aprueba actos de ejecución de conformidad con el artículo 21 del Reglamento Financiero.\n",
      "\n",
      "> Entrada:     The Commission shall adopt implementing acts in accordance with Article 21 of the Financial Regulation.\n",
      "> Referencia:  #qum# Todo la arveja se\n",
      "> Predicción:            \n",
      "\n",
      "> Entrada:     The Commission shall adopt implementing acts in accordance with Article 21 of the Financial Regulation.\n",
      "> Referencia:  #qum# En nuestro pueblo ya no se usa nuestro idioma\n",
      "> Predicción:              \n",
      "\n",
      "> Entrada:     The Commission has decided to extend the period of validity of the agreement to the Member States.\n",
      "> Referencia:  #qum# El estudiante está aprendiendo como\n",
      "> Predicción:  la Comisión decidió prorrogar el periodo de validez del acuerdo a los Estados miembros.\n",
      "\n",
      "> Entrada:     The Commission shall adopt the following implementing acts:\n",
      "> Referencia:  #qum# La mujer estaba abrazada por su marido\n",
      "> Predicción:        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Ejemplos Fine-Tuned ===\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"> Entrada:     {en_qum_dataset['test'][i]['input']}\")\n",
    "    print(f\"> Referencia:  {en_qum_dataset['test'][i]['target']}\")\n",
    "    print(f\"> Predicción:  {predictions_en_qum[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UUh-Dvk3iLoy",
    "outputId": "6f382bc5-f056-4380-81fe-0701fbaa9ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Métricas BLEU ===\n",
      "BLEU-1: 3.03\n",
      "BLEU-2: 0.12\n",
      "BLEU-3: 0.00\n",
      "BLEU-4: 0.00\n",
      "BLEU total: 0.00\n",
      "\n",
      "=== Métricas ROUGE ===\n",
      "ROUGE-1:   4.07\n",
      "ROUGE-2:   0.14\n",
      "ROUGE-L:   3.70\n",
      "ROUGE-Lsum:3.71\n",
      "\n",
      "=== Otras Métricas ===\n",
      "METEOR:     2.62\n"
     ]
    }
   ],
   "source": [
    "bleu_score = bleu.compute(predictions=predictions_en_qum, references=[[ref] for ref in references_en_qum])\n",
    "\n",
    "print(\"\\n=== Métricas BLEU ===\")\n",
    "print(f\"BLEU-1: {bleu_score['precisions'][0]*100:.2f}\")\n",
    "print(f\"BLEU-2: {bleu_score['precisions'][1]*100:.2f}\")\n",
    "print(f\"BLEU-3: {bleu_score['precisions'][2]*100:.2f}\")\n",
    "print(f\"BLEU-4: {bleu_score['precisions'][3]*100:.2f}\")\n",
    "print(f\"BLEU total: {bleu_score['bleu']*100:.2f}\")\n",
    "\n",
    "rouge_score = rouge.compute(predictions=predictions_en_qum, references=references_en_qum)\n",
    "\n",
    "print(\"\\n=== Métricas ROUGE ===\")\n",
    "print(f\"ROUGE-1:   {rouge_score['rouge1']*100:.2f}\")\n",
    "print(f\"ROUGE-2:   {rouge_score['rouge2']*100:.2f}\")\n",
    "print(f\"ROUGE-L:   {rouge_score['rougeL']*100:.2f}\")\n",
    "print(f\"ROUGE-Lsum:{rouge_score['rougeLsum']*100:.2f}\")\n",
    "\n",
    "meteor_score = meteor.compute(predictions=predictions_en_qum, references=references_en_qum)\n",
    "\n",
    "print(\"\\n=== Otras Métricas ===\")\n",
    "print(f\"METEOR:     {meteor_score['meteor']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uTytWvytiOA-",
    "outputId": "fccc3534-5ff0-4e2e-bc7b-0d17e8d4cb2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados guardados en 'results_en_qum_directo.tsv'\n"
     ]
    }
   ],
   "source": [
    "filename = \"results_en_qum_directo.tsv\"\n",
    "with open(filename, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    writer.writerow([\"input\", \"reference\", \"prediction\"])\n",
    "\n",
    "    for example, pred, ref in zip(es_qum_dataset[\"test\"], predictions_en_qum, references_en_qum):\n",
    "        writer.writerow([example[\"input\"], ref, pred])\n",
    "\n",
    "print(f\"✅ Resultados guardados en '{filename}'\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "g5rb6MT0A5mD",
    "6x8Nds_8Y1Mm",
    "o6ngW-l5c1aq",
    "qjWCp3bkc27u",
    "U9jCIC05CCG_",
    "ljNvMeB3ezyA",
    "rjB3SBkqn1JG",
    "y_UFY-dToFsb"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
